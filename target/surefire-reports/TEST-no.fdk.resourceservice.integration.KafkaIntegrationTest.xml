<?xml version="1.0" encoding="UTF-8"?>
<testsuite xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="https://maven.apache.org/surefire/maven-surefire-plugin/xsd/surefire-test-report.xsd" version="3.0.2" name="no.fdk.resourceservice.integration.KafkaIntegrationTest" time="59.351" tests="6" errors="0" skipped="0" failures="2">
  <properties>
    <property name="java.specification.version" value="22"/>
    <property name="sun.jnu.encoding" value="UTF-8"/>
    <property name="java.class.path" value="/Users/jeffreiffers/Digdir/fdk-resource-service/target/test-classes:/Users/jeffreiffers/Digdir/fdk-resource-service/target/classes:/Users/jeffreiffers/.m2/repository/org/springframework/boot/spring-boot-starter-web/3.5.6/spring-boot-starter-web-3.5.6.jar:/Users/jeffreiffers/.m2/repository/org/springframework/boot/spring-boot-starter/3.5.6/spring-boot-starter-3.5.6.jar:/Users/jeffreiffers/.m2/repository/org/springframework/boot/spring-boot/3.5.6/spring-boot-3.5.6.jar:/Users/jeffreiffers/.m2/repository/org/springframework/boot/spring-boot-autoconfigure/3.5.6/spring-boot-autoconfigure-3.5.6.jar:/Users/jeffreiffers/.m2/repository/org/springframework/boot/spring-boot-starter-logging/3.5.6/spring-boot-starter-logging-3.5.6.jar:/Users/jeffreiffers/.m2/repository/org/apache/logging/log4j/log4j-to-slf4j/2.24.3/log4j-to-slf4j-2.24.3.jar:/Users/jeffreiffers/.m2/repository/org/apache/logging/log4j/log4j-api/2.24.3/log4j-api-2.24.3.jar:/Users/jeffreiffers/.m2/repository/org/slf4j/jul-to-slf4j/2.0.17/jul-to-slf4j-2.0.17.jar:/Users/jeffreiffers/.m2/repository/jakarta/annotation/jakarta.annotation-api/2.1.1/jakarta.annotation-api-2.1.1.jar:/Users/jeffreiffers/.m2/repository/org/yaml/snakeyaml/2.4/snakeyaml-2.4.jar:/Users/jeffreiffers/.m2/repository/org/springframework/boot/spring-boot-starter-json/3.5.6/spring-boot-starter-json-3.5.6.jar:/Users/jeffreiffers/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jdk8/2.19.2/jackson-datatype-jdk8-2.19.2.jar:/Users/jeffreiffers/.m2/repository/com/fasterxml/jackson/module/jackson-module-parameter-names/2.19.2/jackson-module-parameter-names-2.19.2.jar:/Users/jeffreiffers/.m2/repository/org/springframework/boot/spring-boot-starter-tomcat/3.5.6/spring-boot-starter-tomcat-3.5.6.jar:/Users/jeffreiffers/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/10.1.46/tomcat-embed-core-10.1.46.jar:/Users/jeffreiffers/.m2/repository/org/apache/tomcat/embed/tomcat-embed-websocket/10.1.46/tomcat-embed-websocket-10.1.46.jar:/Users/jeffreiffers/.m2/repository/org/springframework/spring-web/6.2.11/spring-web-6.2.11.jar:/Users/jeffreiffers/.m2/repository/org/springframework/spring-beans/6.2.11/spring-beans-6.2.11.jar:/Users/jeffreiffers/.m2/repository/org/springframework/spring-webmvc/6.2.11/spring-webmvc-6.2.11.jar:/Users/jeffreiffers/.m2/repository/org/springframework/spring-expression/6.2.11/spring-expression-6.2.11.jar:/Users/jeffreiffers/.m2/repository/org/springframework/boot/spring-boot-starter-data-jpa/3.5.6/spring-boot-starter-data-jpa-3.5.6.jar:/Users/jeffreiffers/.m2/repository/org/springframework/boot/spring-boot-starter-jdbc/3.5.6/spring-boot-starter-jdbc-3.5.6.jar:/Users/jeffreiffers/.m2/repository/com/zaxxer/HikariCP/6.3.3/HikariCP-6.3.3.jar:/Users/jeffreiffers/.m2/repository/org/springframework/spring-jdbc/6.2.11/spring-jdbc-6.2.11.jar:/Users/jeffreiffers/.m2/repository/org/hibernate/orm/hibernate-core/6.6.29.Final/hibernate-core-6.6.29.Final.jar:/Users/jeffreiffers/.m2/repository/jakarta/persistence/jakarta.persistence-api/3.1.0/jakarta.persistence-api-3.1.0.jar:/Users/jeffreiffers/.m2/repository/jakarta/transaction/jakarta.transaction-api/2.0.1/jakarta.transaction-api-2.0.1.jar:/Users/jeffreiffers/.m2/repository/org/jboss/logging/jboss-logging/3.6.1.Final/jboss-logging-3.6.1.Final.jar:/Users/jeffreiffers/.m2/repository/org/hibernate/common/hibernate-commons-annotations/7.0.3.Final/hibernate-commons-annotations-7.0.3.Final.jar:/Users/jeffreiffers/.m2/repository/io/smallrye/jandex/3.2.0/jandex-3.2.0.jar:/Users/jeffreiffers/.m2/repository/com/fasterxml/classmate/1.7.0/classmate-1.7.0.jar:/Users/jeffreiffers/.m2/repository/org/glassfish/jaxb/jaxb-runtime/4.0.5/jaxb-runtime-4.0.5.jar:/Users/jeffreiffers/.m2/repository/org/glassfish/jaxb/jaxb-core/4.0.5/jaxb-core-4.0.5.jar:/Users/jeffreiffers/.m2/repository/org/eclipse/angus/angus-activation/2.0.2/angus-activation-2.0.2.jar:/Users/jeffreiffers/.m2/repository/org/glassfish/jaxb/txw2/4.0.5/txw2-4.0.5.jar:/Users/jeffreiffers/.m2/repository/com/sun/istack/istack-commons-runtime/4.1.2/istack-commons-runtime-4.1.2.jar:/Users/jeffreiffers/.m2/repository/jakarta/inject/jakarta.inject-api/2.0.1/jakarta.inject-api-2.0.1.jar:/Users/jeffreiffers/.m2/repository/org/antlr/antlr4-runtime/4.13.0/antlr4-runtime-4.13.0.jar:/Users/jeffreiffers/.m2/repository/org/springframework/data/spring-data-jpa/3.5.4/spring-data-jpa-3.5.4.jar:/Users/jeffreiffers/.m2/repository/org/springframework/data/spring-data-commons/3.5.4/spring-data-commons-3.5.4.jar:/Users/jeffreiffers/.m2/repository/org/springframework/spring-orm/6.2.11/spring-orm-6.2.11.jar:/Users/jeffreiffers/.m2/repository/org/springframework/spring-aspects/6.2.11/spring-aspects-6.2.11.jar:/Users/jeffreiffers/.m2/repository/org/aspectj/aspectjweaver/1.9.24/aspectjweaver-1.9.24.jar:/Users/jeffreiffers/.m2/repository/org/springframework/boot/spring-boot-starter-validation/3.5.6/spring-boot-starter-validation-3.5.6.jar:/Users/jeffreiffers/.m2/repository/org/apache/tomcat/embed/tomcat-embed-el/10.1.46/tomcat-embed-el-10.1.46.jar:/Users/jeffreiffers/.m2/repository/org/hibernate/validator/hibernate-validator/8.0.3.Final/hibernate-validator-8.0.3.Final.jar:/Users/jeffreiffers/.m2/repository/jakarta/validation/jakarta.validation-api/3.0.2/jakarta.validation-api-3.0.2.jar:/Users/jeffreiffers/.m2/repository/org/springframework/boot/spring-boot-starter-actuator/3.5.6/spring-boot-starter-actuator-3.5.6.jar:/Users/jeffreiffers/.m2/repository/org/springframework/boot/spring-boot-actuator-autoconfigure/3.5.6/spring-boot-actuator-autoconfigure-3.5.6.jar:/Users/jeffreiffers/.m2/repository/org/springframework/boot/spring-boot-actuator/3.5.6/spring-boot-actuator-3.5.6.jar:/Users/jeffreiffers/.m2/repository/io/micrometer/micrometer-observation/1.15.4/micrometer-observation-1.15.4.jar:/Users/jeffreiffers/.m2/repository/io/micrometer/micrometer-commons/1.15.4/micrometer-commons-1.15.4.jar:/Users/jeffreiffers/.m2/repository/io/micrometer/micrometer-jakarta9/1.15.4/micrometer-jakarta9-1.15.4.jar:/Users/jeffreiffers/.m2/repository/io/micrometer/micrometer-core/1.15.4/micrometer-core-1.15.4.jar:/Users/jeffreiffers/.m2/repository/org/hdrhistogram/HdrHistogram/2.2.2/HdrHistogram-2.2.2.jar:/Users/jeffreiffers/.m2/repository/org/latencyutils/LatencyUtils/2.0.3/LatencyUtils-2.0.3.jar:/Users/jeffreiffers/.m2/repository/org/springframework/kafka/spring-kafka/3.3.10/spring-kafka-3.3.10.jar:/Users/jeffreiffers/.m2/repository/org/springframework/spring-context/6.2.11/spring-context-6.2.11.jar:/Users/jeffreiffers/.m2/repository/org/springframework/spring-messaging/6.2.11/spring-messaging-6.2.11.jar:/Users/jeffreiffers/.m2/repository/org/springframework/spring-tx/6.2.11/spring-tx-6.2.11.jar:/Users/jeffreiffers/.m2/repository/org/springframework/retry/spring-retry/2.0.12/spring-retry-2.0.12.jar:/Users/jeffreiffers/.m2/repository/org/springframework/boot/spring-boot-starter-security/3.5.6/spring-boot-starter-security-3.5.6.jar:/Users/jeffreiffers/.m2/repository/org/springframework/spring-aop/6.2.11/spring-aop-6.2.11.jar:/Users/jeffreiffers/.m2/repository/org/springframework/security/spring-security-config/6.5.5/spring-security-config-6.5.5.jar:/Users/jeffreiffers/.m2/repository/org/springframework/security/spring-security-web/6.5.5/spring-security-web-6.5.5.jar:/Users/jeffreiffers/.m2/repository/org/springframework/security/spring-security-oauth2-jose/6.5.5/spring-security-oauth2-jose-6.5.5.jar:/Users/jeffreiffers/.m2/repository/org/springframework/security/spring-security-core/6.5.5/spring-security-core-6.5.5.jar:/Users/jeffreiffers/.m2/repository/org/springframework/security/spring-security-crypto/6.5.5/spring-security-crypto-6.5.5.jar:/Users/jeffreiffers/.m2/repository/org/springframework/security/spring-security-oauth2-core/6.5.5/spring-security-oauth2-core-6.5.5.jar:/Users/jeffreiffers/.m2/repository/org/springframework/spring-core/6.2.11/spring-core-6.2.11.jar:/Users/jeffreiffers/.m2/repository/org/springframework/spring-jcl/6.2.11/spring-jcl-6.2.11.jar:/Users/jeffreiffers/.m2/repository/com/nimbusds/nimbus-jose-jwt/9.37.4/nimbus-jose-jwt-9.37.4.jar:/Users/jeffreiffers/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/Users/jeffreiffers/.m2/repository/org/springframework/security/spring-security-oauth2-resource-server/6.5.5/spring-security-oauth2-resource-server-6.5.5.jar:/Users/jeffreiffers/.m2/repository/org/postgresql/postgresql/42.7.7/postgresql-42.7.7.jar:/Users/jeffreiffers/.m2/repository/org/checkerframework/checker-qual/3.49.3/checker-qual-3.49.3.jar:/Users/jeffreiffers/.m2/repository/org/flywaydb/flyway-core/11.7.2/flyway-core-11.7.2.jar:/Users/jeffreiffers/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-toml/2.19.2/jackson-dataformat-toml-2.19.2.jar:/Users/jeffreiffers/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.19.2/jackson-datatype-jsr310-2.19.2.jar:/Users/jeffreiffers/.m2/repository/org/flywaydb/flyway-database-postgresql/11.7.2/flyway-database-postgresql-11.7.2.jar:/Users/jeffreiffers/.m2/repository/org/apache/avro/avro/1.12.1/avro-1.12.1.jar:/Users/jeffreiffers/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.19.2/jackson-core-2.19.2.jar:/Users/jeffreiffers/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.19.2/jackson-databind-2.19.2.jar:/Users/jeffreiffers/.m2/repository/org/apache/commons/commons-compress/1.28.0/commons-compress-1.28.0.jar:/Users/jeffreiffers/.m2/repository/commons-codec/commons-codec/1.18.0/commons-codec-1.18.0.jar:/Users/jeffreiffers/.m2/repository/commons-io/commons-io/2.20.0/commons-io-2.20.0.jar:/Users/jeffreiffers/.m2/repository/org/apache/commons/commons-lang3/3.17.0/commons-lang3-3.17.0.jar:/Users/jeffreiffers/.m2/repository/org/slf4j/slf4j-api/2.0.17/slf4j-api-2.0.17.jar:/Users/jeffreiffers/.m2/repository/org/apache/kafka/kafka-clients/3.9.1/kafka-clients-3.9.1.jar:/Users/jeffreiffers/.m2/repository/com/github/luben/zstd-jni/1.5.6-4/zstd-jni-1.5.6-4.jar:/Users/jeffreiffers/.m2/repository/org/lz4/lz4-java/1.8.0/lz4-java-1.8.0.jar:/Users/jeffreiffers/.m2/repository/org/xerial/snappy/snappy-java/1.1.10.5/snappy-java-1.1.10.5.jar:/Users/jeffreiffers/.m2/repository/io/confluent/kafka-avro-serializer/8.0.0/kafka-avro-serializer-8.0.0.jar:/Users/jeffreiffers/.m2/repository/io/confluent/kafka-schema-serializer/8.0.0/kafka-schema-serializer-8.0.0.jar:/Users/jeffreiffers/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-csv/2.19.2/jackson-dataformat-csv-2.19.2.jar:/Users/jeffreiffers/.m2/repository/io/confluent/kafka-schema-registry-client/8.0.0/kafka-schema-registry-client-8.0.0.jar:/Users/jeffreiffers/.m2/repository/io/swagger/core/v3/swagger-annotations/2.2.29/swagger-annotations-2.2.29.jar:/Users/jeffreiffers/.m2/repository/com/google/guava/guava/32.0.1-jre/guava-32.0.1-jre.jar:/Users/jeffreiffers/.m2/repository/com/google/guava/failureaccess/1.0.1/failureaccess-1.0.1.jar:/Users/jeffreiffers/.m2/repository/com/google/guava/listenablefuture/9999.0-empty-to-avoid-conflict-with-guava/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/Users/jeffreiffers/.m2/repository/com/google/code/findbugs/jsr305/3.0.2/jsr305-3.0.2.jar:/Users/jeffreiffers/.m2/repository/com/google/errorprone/error_prone_annotations/2.18.0/error_prone_annotations-2.18.0.jar:/Users/jeffreiffers/.m2/repository/com/google/j2objc/j2objc-annotations/2.8/j2objc-annotations-2.8.jar:/Users/jeffreiffers/.m2/repository/io/confluent/logredactor/1.0.13/logredactor-1.0.13.jar:/Users/jeffreiffers/.m2/repository/com/google/re2j/re2j/1.6/re2j-1.6.jar:/Users/jeffreiffers/.m2/repository/io/confluent/logredactor-metrics/1.0.13/logredactor-metrics-1.0.13.jar:/Users/jeffreiffers/.m2/repository/com/eclipsesource/minimal-json/minimal-json/0.9.5/minimal-json-0.9.5.jar:/Users/jeffreiffers/.m2/repository/io/confluent/common-utils/8.0.0/common-utils-8.0.0.jar:/Users/jeffreiffers/.m2/repository/com/fasterxml/jackson/module/jackson-module-kotlin/2.19.2/jackson-module-kotlin-2.19.2.jar:/Users/jeffreiffers/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.19.2/jackson-annotations-2.19.2.jar:/Users/jeffreiffers/.m2/repository/org/springdoc/springdoc-openapi-starter-webmvc-ui/2.8.13/springdoc-openapi-starter-webmvc-ui-2.8.13.jar:/Users/jeffreiffers/.m2/repository/org/springdoc/springdoc-openapi-starter-webmvc-api/2.8.13/springdoc-openapi-starter-webmvc-api-2.8.13.jar:/Users/jeffreiffers/.m2/repository/org/springdoc/springdoc-openapi-starter-common/2.8.13/springdoc-openapi-starter-common-2.8.13.jar:/Users/jeffreiffers/.m2/repository/io/swagger/core/v3/swagger-core-jakarta/2.2.36/swagger-core-jakarta-2.2.36.jar:/Users/jeffreiffers/.m2/repository/io/swagger/core/v3/swagger-annotations-jakarta/2.2.36/swagger-annotations-jakarta-2.2.36.jar:/Users/jeffreiffers/.m2/repository/io/swagger/core/v3/swagger-models-jakarta/2.2.36/swagger-models-jakarta-2.2.36.jar:/Users/jeffreiffers/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-yaml/2.19.2/jackson-dataformat-yaml-2.19.2.jar:/Users/jeffreiffers/.m2/repository/org/webjars/swagger-ui/5.28.1/swagger-ui-5.28.1.jar:/Users/jeffreiffers/.m2/repository/org/webjars/webjars-locator-lite/1.1.0/webjars-locator-lite-1.1.0.jar:/Users/jeffreiffers/.m2/repository/org/jspecify/jspecify/1.0.0/jspecify-1.0.0.jar:/Users/jeffreiffers/.m2/repository/io/github/resilience4j/resilience4j-spring-boot3/2.2.0/resilience4j-spring-boot3-2.2.0.jar:/Users/jeffreiffers/.m2/repository/io/github/resilience4j/resilience4j-spring6/2.2.0/resilience4j-spring6-2.2.0.jar:/Users/jeffreiffers/.m2/repository/io/github/resilience4j/resilience4j-annotations/2.2.0/resilience4j-annotations-2.2.0.jar:/Users/jeffreiffers/.m2/repository/io/github/resilience4j/resilience4j-consumer/2.2.0/resilience4j-consumer-2.2.0.jar:/Users/jeffreiffers/.m2/repository/io/github/resilience4j/resilience4j-circularbuffer/2.2.0/resilience4j-circularbuffer-2.2.0.jar:/Users/jeffreiffers/.m2/repository/io/github/resilience4j/resilience4j-framework-common/2.2.0/resilience4j-framework-common-2.2.0.jar:/Users/jeffreiffers/.m2/repository/io/github/resilience4j/resilience4j-micrometer/2.2.0/resilience4j-micrometer-2.2.0.jar:/Users/jeffreiffers/.m2/repository/io/github/resilience4j/resilience4j-reactor/2.2.0/resilience4j-reactor-2.2.0.jar:/Users/jeffreiffers/.m2/repository/io/projectreactor/reactor-core/3.7.11/reactor-core-3.7.11.jar:/Users/jeffreiffers/.m2/repository/org/reactivestreams/reactive-streams/1.0.4/reactive-streams-1.0.4.jar:/Users/jeffreiffers/.m2/repository/io/github/resilience4j/resilience4j-circuitbreaker/2.2.0/resilience4j-circuitbreaker-2.2.0.jar:/Users/jeffreiffers/.m2/repository/io/github/resilience4j/resilience4j-core/2.2.0/resilience4j-core-2.2.0.jar:/Users/jeffreiffers/.m2/repository/io/github/resilience4j/resilience4j-ratelimiter/2.2.0/resilience4j-ratelimiter-2.2.0.jar:/Users/jeffreiffers/.m2/repository/io/github/resilience4j/resilience4j-timelimiter/2.2.0/resilience4j-timelimiter-2.2.0.jar:/Users/jeffreiffers/.m2/repository/io/github/resilience4j/resilience4j-bulkhead/2.2.0/resilience4j-bulkhead-2.2.0.jar:/Users/jeffreiffers/.m2/repository/io/github/resilience4j/resilience4j-retry/2.2.0/resilience4j-retry-2.2.0.jar:/Users/jeffreiffers/.m2/repository/org/apache/jena/jena-rdfpatch/5.6.0/jena-rdfpatch-5.6.0.jar:/Users/jeffreiffers/.m2/repository/org/apache/jena/jena-arq/5.6.0/jena-arq-5.6.0.jar:/Users/jeffreiffers/.m2/repository/org/apache/jena/jena-core/5.6.0/jena-core-5.6.0.jar:/Users/jeffreiffers/.m2/repository/org/apache/jena/jena-base/5.6.0/jena-base-5.6.0.jar:/Users/jeffreiffers/.m2/repository/org/apache/commons/commons-csv/1.14.1/commons-csv-1.14.1.jar:/Users/jeffreiffers/.m2/repository/org/apache/commons/commons-collections4/4.5.0/commons-collections4-4.5.0.jar:/Users/jeffreiffers/.m2/repository/com/github/andrewoma/dexx/collection/0.7/collection-0.7.jar:/Users/jeffreiffers/.m2/repository/org/apache/jena/jena-iri3986/5.6.0/jena-iri3986-5.6.0.jar:/Users/jeffreiffers/.m2/repository/org/apache/jena/jena-iri/5.6.0/jena-iri-5.6.0.jar:/Users/jeffreiffers/.m2/repository/org/apache/jena/jena-langtag/5.6.0/jena-langtag-5.6.0.jar:/Users/jeffreiffers/.m2/repository/org/roaringbitmap/RoaringBitmap/1.3.0/RoaringBitmap-1.3.0.jar:/Users/jeffreiffers/.m2/repository/com/google/code/gson/gson/2.13.2/gson-2.13.2.jar:/Users/jeffreiffers/.m2/repository/org/slf4j/jcl-over-slf4j/2.0.17/jcl-over-slf4j-2.0.17.jar:/Users/jeffreiffers/.m2/repository/com/apicatalog/titanium-json-ld/1.7.0/titanium-json-ld-1.7.0.jar:/Users/jeffreiffers/.m2/repository/com/apicatalog/titanium-jcs/1.1.1/titanium-jcs-1.1.1.jar:/Users/jeffreiffers/.m2/repository/com/apicatalog/titanium-rdf-api/1.0.0/titanium-rdf-api-1.0.0.jar:/Users/jeffreiffers/.m2/repository/com/apicatalog/titanium-rdf-n-quads/1.0.2/titanium-rdf-n-quads-1.0.2.jar:/Users/jeffreiffers/.m2/repository/org/glassfish/jakarta.json/2.0.1/jakarta.json-2.0.1.jar:/Users/jeffreiffers/.m2/repository/com/google/protobuf/protobuf-java/4.32.1/protobuf-java-4.32.1.jar:/Users/jeffreiffers/.m2/repository/org/apache/thrift/libthrift/0.22.0/libthrift-0.22.0.jar:/Users/jeffreiffers/.m2/repository/org/apache/jena/jena-ontapi/5.6.0/jena-ontapi-5.6.0.jar:/Users/jeffreiffers/.m2/repository/org/apache/jena/jena-shacl/5.6.0/jena-shacl-5.6.0.jar:/Users/jeffreiffers/.m2/repository/org/apache/jena/jena-shex/5.6.0/jena-shex-5.6.0.jar:/Users/jeffreiffers/.m2/repository/org/apache/jena/jena-tdb1/5.6.0/jena-tdb1-5.6.0.jar:/Users/jeffreiffers/.m2/repository/org/apache/jena/jena-tdb2/5.6.0/jena-tdb2-5.6.0.jar:/Users/jeffreiffers/.m2/repository/org/apache/jena/jena-dboe-storage/5.6.0/jena-dboe-storage-5.6.0.jar:/Users/jeffreiffers/.m2/repository/org/apache/jena/jena-dboe-trans-data/5.6.0/jena-dboe-trans-data-5.6.0.jar:/Users/jeffreiffers/.m2/repository/org/apache/jena/jena-dboe-transaction/5.6.0/jena-dboe-transaction-5.6.0.jar:/Users/jeffreiffers/.m2/repository/org/apache/jena/jena-dboe-base/5.6.0/jena-dboe-base-5.6.0.jar:/Users/jeffreiffers/.m2/repository/org/apache/jena/jena-dboe-index/5.6.0/jena-dboe-index-5.6.0.jar:/Users/jeffreiffers/.m2/repository/org/apache/jena/jena-rdfconnection/5.6.0/jena-rdfconnection-5.6.0.jar:/Users/jeffreiffers/.m2/repository/org/jetbrains/kotlin/kotlin-reflect/2.2.20/kotlin-reflect-2.2.20.jar:/Users/jeffreiffers/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib/2.2.20/kotlin-stdlib-2.2.20.jar:/Users/jeffreiffers/.m2/repository/org/jetbrains/annotations/13.0/annotations-13.0.jar:/Users/jeffreiffers/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib-jdk8/2.2.20/kotlin-stdlib-jdk8-2.2.20.jar:/Users/jeffreiffers/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib-jdk7/2.2.20/kotlin-stdlib-jdk7-2.2.20.jar:/Users/jeffreiffers/.m2/repository/org/springframework/boot/spring-boot-starter-test/3.5.6/spring-boot-starter-test-3.5.6.jar:/Users/jeffreiffers/.m2/repository/org/springframework/boot/spring-boot-test/3.5.6/spring-boot-test-3.5.6.jar:/Users/jeffreiffers/.m2/repository/org/springframework/boot/spring-boot-test-autoconfigure/3.5.6/spring-boot-test-autoconfigure-3.5.6.jar:/Users/jeffreiffers/.m2/repository/com/jayway/jsonpath/json-path/2.9.0/json-path-2.9.0.jar:/Users/jeffreiffers/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/4.0.2/jakarta.xml.bind-api-4.0.2.jar:/Users/jeffreiffers/.m2/repository/jakarta/activation/jakarta.activation-api/2.1.4/jakarta.activation-api-2.1.4.jar:/Users/jeffreiffers/.m2/repository/net/minidev/json-smart/2.5.2/json-smart-2.5.2.jar:/Users/jeffreiffers/.m2/repository/net/minidev/accessors-smart/2.5.2/accessors-smart-2.5.2.jar:/Users/jeffreiffers/.m2/repository/org/ow2/asm/asm/9.7.1/asm-9.7.1.jar:/Users/jeffreiffers/.m2/repository/org/assertj/assertj-core/3.27.4/assertj-core-3.27.4.jar:/Users/jeffreiffers/.m2/repository/org/awaitility/awaitility/4.2.2/awaitility-4.2.2.jar:/Users/jeffreiffers/.m2/repository/org/hamcrest/hamcrest/3.0/hamcrest-3.0.jar:/Users/jeffreiffers/.m2/repository/org/junit/jupiter/junit-jupiter/5.12.2/junit-jupiter-5.12.2.jar:/Users/jeffreiffers/.m2/repository/org/junit/jupiter/junit-jupiter-params/5.12.2/junit-jupiter-params-5.12.2.jar:/Users/jeffreiffers/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.12.2/junit-jupiter-engine-5.12.2.jar:/Users/jeffreiffers/.m2/repository/org/skyscreamer/jsonassert/1.5.3/jsonassert-1.5.3.jar:/Users/jeffreiffers/.m2/repository/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar:/Users/jeffreiffers/.m2/repository/org/springframework/spring-test/6.2.11/spring-test-6.2.11.jar:/Users/jeffreiffers/.m2/repository/org/xmlunit/xmlunit-core/2.10.4/xmlunit-core-2.10.4.jar:/Users/jeffreiffers/.m2/repository/org/springframework/kafka/spring-kafka-test/3.3.10/spring-kafka-test-3.3.10.jar:/Users/jeffreiffers/.m2/repository/org/apache/zookeeper/zookeeper/3.8.4/zookeeper-3.8.4.jar:/Users/jeffreiffers/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.8.4/zookeeper-jute-3.8.4.jar:/Users/jeffreiffers/.m2/repository/org/apache/yetus/audience-annotations/0.12.0/audience-annotations-0.12.0.jar:/Users/jeffreiffers/.m2/repository/io/netty/netty-handler/4.1.127.Final/netty-handler-4.1.127.Final.jar:/Users/jeffreiffers/.m2/repository/io/netty/netty-common/4.1.127.Final/netty-common-4.1.127.Final.jar:/Users/jeffreiffers/.m2/repository/io/netty/netty-resolver/4.1.127.Final/netty-resolver-4.1.127.Final.jar:/Users/jeffreiffers/.m2/repository/io/netty/netty-buffer/4.1.127.Final/netty-buffer-4.1.127.Final.jar:/Users/jeffreiffers/.m2/repository/io/netty/netty-transport/4.1.127.Final/netty-transport-4.1.127.Final.jar:/Users/jeffreiffers/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.127.Final/netty-transport-native-unix-common-4.1.127.Final.jar:/Users/jeffreiffers/.m2/repository/io/netty/netty-codec/4.1.127.Final/netty-codec-4.1.127.Final.jar:/Users/jeffreiffers/.m2/repository/io/netty/netty-transport-native-epoll/4.1.127.Final/netty-transport-native-epoll-4.1.127.Final.jar:/Users/jeffreiffers/.m2/repository/io/netty/netty-transport-classes-epoll/4.1.127.Final/netty-transport-classes-epoll-4.1.127.Final.jar:/Users/jeffreiffers/.m2/repository/ch/qos/logback/logback-core/1.5.18/logback-core-1.5.18.jar:/Users/jeffreiffers/.m2/repository/ch/qos/logback/logback-classic/1.5.18/logback-classic-1.5.18.jar:/Users/jeffreiffers/.m2/repository/org/apache/kafka/kafka-clients/3.9.1/kafka-clients-3.9.1-test.jar:/Users/jeffreiffers/.m2/repository/org/apache/kafka/kafka-server/3.9.1/kafka-server-3.9.1.jar:/Users/jeffreiffers/.m2/repository/org/apache/kafka/kafka-storage/3.9.1/kafka-storage-3.9.1.jar:/Users/jeffreiffers/.m2/repository/com/github/ben-manes/caffeine/caffeine/3.2.2/caffeine-3.2.2.jar:/Users/jeffreiffers/.m2/repository/org/apache/kafka/kafka-group-coordinator/3.9.1/kafka-group-coordinator-3.9.1.jar:/Users/jeffreiffers/.m2/repository/org/apache/kafka/kafka-transaction-coordinator/3.9.1/kafka-transaction-coordinator-3.9.1.jar:/Users/jeffreiffers/.m2/repository/org/apache/kafka/kafka-raft/3.9.1/kafka-raft-3.9.1.jar:/Users/jeffreiffers/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/Users/jeffreiffers/.m2/repository/org/apache/kafka/kafka-metadata/3.9.1/kafka-metadata-3.9.1.jar:/Users/jeffreiffers/.m2/repository/org/apache/kafka/kafka-server-common/3.9.1/kafka-server-common-3.9.1.jar:/Users/jeffreiffers/.m2/repository/net/sf/jopt-simple/jopt-simple/5.0.4/jopt-simple-5.0.4.jar:/Users/jeffreiffers/.m2/repository/org/pcollections/pcollections/4.0.1/pcollections-4.0.1.jar:/Users/jeffreiffers/.m2/repository/org/apache/kafka/kafka-server-common/3.9.1/kafka-server-common-3.9.1-test.jar:/Users/jeffreiffers/.m2/repository/org/apache/kafka/kafka-streams-test-utils/3.9.1/kafka-streams-test-utils-3.9.1.jar:/Users/jeffreiffers/.m2/repository/org/apache/kafka/kafka-streams/3.9.1/kafka-streams-3.9.1.jar:/Users/jeffreiffers/.m2/repository/org/rocksdb/rocksdbjni/7.9.2/rocksdbjni-7.9.2.jar:/Users/jeffreiffers/.m2/repository/org/apache/kafka/kafka_2.13/3.9.1/kafka_2.13-3.9.1.jar:/Users/jeffreiffers/.m2/repository/org/scala-lang/scala-library/2.13.15/scala-library-2.13.15.jar:/Users/jeffreiffers/.m2/repository/org/apache/kafka/kafka-group-coordinator-api/3.9.1/kafka-group-coordinator-api-3.9.1.jar:/Users/jeffreiffers/.m2/repository/org/apache/kafka/kafka-storage-api/3.9.1/kafka-storage-api-3.9.1.jar:/Users/jeffreiffers/.m2/repository/org/apache/kafka/kafka-tools-api/3.9.1/kafka-tools-api-3.9.1.jar:/Users/jeffreiffers/.m2/repository/net/sourceforge/argparse4j/argparse4j/0.7.0/argparse4j-0.7.0.jar:/Users/jeffreiffers/.m2/repository/commons-validator/commons-validator/1.7/commons-validator-1.7.jar:/Users/jeffreiffers/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/Users/jeffreiffers/.m2/repository/commons-digester/commons-digester/2.1/commons-digester-2.1.jar:/Users/jeffreiffers/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/Users/jeffreiffers/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.13/2.19.2/jackson-module-scala_2.13-2.19.2.jar:/Users/jeffreiffers/.m2/repository/com/thoughtworks/paranamer/paranamer/2.8.3/paranamer-2.8.3.jar:/Users/jeffreiffers/.m2/repository/org/bitbucket/b_c/jose4j/0.9.4/jose4j-0.9.4.jar:/Users/jeffreiffers/.m2/repository/org/scala-lang/modules/scala-collection-compat_2.13/2.10.0/scala-collection-compat_2.13-2.10.0.jar:/Users/jeffreiffers/.m2/repository/org/scala-lang/modules/scala-java8-compat_2.13/1.0.2/scala-java8-compat_2.13-1.0.2.jar:/Users/jeffreiffers/.m2/repository/org/scala-lang/scala-reflect/2.13.15/scala-reflect-2.13.15.jar:/Users/jeffreiffers/.m2/repository/com/typesafe/scala-logging/scala-logging_2.13/3.9.5/scala-logging_2.13-3.9.5.jar:/Users/jeffreiffers/.m2/repository/io/dropwizard/metrics/metrics-core/4.1.12.1/metrics-core-4.1.12.1.jar:/Users/jeffreiffers/.m2/repository/commons-cli/commons-cli/1.4/commons-cli-1.4.jar:/Users/jeffreiffers/.m2/repository/org/apache/kafka/kafka_2.13/3.9.1/kafka_2.13-3.9.1-test.jar:/Users/jeffreiffers/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.12.2/junit-jupiter-api-5.12.2.jar:/Users/jeffreiffers/.m2/repository/org/opentest4j/opentest4j/1.3.0/opentest4j-1.3.0.jar:/Users/jeffreiffers/.m2/repository/org/junit/platform/junit-platform-commons/1.12.2/junit-platform-commons-1.12.2.jar:/Users/jeffreiffers/.m2/repository/org/apiguardian/apiguardian-api/1.1.2/apiguardian-api-1.1.2.jar:/Users/jeffreiffers/.m2/repository/org/junit/platform/junit-platform-launcher/1.12.2/junit-platform-launcher-1.12.2.jar:/Users/jeffreiffers/.m2/repository/org/junit/platform/junit-platform-engine/1.12.2/junit-platform-engine-1.12.2.jar:/Users/jeffreiffers/.m2/repository/org/testcontainers/junit-jupiter/1.19.3/junit-jupiter-1.19.3.jar:/Users/jeffreiffers/.m2/repository/org/testcontainers/testcontainers/1.19.3/testcontainers-1.19.3.jar:/Users/jeffreiffers/.m2/repository/org/rnorth/duct-tape/duct-tape/1.0.8/duct-tape-1.0.8.jar:/Users/jeffreiffers/.m2/repository/com/github/docker-java/docker-java-api/3.3.4/docker-java-api-3.3.4.jar:/Users/jeffreiffers/.m2/repository/com/github/docker-java/docker-java-transport-zerodep/3.3.4/docker-java-transport-zerodep-3.3.4.jar:/Users/jeffreiffers/.m2/repository/com/github/docker-java/docker-java-transport/3.3.4/docker-java-transport-3.3.4.jar:/Users/jeffreiffers/.m2/repository/net/java/dev/jna/jna/5.13.0/jna-5.13.0.jar:/Users/jeffreiffers/.m2/repository/org/testcontainers/postgresql/1.19.3/postgresql-1.19.3.jar:/Users/jeffreiffers/.m2/repository/org/testcontainers/jdbc/1.19.3/jdbc-1.19.3.jar:/Users/jeffreiffers/.m2/repository/org/testcontainers/database-commons/1.19.3/database-commons-1.19.3.jar:/Users/jeffreiffers/.m2/repository/org/testcontainers/kafka/1.19.3/kafka-1.19.3.jar:/Users/jeffreiffers/.m2/repository/org/mockito/mockito-core/5.17.0/mockito-core-5.17.0.jar:/Users/jeffreiffers/.m2/repository/net/bytebuddy/byte-buddy/1.17.7/byte-buddy-1.17.7.jar:/Users/jeffreiffers/.m2/repository/net/bytebuddy/byte-buddy-agent/1.17.7/byte-buddy-agent-1.17.7.jar:/Users/jeffreiffers/.m2/repository/org/objenesis/objenesis/3.3/objenesis-3.3.jar:/Users/jeffreiffers/.m2/repository/org/mockito/mockito-junit-jupiter/5.17.0/mockito-junit-jupiter-5.17.0.jar:/Users/jeffreiffers/.m2/repository/org/mockito/kotlin/mockito-kotlin/5.4.0/mockito-kotlin-5.4.0.jar:/Users/jeffreiffers/.m2/repository/io/mockk/mockk-jvm/1.13.8/mockk-jvm-1.13.8.jar:/Users/jeffreiffers/.m2/repository/io/mockk/mockk-dsl-jvm/1.13.8/mockk-dsl-jvm-1.13.8.jar:/Users/jeffreiffers/.m2/repository/io/mockk/mockk-agent-jvm/1.13.8/mockk-agent-jvm-1.13.8.jar:/Users/jeffreiffers/.m2/repository/io/mockk/mockk-agent-api-jvm/1.13.8/mockk-agent-api-jvm-1.13.8.jar:/Users/jeffreiffers/.m2/repository/io/mockk/mockk-core-jvm/1.13.8/mockk-core-jvm-1.13.8.jar:/Users/jeffreiffers/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib-common/1.9.10/kotlin-stdlib-common-1.9.10.jar:/Users/jeffreiffers/.m2/repository/junit/junit/4.13.2/junit-4.13.2.jar:/Users/jeffreiffers/.m2/repository/org/hamcrest/hamcrest-core/3.0/hamcrest-core-3.0.jar:/Users/jeffreiffers/.m2/repository/org/jetbrains/kotlinx/kotlinx-coroutines-core/1.8.1/kotlinx-coroutines-core-1.8.1.jar:/Users/jeffreiffers/.m2/repository/org/jetbrains/kotlinx/kotlinx-coroutines-core-jvm/1.8.1/kotlinx-coroutines-core-jvm-1.8.1.jar:/Users/jeffreiffers/.m2/repository/com/ninja-squad/springmockk/3.0.1/springmockk-3.0.1.jar:/Users/jeffreiffers/.m2/repository/io/mockk/mockk/1.10.2/mockk-1.10.2.jar:/Users/jeffreiffers/.m2/repository/io/mockk/mockk-common/1.10.2/mockk-common-1.10.2.jar:/Users/jeffreiffers/.m2/repository/io/mockk/mockk-dsl/1.10.2/mockk-dsl-1.10.2.jar:/Users/jeffreiffers/.m2/repository/org/springframework/security/spring-security-test/6.5.5/spring-security-test-6.5.5.jar:"/>
    <property name="java.vm.vendor" value="Oracle Corporation"/>
    <property name="sun.arch.data.model" value="64"/>
    <property name="java.vendor.url" value="https://java.oracle.com/"/>
    <property name="user.timezone" value="Europe/Oslo"/>
    <property name="org.jboss.logging.provider" value="slf4j"/>
    <property name="os.name" value="Mac OS X"/>
    <property name="java.vm.specification.version" value="22"/>
    <property name="APPLICATION_NAME" value="fdk-resource-service"/>
    <property name="sun.java.launcher" value="SUN_STANDARD"/>
    <property name="user.country" value="US"/>
    <property name="sun.boot.library.path" value="/Users/jeffreiffers/.sdkman/candidates/java/22-open/lib"/>
    <property name="sun.java.command" value="/Users/jeffreiffers/Digdir/fdk-resource-service/target/surefire/surefirebooter-20251024182926422_3.jar /Users/jeffreiffers/Digdir/fdk-resource-service/target/surefire 2025-10-24T18-29-26_204-jvmRun1 surefire-20251024182926422_1tmp surefire_0-20251024182926422_2tmp"/>
    <property name="jdk.debug" value="release"/>
    <property name="surefire.test.class.path" value="/Users/jeffreiffers/Digdir/fdk-resource-service/target/test-classes:/Users/jeffreiffers/Digdir/fdk-resource-service/target/classes:/Users/jeffreiffers/.m2/repository/org/springframework/boot/spring-boot-starter-web/3.5.6/spring-boot-starter-web-3.5.6.jar:/Users/jeffreiffers/.m2/repository/org/springframework/boot/spring-boot-starter/3.5.6/spring-boot-starter-3.5.6.jar:/Users/jeffreiffers/.m2/repository/org/springframework/boot/spring-boot/3.5.6/spring-boot-3.5.6.jar:/Users/jeffreiffers/.m2/repository/org/springframework/boot/spring-boot-autoconfigure/3.5.6/spring-boot-autoconfigure-3.5.6.jar:/Users/jeffreiffers/.m2/repository/org/springframework/boot/spring-boot-starter-logging/3.5.6/spring-boot-starter-logging-3.5.6.jar:/Users/jeffreiffers/.m2/repository/org/apache/logging/log4j/log4j-to-slf4j/2.24.3/log4j-to-slf4j-2.24.3.jar:/Users/jeffreiffers/.m2/repository/org/apache/logging/log4j/log4j-api/2.24.3/log4j-api-2.24.3.jar:/Users/jeffreiffers/.m2/repository/org/slf4j/jul-to-slf4j/2.0.17/jul-to-slf4j-2.0.17.jar:/Users/jeffreiffers/.m2/repository/jakarta/annotation/jakarta.annotation-api/2.1.1/jakarta.annotation-api-2.1.1.jar:/Users/jeffreiffers/.m2/repository/org/yaml/snakeyaml/2.4/snakeyaml-2.4.jar:/Users/jeffreiffers/.m2/repository/org/springframework/boot/spring-boot-starter-json/3.5.6/spring-boot-starter-json-3.5.6.jar:/Users/jeffreiffers/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jdk8/2.19.2/jackson-datatype-jdk8-2.19.2.jar:/Users/jeffreiffers/.m2/repository/com/fasterxml/jackson/module/jackson-module-parameter-names/2.19.2/jackson-module-parameter-names-2.19.2.jar:/Users/jeffreiffers/.m2/repository/org/springframework/boot/spring-boot-starter-tomcat/3.5.6/spring-boot-starter-tomcat-3.5.6.jar:/Users/jeffreiffers/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/10.1.46/tomcat-embed-core-10.1.46.jar:/Users/jeffreiffers/.m2/repository/org/apache/tomcat/embed/tomcat-embed-websocket/10.1.46/tomcat-embed-websocket-10.1.46.jar:/Users/jeffreiffers/.m2/repository/org/springframework/spring-web/6.2.11/spring-web-6.2.11.jar:/Users/jeffreiffers/.m2/repository/org/springframework/spring-beans/6.2.11/spring-beans-6.2.11.jar:/Users/jeffreiffers/.m2/repository/org/springframework/spring-webmvc/6.2.11/spring-webmvc-6.2.11.jar:/Users/jeffreiffers/.m2/repository/org/springframework/spring-expression/6.2.11/spring-expression-6.2.11.jar:/Users/jeffreiffers/.m2/repository/org/springframework/boot/spring-boot-starter-data-jpa/3.5.6/spring-boot-starter-data-jpa-3.5.6.jar:/Users/jeffreiffers/.m2/repository/org/springframework/boot/spring-boot-starter-jdbc/3.5.6/spring-boot-starter-jdbc-3.5.6.jar:/Users/jeffreiffers/.m2/repository/com/zaxxer/HikariCP/6.3.3/HikariCP-6.3.3.jar:/Users/jeffreiffers/.m2/repository/org/springframework/spring-jdbc/6.2.11/spring-jdbc-6.2.11.jar:/Users/jeffreiffers/.m2/repository/org/hibernate/orm/hibernate-core/6.6.29.Final/hibernate-core-6.6.29.Final.jar:/Users/jeffreiffers/.m2/repository/jakarta/persistence/jakarta.persistence-api/3.1.0/jakarta.persistence-api-3.1.0.jar:/Users/jeffreiffers/.m2/repository/jakarta/transaction/jakarta.transaction-api/2.0.1/jakarta.transaction-api-2.0.1.jar:/Users/jeffreiffers/.m2/repository/org/jboss/logging/jboss-logging/3.6.1.Final/jboss-logging-3.6.1.Final.jar:/Users/jeffreiffers/.m2/repository/org/hibernate/common/hibernate-commons-annotations/7.0.3.Final/hibernate-commons-annotations-7.0.3.Final.jar:/Users/jeffreiffers/.m2/repository/io/smallrye/jandex/3.2.0/jandex-3.2.0.jar:/Users/jeffreiffers/.m2/repository/com/fasterxml/classmate/1.7.0/classmate-1.7.0.jar:/Users/jeffreiffers/.m2/repository/org/glassfish/jaxb/jaxb-runtime/4.0.5/jaxb-runtime-4.0.5.jar:/Users/jeffreiffers/.m2/repository/org/glassfish/jaxb/jaxb-core/4.0.5/jaxb-core-4.0.5.jar:/Users/jeffreiffers/.m2/repository/org/eclipse/angus/angus-activation/2.0.2/angus-activation-2.0.2.jar:/Users/jeffreiffers/.m2/repository/org/glassfish/jaxb/txw2/4.0.5/txw2-4.0.5.jar:/Users/jeffreiffers/.m2/repository/com/sun/istack/istack-commons-runtime/4.1.2/istack-commons-runtime-4.1.2.jar:/Users/jeffreiffers/.m2/repository/jakarta/inject/jakarta.inject-api/2.0.1/jakarta.inject-api-2.0.1.jar:/Users/jeffreiffers/.m2/repository/org/antlr/antlr4-runtime/4.13.0/antlr4-runtime-4.13.0.jar:/Users/jeffreiffers/.m2/repository/org/springframework/data/spring-data-jpa/3.5.4/spring-data-jpa-3.5.4.jar:/Users/jeffreiffers/.m2/repository/org/springframework/data/spring-data-commons/3.5.4/spring-data-commons-3.5.4.jar:/Users/jeffreiffers/.m2/repository/org/springframework/spring-orm/6.2.11/spring-orm-6.2.11.jar:/Users/jeffreiffers/.m2/repository/org/springframework/spring-aspects/6.2.11/spring-aspects-6.2.11.jar:/Users/jeffreiffers/.m2/repository/org/aspectj/aspectjweaver/1.9.24/aspectjweaver-1.9.24.jar:/Users/jeffreiffers/.m2/repository/org/springframework/boot/spring-boot-starter-validation/3.5.6/spring-boot-starter-validation-3.5.6.jar:/Users/jeffreiffers/.m2/repository/org/apache/tomcat/embed/tomcat-embed-el/10.1.46/tomcat-embed-el-10.1.46.jar:/Users/jeffreiffers/.m2/repository/org/hibernate/validator/hibernate-validator/8.0.3.Final/hibernate-validator-8.0.3.Final.jar:/Users/jeffreiffers/.m2/repository/jakarta/validation/jakarta.validation-api/3.0.2/jakarta.validation-api-3.0.2.jar:/Users/jeffreiffers/.m2/repository/org/springframework/boot/spring-boot-starter-actuator/3.5.6/spring-boot-starter-actuator-3.5.6.jar:/Users/jeffreiffers/.m2/repository/org/springframework/boot/spring-boot-actuator-autoconfigure/3.5.6/spring-boot-actuator-autoconfigure-3.5.6.jar:/Users/jeffreiffers/.m2/repository/org/springframework/boot/spring-boot-actuator/3.5.6/spring-boot-actuator-3.5.6.jar:/Users/jeffreiffers/.m2/repository/io/micrometer/micrometer-observation/1.15.4/micrometer-observation-1.15.4.jar:/Users/jeffreiffers/.m2/repository/io/micrometer/micrometer-commons/1.15.4/micrometer-commons-1.15.4.jar:/Users/jeffreiffers/.m2/repository/io/micrometer/micrometer-jakarta9/1.15.4/micrometer-jakarta9-1.15.4.jar:/Users/jeffreiffers/.m2/repository/io/micrometer/micrometer-core/1.15.4/micrometer-core-1.15.4.jar:/Users/jeffreiffers/.m2/repository/org/hdrhistogram/HdrHistogram/2.2.2/HdrHistogram-2.2.2.jar:/Users/jeffreiffers/.m2/repository/org/latencyutils/LatencyUtils/2.0.3/LatencyUtils-2.0.3.jar:/Users/jeffreiffers/.m2/repository/org/springframework/kafka/spring-kafka/3.3.10/spring-kafka-3.3.10.jar:/Users/jeffreiffers/.m2/repository/org/springframework/spring-context/6.2.11/spring-context-6.2.11.jar:/Users/jeffreiffers/.m2/repository/org/springframework/spring-messaging/6.2.11/spring-messaging-6.2.11.jar:/Users/jeffreiffers/.m2/repository/org/springframework/spring-tx/6.2.11/spring-tx-6.2.11.jar:/Users/jeffreiffers/.m2/repository/org/springframework/retry/spring-retry/2.0.12/spring-retry-2.0.12.jar:/Users/jeffreiffers/.m2/repository/org/springframework/boot/spring-boot-starter-security/3.5.6/spring-boot-starter-security-3.5.6.jar:/Users/jeffreiffers/.m2/repository/org/springframework/spring-aop/6.2.11/spring-aop-6.2.11.jar:/Users/jeffreiffers/.m2/repository/org/springframework/security/spring-security-config/6.5.5/spring-security-config-6.5.5.jar:/Users/jeffreiffers/.m2/repository/org/springframework/security/spring-security-web/6.5.5/spring-security-web-6.5.5.jar:/Users/jeffreiffers/.m2/repository/org/springframework/security/spring-security-oauth2-jose/6.5.5/spring-security-oauth2-jose-6.5.5.jar:/Users/jeffreiffers/.m2/repository/org/springframework/security/spring-security-core/6.5.5/spring-security-core-6.5.5.jar:/Users/jeffreiffers/.m2/repository/org/springframework/security/spring-security-crypto/6.5.5/spring-security-crypto-6.5.5.jar:/Users/jeffreiffers/.m2/repository/org/springframework/security/spring-security-oauth2-core/6.5.5/spring-security-oauth2-core-6.5.5.jar:/Users/jeffreiffers/.m2/repository/org/springframework/spring-core/6.2.11/spring-core-6.2.11.jar:/Users/jeffreiffers/.m2/repository/org/springframework/spring-jcl/6.2.11/spring-jcl-6.2.11.jar:/Users/jeffreiffers/.m2/repository/com/nimbusds/nimbus-jose-jwt/9.37.4/nimbus-jose-jwt-9.37.4.jar:/Users/jeffreiffers/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/Users/jeffreiffers/.m2/repository/org/springframework/security/spring-security-oauth2-resource-server/6.5.5/spring-security-oauth2-resource-server-6.5.5.jar:/Users/jeffreiffers/.m2/repository/org/postgresql/postgresql/42.7.7/postgresql-42.7.7.jar:/Users/jeffreiffers/.m2/repository/org/checkerframework/checker-qual/3.49.3/checker-qual-3.49.3.jar:/Users/jeffreiffers/.m2/repository/org/flywaydb/flyway-core/11.7.2/flyway-core-11.7.2.jar:/Users/jeffreiffers/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-toml/2.19.2/jackson-dataformat-toml-2.19.2.jar:/Users/jeffreiffers/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.19.2/jackson-datatype-jsr310-2.19.2.jar:/Users/jeffreiffers/.m2/repository/org/flywaydb/flyway-database-postgresql/11.7.2/flyway-database-postgresql-11.7.2.jar:/Users/jeffreiffers/.m2/repository/org/apache/avro/avro/1.12.1/avro-1.12.1.jar:/Users/jeffreiffers/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.19.2/jackson-core-2.19.2.jar:/Users/jeffreiffers/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.19.2/jackson-databind-2.19.2.jar:/Users/jeffreiffers/.m2/repository/org/apache/commons/commons-compress/1.28.0/commons-compress-1.28.0.jar:/Users/jeffreiffers/.m2/repository/commons-codec/commons-codec/1.18.0/commons-codec-1.18.0.jar:/Users/jeffreiffers/.m2/repository/commons-io/commons-io/2.20.0/commons-io-2.20.0.jar:/Users/jeffreiffers/.m2/repository/org/apache/commons/commons-lang3/3.17.0/commons-lang3-3.17.0.jar:/Users/jeffreiffers/.m2/repository/org/slf4j/slf4j-api/2.0.17/slf4j-api-2.0.17.jar:/Users/jeffreiffers/.m2/repository/org/apache/kafka/kafka-clients/3.9.1/kafka-clients-3.9.1.jar:/Users/jeffreiffers/.m2/repository/com/github/luben/zstd-jni/1.5.6-4/zstd-jni-1.5.6-4.jar:/Users/jeffreiffers/.m2/repository/org/lz4/lz4-java/1.8.0/lz4-java-1.8.0.jar:/Users/jeffreiffers/.m2/repository/org/xerial/snappy/snappy-java/1.1.10.5/snappy-java-1.1.10.5.jar:/Users/jeffreiffers/.m2/repository/io/confluent/kafka-avro-serializer/8.0.0/kafka-avro-serializer-8.0.0.jar:/Users/jeffreiffers/.m2/repository/io/confluent/kafka-schema-serializer/8.0.0/kafka-schema-serializer-8.0.0.jar:/Users/jeffreiffers/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-csv/2.19.2/jackson-dataformat-csv-2.19.2.jar:/Users/jeffreiffers/.m2/repository/io/confluent/kafka-schema-registry-client/8.0.0/kafka-schema-registry-client-8.0.0.jar:/Users/jeffreiffers/.m2/repository/io/swagger/core/v3/swagger-annotations/2.2.29/swagger-annotations-2.2.29.jar:/Users/jeffreiffers/.m2/repository/com/google/guava/guava/32.0.1-jre/guava-32.0.1-jre.jar:/Users/jeffreiffers/.m2/repository/com/google/guava/failureaccess/1.0.1/failureaccess-1.0.1.jar:/Users/jeffreiffers/.m2/repository/com/google/guava/listenablefuture/9999.0-empty-to-avoid-conflict-with-guava/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/Users/jeffreiffers/.m2/repository/com/google/code/findbugs/jsr305/3.0.2/jsr305-3.0.2.jar:/Users/jeffreiffers/.m2/repository/com/google/errorprone/error_prone_annotations/2.18.0/error_prone_annotations-2.18.0.jar:/Users/jeffreiffers/.m2/repository/com/google/j2objc/j2objc-annotations/2.8/j2objc-annotations-2.8.jar:/Users/jeffreiffers/.m2/repository/io/confluent/logredactor/1.0.13/logredactor-1.0.13.jar:/Users/jeffreiffers/.m2/repository/com/google/re2j/re2j/1.6/re2j-1.6.jar:/Users/jeffreiffers/.m2/repository/io/confluent/logredactor-metrics/1.0.13/logredactor-metrics-1.0.13.jar:/Users/jeffreiffers/.m2/repository/com/eclipsesource/minimal-json/minimal-json/0.9.5/minimal-json-0.9.5.jar:/Users/jeffreiffers/.m2/repository/io/confluent/common-utils/8.0.0/common-utils-8.0.0.jar:/Users/jeffreiffers/.m2/repository/com/fasterxml/jackson/module/jackson-module-kotlin/2.19.2/jackson-module-kotlin-2.19.2.jar:/Users/jeffreiffers/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.19.2/jackson-annotations-2.19.2.jar:/Users/jeffreiffers/.m2/repository/org/springdoc/springdoc-openapi-starter-webmvc-ui/2.8.13/springdoc-openapi-starter-webmvc-ui-2.8.13.jar:/Users/jeffreiffers/.m2/repository/org/springdoc/springdoc-openapi-starter-webmvc-api/2.8.13/springdoc-openapi-starter-webmvc-api-2.8.13.jar:/Users/jeffreiffers/.m2/repository/org/springdoc/springdoc-openapi-starter-common/2.8.13/springdoc-openapi-starter-common-2.8.13.jar:/Users/jeffreiffers/.m2/repository/io/swagger/core/v3/swagger-core-jakarta/2.2.36/swagger-core-jakarta-2.2.36.jar:/Users/jeffreiffers/.m2/repository/io/swagger/core/v3/swagger-annotations-jakarta/2.2.36/swagger-annotations-jakarta-2.2.36.jar:/Users/jeffreiffers/.m2/repository/io/swagger/core/v3/swagger-models-jakarta/2.2.36/swagger-models-jakarta-2.2.36.jar:/Users/jeffreiffers/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-yaml/2.19.2/jackson-dataformat-yaml-2.19.2.jar:/Users/jeffreiffers/.m2/repository/org/webjars/swagger-ui/5.28.1/swagger-ui-5.28.1.jar:/Users/jeffreiffers/.m2/repository/org/webjars/webjars-locator-lite/1.1.0/webjars-locator-lite-1.1.0.jar:/Users/jeffreiffers/.m2/repository/org/jspecify/jspecify/1.0.0/jspecify-1.0.0.jar:/Users/jeffreiffers/.m2/repository/io/github/resilience4j/resilience4j-spring-boot3/2.2.0/resilience4j-spring-boot3-2.2.0.jar:/Users/jeffreiffers/.m2/repository/io/github/resilience4j/resilience4j-spring6/2.2.0/resilience4j-spring6-2.2.0.jar:/Users/jeffreiffers/.m2/repository/io/github/resilience4j/resilience4j-annotations/2.2.0/resilience4j-annotations-2.2.0.jar:/Users/jeffreiffers/.m2/repository/io/github/resilience4j/resilience4j-consumer/2.2.0/resilience4j-consumer-2.2.0.jar:/Users/jeffreiffers/.m2/repository/io/github/resilience4j/resilience4j-circularbuffer/2.2.0/resilience4j-circularbuffer-2.2.0.jar:/Users/jeffreiffers/.m2/repository/io/github/resilience4j/resilience4j-framework-common/2.2.0/resilience4j-framework-common-2.2.0.jar:/Users/jeffreiffers/.m2/repository/io/github/resilience4j/resilience4j-micrometer/2.2.0/resilience4j-micrometer-2.2.0.jar:/Users/jeffreiffers/.m2/repository/io/github/resilience4j/resilience4j-reactor/2.2.0/resilience4j-reactor-2.2.0.jar:/Users/jeffreiffers/.m2/repository/io/projectreactor/reactor-core/3.7.11/reactor-core-3.7.11.jar:/Users/jeffreiffers/.m2/repository/org/reactivestreams/reactive-streams/1.0.4/reactive-streams-1.0.4.jar:/Users/jeffreiffers/.m2/repository/io/github/resilience4j/resilience4j-circuitbreaker/2.2.0/resilience4j-circuitbreaker-2.2.0.jar:/Users/jeffreiffers/.m2/repository/io/github/resilience4j/resilience4j-core/2.2.0/resilience4j-core-2.2.0.jar:/Users/jeffreiffers/.m2/repository/io/github/resilience4j/resilience4j-ratelimiter/2.2.0/resilience4j-ratelimiter-2.2.0.jar:/Users/jeffreiffers/.m2/repository/io/github/resilience4j/resilience4j-timelimiter/2.2.0/resilience4j-timelimiter-2.2.0.jar:/Users/jeffreiffers/.m2/repository/io/github/resilience4j/resilience4j-bulkhead/2.2.0/resilience4j-bulkhead-2.2.0.jar:/Users/jeffreiffers/.m2/repository/io/github/resilience4j/resilience4j-retry/2.2.0/resilience4j-retry-2.2.0.jar:/Users/jeffreiffers/.m2/repository/org/apache/jena/jena-rdfpatch/5.6.0/jena-rdfpatch-5.6.0.jar:/Users/jeffreiffers/.m2/repository/org/apache/jena/jena-arq/5.6.0/jena-arq-5.6.0.jar:/Users/jeffreiffers/.m2/repository/org/apache/jena/jena-core/5.6.0/jena-core-5.6.0.jar:/Users/jeffreiffers/.m2/repository/org/apache/jena/jena-base/5.6.0/jena-base-5.6.0.jar:/Users/jeffreiffers/.m2/repository/org/apache/commons/commons-csv/1.14.1/commons-csv-1.14.1.jar:/Users/jeffreiffers/.m2/repository/org/apache/commons/commons-collections4/4.5.0/commons-collections4-4.5.0.jar:/Users/jeffreiffers/.m2/repository/com/github/andrewoma/dexx/collection/0.7/collection-0.7.jar:/Users/jeffreiffers/.m2/repository/org/apache/jena/jena-iri3986/5.6.0/jena-iri3986-5.6.0.jar:/Users/jeffreiffers/.m2/repository/org/apache/jena/jena-iri/5.6.0/jena-iri-5.6.0.jar:/Users/jeffreiffers/.m2/repository/org/apache/jena/jena-langtag/5.6.0/jena-langtag-5.6.0.jar:/Users/jeffreiffers/.m2/repository/org/roaringbitmap/RoaringBitmap/1.3.0/RoaringBitmap-1.3.0.jar:/Users/jeffreiffers/.m2/repository/com/google/code/gson/gson/2.13.2/gson-2.13.2.jar:/Users/jeffreiffers/.m2/repository/org/slf4j/jcl-over-slf4j/2.0.17/jcl-over-slf4j-2.0.17.jar:/Users/jeffreiffers/.m2/repository/com/apicatalog/titanium-json-ld/1.7.0/titanium-json-ld-1.7.0.jar:/Users/jeffreiffers/.m2/repository/com/apicatalog/titanium-jcs/1.1.1/titanium-jcs-1.1.1.jar:/Users/jeffreiffers/.m2/repository/com/apicatalog/titanium-rdf-api/1.0.0/titanium-rdf-api-1.0.0.jar:/Users/jeffreiffers/.m2/repository/com/apicatalog/titanium-rdf-n-quads/1.0.2/titanium-rdf-n-quads-1.0.2.jar:/Users/jeffreiffers/.m2/repository/org/glassfish/jakarta.json/2.0.1/jakarta.json-2.0.1.jar:/Users/jeffreiffers/.m2/repository/com/google/protobuf/protobuf-java/4.32.1/protobuf-java-4.32.1.jar:/Users/jeffreiffers/.m2/repository/org/apache/thrift/libthrift/0.22.0/libthrift-0.22.0.jar:/Users/jeffreiffers/.m2/repository/org/apache/jena/jena-ontapi/5.6.0/jena-ontapi-5.6.0.jar:/Users/jeffreiffers/.m2/repository/org/apache/jena/jena-shacl/5.6.0/jena-shacl-5.6.0.jar:/Users/jeffreiffers/.m2/repository/org/apache/jena/jena-shex/5.6.0/jena-shex-5.6.0.jar:/Users/jeffreiffers/.m2/repository/org/apache/jena/jena-tdb1/5.6.0/jena-tdb1-5.6.0.jar:/Users/jeffreiffers/.m2/repository/org/apache/jena/jena-tdb2/5.6.0/jena-tdb2-5.6.0.jar:/Users/jeffreiffers/.m2/repository/org/apache/jena/jena-dboe-storage/5.6.0/jena-dboe-storage-5.6.0.jar:/Users/jeffreiffers/.m2/repository/org/apache/jena/jena-dboe-trans-data/5.6.0/jena-dboe-trans-data-5.6.0.jar:/Users/jeffreiffers/.m2/repository/org/apache/jena/jena-dboe-transaction/5.6.0/jena-dboe-transaction-5.6.0.jar:/Users/jeffreiffers/.m2/repository/org/apache/jena/jena-dboe-base/5.6.0/jena-dboe-base-5.6.0.jar:/Users/jeffreiffers/.m2/repository/org/apache/jena/jena-dboe-index/5.6.0/jena-dboe-index-5.6.0.jar:/Users/jeffreiffers/.m2/repository/org/apache/jena/jena-rdfconnection/5.6.0/jena-rdfconnection-5.6.0.jar:/Users/jeffreiffers/.m2/repository/org/jetbrains/kotlin/kotlin-reflect/2.2.20/kotlin-reflect-2.2.20.jar:/Users/jeffreiffers/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib/2.2.20/kotlin-stdlib-2.2.20.jar:/Users/jeffreiffers/.m2/repository/org/jetbrains/annotations/13.0/annotations-13.0.jar:/Users/jeffreiffers/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib-jdk8/2.2.20/kotlin-stdlib-jdk8-2.2.20.jar:/Users/jeffreiffers/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib-jdk7/2.2.20/kotlin-stdlib-jdk7-2.2.20.jar:/Users/jeffreiffers/.m2/repository/org/springframework/boot/spring-boot-starter-test/3.5.6/spring-boot-starter-test-3.5.6.jar:/Users/jeffreiffers/.m2/repository/org/springframework/boot/spring-boot-test/3.5.6/spring-boot-test-3.5.6.jar:/Users/jeffreiffers/.m2/repository/org/springframework/boot/spring-boot-test-autoconfigure/3.5.6/spring-boot-test-autoconfigure-3.5.6.jar:/Users/jeffreiffers/.m2/repository/com/jayway/jsonpath/json-path/2.9.0/json-path-2.9.0.jar:/Users/jeffreiffers/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/4.0.2/jakarta.xml.bind-api-4.0.2.jar:/Users/jeffreiffers/.m2/repository/jakarta/activation/jakarta.activation-api/2.1.4/jakarta.activation-api-2.1.4.jar:/Users/jeffreiffers/.m2/repository/net/minidev/json-smart/2.5.2/json-smart-2.5.2.jar:/Users/jeffreiffers/.m2/repository/net/minidev/accessors-smart/2.5.2/accessors-smart-2.5.2.jar:/Users/jeffreiffers/.m2/repository/org/ow2/asm/asm/9.7.1/asm-9.7.1.jar:/Users/jeffreiffers/.m2/repository/org/assertj/assertj-core/3.27.4/assertj-core-3.27.4.jar:/Users/jeffreiffers/.m2/repository/org/awaitility/awaitility/4.2.2/awaitility-4.2.2.jar:/Users/jeffreiffers/.m2/repository/org/hamcrest/hamcrest/3.0/hamcrest-3.0.jar:/Users/jeffreiffers/.m2/repository/org/junit/jupiter/junit-jupiter/5.12.2/junit-jupiter-5.12.2.jar:/Users/jeffreiffers/.m2/repository/org/junit/jupiter/junit-jupiter-params/5.12.2/junit-jupiter-params-5.12.2.jar:/Users/jeffreiffers/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.12.2/junit-jupiter-engine-5.12.2.jar:/Users/jeffreiffers/.m2/repository/org/skyscreamer/jsonassert/1.5.3/jsonassert-1.5.3.jar:/Users/jeffreiffers/.m2/repository/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar:/Users/jeffreiffers/.m2/repository/org/springframework/spring-test/6.2.11/spring-test-6.2.11.jar:/Users/jeffreiffers/.m2/repository/org/xmlunit/xmlunit-core/2.10.4/xmlunit-core-2.10.4.jar:/Users/jeffreiffers/.m2/repository/org/springframework/kafka/spring-kafka-test/3.3.10/spring-kafka-test-3.3.10.jar:/Users/jeffreiffers/.m2/repository/org/apache/zookeeper/zookeeper/3.8.4/zookeeper-3.8.4.jar:/Users/jeffreiffers/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.8.4/zookeeper-jute-3.8.4.jar:/Users/jeffreiffers/.m2/repository/org/apache/yetus/audience-annotations/0.12.0/audience-annotations-0.12.0.jar:/Users/jeffreiffers/.m2/repository/io/netty/netty-handler/4.1.127.Final/netty-handler-4.1.127.Final.jar:/Users/jeffreiffers/.m2/repository/io/netty/netty-common/4.1.127.Final/netty-common-4.1.127.Final.jar:/Users/jeffreiffers/.m2/repository/io/netty/netty-resolver/4.1.127.Final/netty-resolver-4.1.127.Final.jar:/Users/jeffreiffers/.m2/repository/io/netty/netty-buffer/4.1.127.Final/netty-buffer-4.1.127.Final.jar:/Users/jeffreiffers/.m2/repository/io/netty/netty-transport/4.1.127.Final/netty-transport-4.1.127.Final.jar:/Users/jeffreiffers/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.127.Final/netty-transport-native-unix-common-4.1.127.Final.jar:/Users/jeffreiffers/.m2/repository/io/netty/netty-codec/4.1.127.Final/netty-codec-4.1.127.Final.jar:/Users/jeffreiffers/.m2/repository/io/netty/netty-transport-native-epoll/4.1.127.Final/netty-transport-native-epoll-4.1.127.Final.jar:/Users/jeffreiffers/.m2/repository/io/netty/netty-transport-classes-epoll/4.1.127.Final/netty-transport-classes-epoll-4.1.127.Final.jar:/Users/jeffreiffers/.m2/repository/ch/qos/logback/logback-core/1.5.18/logback-core-1.5.18.jar:/Users/jeffreiffers/.m2/repository/ch/qos/logback/logback-classic/1.5.18/logback-classic-1.5.18.jar:/Users/jeffreiffers/.m2/repository/org/apache/kafka/kafka-clients/3.9.1/kafka-clients-3.9.1-test.jar:/Users/jeffreiffers/.m2/repository/org/apache/kafka/kafka-server/3.9.1/kafka-server-3.9.1.jar:/Users/jeffreiffers/.m2/repository/org/apache/kafka/kafka-storage/3.9.1/kafka-storage-3.9.1.jar:/Users/jeffreiffers/.m2/repository/com/github/ben-manes/caffeine/caffeine/3.2.2/caffeine-3.2.2.jar:/Users/jeffreiffers/.m2/repository/org/apache/kafka/kafka-group-coordinator/3.9.1/kafka-group-coordinator-3.9.1.jar:/Users/jeffreiffers/.m2/repository/org/apache/kafka/kafka-transaction-coordinator/3.9.1/kafka-transaction-coordinator-3.9.1.jar:/Users/jeffreiffers/.m2/repository/org/apache/kafka/kafka-raft/3.9.1/kafka-raft-3.9.1.jar:/Users/jeffreiffers/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/Users/jeffreiffers/.m2/repository/org/apache/kafka/kafka-metadata/3.9.1/kafka-metadata-3.9.1.jar:/Users/jeffreiffers/.m2/repository/org/apache/kafka/kafka-server-common/3.9.1/kafka-server-common-3.9.1.jar:/Users/jeffreiffers/.m2/repository/net/sf/jopt-simple/jopt-simple/5.0.4/jopt-simple-5.0.4.jar:/Users/jeffreiffers/.m2/repository/org/pcollections/pcollections/4.0.1/pcollections-4.0.1.jar:/Users/jeffreiffers/.m2/repository/org/apache/kafka/kafka-server-common/3.9.1/kafka-server-common-3.9.1-test.jar:/Users/jeffreiffers/.m2/repository/org/apache/kafka/kafka-streams-test-utils/3.9.1/kafka-streams-test-utils-3.9.1.jar:/Users/jeffreiffers/.m2/repository/org/apache/kafka/kafka-streams/3.9.1/kafka-streams-3.9.1.jar:/Users/jeffreiffers/.m2/repository/org/rocksdb/rocksdbjni/7.9.2/rocksdbjni-7.9.2.jar:/Users/jeffreiffers/.m2/repository/org/apache/kafka/kafka_2.13/3.9.1/kafka_2.13-3.9.1.jar:/Users/jeffreiffers/.m2/repository/org/scala-lang/scala-library/2.13.15/scala-library-2.13.15.jar:/Users/jeffreiffers/.m2/repository/org/apache/kafka/kafka-group-coordinator-api/3.9.1/kafka-group-coordinator-api-3.9.1.jar:/Users/jeffreiffers/.m2/repository/org/apache/kafka/kafka-storage-api/3.9.1/kafka-storage-api-3.9.1.jar:/Users/jeffreiffers/.m2/repository/org/apache/kafka/kafka-tools-api/3.9.1/kafka-tools-api-3.9.1.jar:/Users/jeffreiffers/.m2/repository/net/sourceforge/argparse4j/argparse4j/0.7.0/argparse4j-0.7.0.jar:/Users/jeffreiffers/.m2/repository/commons-validator/commons-validator/1.7/commons-validator-1.7.jar:/Users/jeffreiffers/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/Users/jeffreiffers/.m2/repository/commons-digester/commons-digester/2.1/commons-digester-2.1.jar:/Users/jeffreiffers/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/Users/jeffreiffers/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.13/2.19.2/jackson-module-scala_2.13-2.19.2.jar:/Users/jeffreiffers/.m2/repository/com/thoughtworks/paranamer/paranamer/2.8.3/paranamer-2.8.3.jar:/Users/jeffreiffers/.m2/repository/org/bitbucket/b_c/jose4j/0.9.4/jose4j-0.9.4.jar:/Users/jeffreiffers/.m2/repository/org/scala-lang/modules/scala-collection-compat_2.13/2.10.0/scala-collection-compat_2.13-2.10.0.jar:/Users/jeffreiffers/.m2/repository/org/scala-lang/modules/scala-java8-compat_2.13/1.0.2/scala-java8-compat_2.13-1.0.2.jar:/Users/jeffreiffers/.m2/repository/org/scala-lang/scala-reflect/2.13.15/scala-reflect-2.13.15.jar:/Users/jeffreiffers/.m2/repository/com/typesafe/scala-logging/scala-logging_2.13/3.9.5/scala-logging_2.13-3.9.5.jar:/Users/jeffreiffers/.m2/repository/io/dropwizard/metrics/metrics-core/4.1.12.1/metrics-core-4.1.12.1.jar:/Users/jeffreiffers/.m2/repository/commons-cli/commons-cli/1.4/commons-cli-1.4.jar:/Users/jeffreiffers/.m2/repository/org/apache/kafka/kafka_2.13/3.9.1/kafka_2.13-3.9.1-test.jar:/Users/jeffreiffers/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.12.2/junit-jupiter-api-5.12.2.jar:/Users/jeffreiffers/.m2/repository/org/opentest4j/opentest4j/1.3.0/opentest4j-1.3.0.jar:/Users/jeffreiffers/.m2/repository/org/junit/platform/junit-platform-commons/1.12.2/junit-platform-commons-1.12.2.jar:/Users/jeffreiffers/.m2/repository/org/apiguardian/apiguardian-api/1.1.2/apiguardian-api-1.1.2.jar:/Users/jeffreiffers/.m2/repository/org/junit/platform/junit-platform-launcher/1.12.2/junit-platform-launcher-1.12.2.jar:/Users/jeffreiffers/.m2/repository/org/junit/platform/junit-platform-engine/1.12.2/junit-platform-engine-1.12.2.jar:/Users/jeffreiffers/.m2/repository/org/testcontainers/junit-jupiter/1.19.3/junit-jupiter-1.19.3.jar:/Users/jeffreiffers/.m2/repository/org/testcontainers/testcontainers/1.19.3/testcontainers-1.19.3.jar:/Users/jeffreiffers/.m2/repository/org/rnorth/duct-tape/duct-tape/1.0.8/duct-tape-1.0.8.jar:/Users/jeffreiffers/.m2/repository/com/github/docker-java/docker-java-api/3.3.4/docker-java-api-3.3.4.jar:/Users/jeffreiffers/.m2/repository/com/github/docker-java/docker-java-transport-zerodep/3.3.4/docker-java-transport-zerodep-3.3.4.jar:/Users/jeffreiffers/.m2/repository/com/github/docker-java/docker-java-transport/3.3.4/docker-java-transport-3.3.4.jar:/Users/jeffreiffers/.m2/repository/net/java/dev/jna/jna/5.13.0/jna-5.13.0.jar:/Users/jeffreiffers/.m2/repository/org/testcontainers/postgresql/1.19.3/postgresql-1.19.3.jar:/Users/jeffreiffers/.m2/repository/org/testcontainers/jdbc/1.19.3/jdbc-1.19.3.jar:/Users/jeffreiffers/.m2/repository/org/testcontainers/database-commons/1.19.3/database-commons-1.19.3.jar:/Users/jeffreiffers/.m2/repository/org/testcontainers/kafka/1.19.3/kafka-1.19.3.jar:/Users/jeffreiffers/.m2/repository/org/mockito/mockito-core/5.17.0/mockito-core-5.17.0.jar:/Users/jeffreiffers/.m2/repository/net/bytebuddy/byte-buddy/1.17.7/byte-buddy-1.17.7.jar:/Users/jeffreiffers/.m2/repository/net/bytebuddy/byte-buddy-agent/1.17.7/byte-buddy-agent-1.17.7.jar:/Users/jeffreiffers/.m2/repository/org/objenesis/objenesis/3.3/objenesis-3.3.jar:/Users/jeffreiffers/.m2/repository/org/mockito/mockito-junit-jupiter/5.17.0/mockito-junit-jupiter-5.17.0.jar:/Users/jeffreiffers/.m2/repository/org/mockito/kotlin/mockito-kotlin/5.4.0/mockito-kotlin-5.4.0.jar:/Users/jeffreiffers/.m2/repository/io/mockk/mockk-jvm/1.13.8/mockk-jvm-1.13.8.jar:/Users/jeffreiffers/.m2/repository/io/mockk/mockk-dsl-jvm/1.13.8/mockk-dsl-jvm-1.13.8.jar:/Users/jeffreiffers/.m2/repository/io/mockk/mockk-agent-jvm/1.13.8/mockk-agent-jvm-1.13.8.jar:/Users/jeffreiffers/.m2/repository/io/mockk/mockk-agent-api-jvm/1.13.8/mockk-agent-api-jvm-1.13.8.jar:/Users/jeffreiffers/.m2/repository/io/mockk/mockk-core-jvm/1.13.8/mockk-core-jvm-1.13.8.jar:/Users/jeffreiffers/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib-common/1.9.10/kotlin-stdlib-common-1.9.10.jar:/Users/jeffreiffers/.m2/repository/junit/junit/4.13.2/junit-4.13.2.jar:/Users/jeffreiffers/.m2/repository/org/hamcrest/hamcrest-core/3.0/hamcrest-core-3.0.jar:/Users/jeffreiffers/.m2/repository/org/jetbrains/kotlinx/kotlinx-coroutines-core/1.8.1/kotlinx-coroutines-core-1.8.1.jar:/Users/jeffreiffers/.m2/repository/org/jetbrains/kotlinx/kotlinx-coroutines-core-jvm/1.8.1/kotlinx-coroutines-core-jvm-1.8.1.jar:/Users/jeffreiffers/.m2/repository/com/ninja-squad/springmockk/3.0.1/springmockk-3.0.1.jar:/Users/jeffreiffers/.m2/repository/io/mockk/mockk/1.10.2/mockk-1.10.2.jar:/Users/jeffreiffers/.m2/repository/io/mockk/mockk-common/1.10.2/mockk-common-1.10.2.jar:/Users/jeffreiffers/.m2/repository/io/mockk/mockk-dsl/1.10.2/mockk-dsl-1.10.2.jar:/Users/jeffreiffers/.m2/repository/org/springframework/security/spring-security-test/6.5.5/spring-security-test-6.5.5.jar:"/>
    <property name="test" value="KafkaIntegrationTest"/>
    <property name="sun.cpu.endian" value="little"/>
    <property name="user.home" value="/Users/jeffreiffers"/>
    <property name="user.language" value="en"/>
    <property name="java.specification.vendor" value="Oracle Corporation"/>
    <property name="java.version.date" value="2024-03-19"/>
    <property name="java.home" value="/Users/jeffreiffers/.sdkman/candidates/java/22-open"/>
    <property name="file.separator" value="/"/>
    <property name="basedir" value="/Users/jeffreiffers/Digdir/fdk-resource-service"/>
    <property name="java.vm.compressedOopsMode" value="Zero based"/>
    <property name="line.separator" value="&#10;"/>
    <property name="java.vm.specification.vendor" value="Oracle Corporation"/>
    <property name="java.specification.name" value="Java Platform API Specification"/>
    <property name="FILE_LOG_CHARSET" value="UTF-8"/>
    <property name="java.awt.headless" value="true"/>
    <property name="apple.awt.application.name" value="ForkedBooter"/>
    <property name="surefire.real.class.path" value="/Users/jeffreiffers/Digdir/fdk-resource-service/target/surefire/surefirebooter-20251024182926422_3.jar"/>
    <property name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers"/>
    <property name="java.runtime.version" value="22+36-2370"/>
    <property name="user.name" value="jeffreiffers"/>
    <property name="stdout.encoding" value="UTF-8"/>
    <property name="path.separator" value=":"/>
    <property name="os.version" value="26.0.1"/>
    <property name="java.runtime.name" value="OpenJDK Runtime Environment"/>
    <property name="file.encoding" value="UTF-8"/>
    <property name="java.vm.name" value="OpenJDK 64-Bit Server VM"/>
    <property name="localRepository" value="/Users/jeffreiffers/.m2/repository"/>
    <property name="java.vendor.url.bug" value="https://bugreport.java.com/bugreport/"/>
    <property name="java.io.tmpdir" value="/var/folders/rs/vzd084gn28v_v9jvlh38mkgm0000gn/T/"/>
    <property name="com.zaxxer.hikari.pool_number" value="1"/>
    <property name="java.version" value="22"/>
    <property name="user.dir" value="/Users/jeffreiffers/Digdir/fdk-resource-service"/>
    <property name="os.arch" value="aarch64"/>
    <property name="java.vm.specification.name" value="Java Virtual Machine Specification"/>
    <property name="PID" value="34429"/>
    <property name="CONSOLE_LOG_CHARSET" value="UTF-8"/>
    <property name="native.encoding" value="UTF-8"/>
    <property name="java.library.path" value="/Users/jeffreiffers/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:."/>
    <property name="java.vm.info" value="mixed mode, sharing"/>
    <property name="stderr.encoding" value="UTF-8"/>
    <property name="java.vendor" value="Oracle Corporation"/>
    <property name="java.vm.version" value="22+36-2370"/>
    <property name="sun.io.unicode.encoding" value="UnicodeBig"/>
    <property name="java.class.version" value="66.0"/>
    <property name="LOGGED_APPLICATION_NAME" value="[fdk-resource-service] "/>
  </properties>
  <testcase name="should handle multiple resource types via Kafka" classname="no.fdk.resourceservice.integration.KafkaIntegrationTest" time="10.674">
    <system-out><![CDATA[18:29:27.071 [main] INFO org.springframework.test.context.support.AnnotationConfigContextLoaderUtils -- Could not detect default configuration classes for test class [no.fdk.resourceservice.integration.BaseIntegrationTest]: BaseIntegrationTest does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
18:29:27.296 [main] INFO org.springframework.boot.test.context.SpringBootTestContextBootstrapper -- Found @SpringBootConfiguration no.fdk.resourceservice.FdkResourceServiceApplication for test class no.fdk.resourceservice.integration.KafkaIntegrationTest
18:29:27.511 [main] INFO org.testcontainers.images.PullPolicy -- Image pull policy will be performed by: DefaultPullPolicy()
18:29:27.513 [main] INFO org.testcontainers.utility.ImageNameSubstitutor -- Image name substitution will be performed by: DefaultImageNameSubstitutor (composite of 'ConfigurationFileImageNameSubstitutor' and 'PrefixingImageNameSubstitutor')
18:29:27.628 [main] INFO org.testcontainers.dockerclient.DockerClientProviderStrategy -- Loaded org.testcontainers.dockerclient.UnixSocketClientProviderStrategy from ~/.testcontainers.properties, will try it first
18:29:27.812 [main] INFO org.testcontainers.dockerclient.DockerClientProviderStrategy -- Found Docker environment with local Unix socket (unix:///var/run/docker.sock)
18:29:27.813 [main] INFO org.testcontainers.DockerClientFactory -- Docker host IP address is localhost
18:29:27.844 [main] INFO org.testcontainers.DockerClientFactory -- Connected to docker: 
  Server Version: 5.4.2
  API Version: 1.41
  Operating System: fedora
  Total Memory: 3616 MB
18:29:27.890 [main] INFO tc.testcontainers/ryuk:0.5.1 -- Creating container for image: testcontainers/ryuk:0.5.1
18:29:27.893 [main] INFO org.testcontainers.utility.RegistryAuthLocator -- Failure when attempting to lookup auth config. Please ignore if you don't have images in an authenticated registry. Details: (dockerImageName: testcontainers/ryuk:0.5.1, configFile: /Users/jeffreiffers/.docker/config.json, configEnv: DOCKER_AUTH_CONFIG). Falling back to docker-java default behaviour. Exception message: Status 404: No config supplied. Checked in order: /Users/jeffreiffers/.docker/config.json (file not found), DOCKER_AUTH_CONFIG (not set)
18:29:27.927 [main] INFO tc.testcontainers/ryuk:0.5.1 -- Container testcontainers/ryuk:0.5.1 is starting: ee9b8ee10cd45794285fc14adf7dcfeb076fca7cfe2ed4cc3ac7baf32f2e3909
18:29:28.063 [main] INFO tc.testcontainers/ryuk:0.5.1 -- Container testcontainers/ryuk:0.5.1 started in PT0.172703S
18:29:28.067 [main] INFO org.testcontainers.utility.RyukResourceReaper -- Ryuk started - will monitor and terminate Testcontainers containers on JVM exit
18:29:28.067 [main] INFO org.testcontainers.DockerClientFactory -- Checking the system...
18:29:28.067 [main] INFO org.testcontainers.DockerClientFactory --  Docker server version should be at least 1.6.0
18:29:28.073 [main] INFO tc.confluentinc/cp-kafka:7.4.0 -- Creating container for image: confluentinc/cp-kafka:7.4.0
18:29:28.077 [main] WARN tc.confluentinc/cp-kafka:7.4.0 -- Reuse was requested but the environment does not support the reuse of containers
To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/jeffreiffers/.testcontainers.properties
18:29:28.091 [main] INFO tc.confluentinc/cp-kafka:7.4.0 -- Container confluentinc/cp-kafka:7.4.0 is starting: b2679386b302c3d5ae3520190f68a2bcdcf1af68fd37f9eac7a15e73eced7284
18:29:30.358 [main] INFO tc.confluentinc/cp-kafka:7.4.0 -- Container confluentinc/cp-kafka:7.4.0 started in PT2.285646S
18:29:30.366 [main] INFO tc.postgres:15 -- Creating container for image: postgres:15
18:29:30.367 [main] WARN tc.postgres:15 -- Reuse was requested but the environment does not support the reuse of containers
To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/jeffreiffers/.testcontainers.properties
18:29:30.379 [main] INFO tc.postgres:15 -- Container postgres:15 is starting: 56fd79fb22f2556edce3315c6beb78f18a72a77a94b27cb863acc71a3a2f5dc6
18:29:31.369 [main] INFO tc.postgres:15 -- Container postgres:15 started in PT1.002561S
18:29:31.370 [main] INFO tc.postgres:15 -- Container is started (JDBC URL: jdbc:postgresql://localhost:45801/fdk_resource_service?loggerLevel=OFF)
18:29:31.387 [main] INFO tc.confluentinc/cp-schema-registry:7.4.0 -- Creating container for image: confluentinc/cp-schema-registry:7.4.0
18:29:31.388 [main] WARN tc.confluentinc/cp-schema-registry:7.4.0 -- Reuse was requested but the environment does not support the reuse of containers
To enable reuse of containers, you must set 'testcontainers.reuse.enable=true' in a file located at /Users/jeffreiffers/.testcontainers.properties
18:29:31.416 [main] INFO tc.confluentinc/cp-schema-registry:7.4.0 -- Container confluentinc/cp-schema-registry:7.4.0 is starting: b2cf47fcdc530e444e408750009f7e5dcce038169dcac5f1bebd4208315c84f3
18:29:31.533 [main] INFO org.testcontainers.containers.wait.strategy.HttpWaitStrategy -- /inspiring_mcnulty: Waiting for 60 seconds for URL: http://localhost:43977/subjects (where port 43977 maps to container port 8081)
18:29:35.755 [main] INFO tc.confluentinc/cp-schema-registry:7.4.0 -- Container confluentinc/cp-schema-registry:7.4.0 started in PT4.368238S

  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/

 :: Spring Boot ::                (v3.5.6)

2025-10-24T18:29:35.981+02:00  INFO 34429 --- [fdk-resource-service] [           main] n.f.r.integration.KafkaIntegrationTest   : Starting KafkaIntegrationTest using Java 22 with PID 34429 (started by jeffreiffers in /Users/jeffreiffers/Digdir/fdk-resource-service)
2025-10-24T18:29:35.982+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] n.f.r.integration.KafkaIntegrationTest   : Running with Spring Boot v3.5.6, Spring v6.2.11
2025-10-24T18:29:35.982+02:00  INFO 34429 --- [fdk-resource-service] [           main] n.f.r.integration.KafkaIntegrationTest   : The following 1 profile is active: "test"
2025-10-24T18:29:36.551+02:00  INFO 34429 --- [fdk-resource-service] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2025-10-24T18:29:36.618+02:00  INFO 34429 --- [fdk-resource-service] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 62 ms. Found 1 JPA repository interface.
2025-10-24T18:29:37.067+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.hibernate.jpa.internal.util.LogHelper  : HHH000204: Processing PersistenceUnitInfo [name: default]
2025-10-24T18:29:37.096+02:00  INFO 34429 --- [fdk-resource-service] [           main] org.hibernate.Version                    : HHH000412: Hibernate ORM core version 6.6.29.Final
2025-10-24T18:29:37.112+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.h.c.internal.RegionFactoryInitiator    : HHH000026: Second-level cache disabled
2025-10-24T18:29:37.237+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.s.o.j.p.SpringPersistenceUnitInfo      : No LoadTimeWeaver setup: ignoring JPA class transformer
2025-10-24T18:29:37.250+02:00  INFO 34429 --- [fdk-resource-service] [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
2025-10-24T18:29:37.344+02:00  INFO 34429 --- [fdk-resource-service] [           main] com.zaxxer.hikari.pool.HikariPool        : HikariPool-1 - Added connection org.postgresql.jdbc.PgConnection@594793d1
2025-10-24T18:29:37.345+02:00  INFO 34429 --- [fdk-resource-service] [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Start completed.
2025-10-24T18:29:37.364+02:00  WARN 34429 --- [fdk-resource-service] [           main] org.hibernate.orm.deprecation            : HHH90000025: PostgreSQLDialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
2025-10-24T18:29:37.375+02:00  INFO 34429 --- [fdk-resource-service] [           main] org.hibernate.orm.connections.pooling    : HHH10001005: Database info:
	Database JDBC URL [Connecting through datasource 'HikariDataSource (HikariPool-1)']
	Database driver: undefined/unknown
	Database version: 15.14
	Autocommit mode: undefined/unknown
	Isolation level: undefined/unknown
	Minimum pool size: undefined/unknown
	Maximum pool size: undefined/unknown
2025-10-24T18:29:37.837+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.h.e.t.j.p.i.JtaPlatformInitiator       : HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
2025-10-24T18:29:37.843+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] org.hibernate.SQL                        : 
    set client_min_messages = WARNING
Hibernate: 
    set client_min_messages = WARNING
2025-10-24T18:29:37.845+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] org.hibernate.SQL                        : 
    drop table if exists resources cascade
Hibernate: 
    drop table if exists resources cascade
2025-10-24T18:29:37.847+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] org.hibernate.SQL                        : 
    create table resources (
        deleted boolean not null,
        created_at timestamp(6) with time zone not null,
        timestamp bigint not null,
        updated_at timestamp(6) with time zone not null,
        resource_type varchar(50) not null,
        id varchar(255) not null,
        resource_json jsonb,
        resource_json_ld jsonb,
        primary key (id)
    )
Hibernate: 
    create table resources (
        deleted boolean not null,
        created_at timestamp(6) with time zone not null,
        timestamp bigint not null,
        updated_at timestamp(6) with time zone not null,
        resource_type varchar(50) not null,
        id varchar(255) not null,
        resource_json jsonb,
        resource_json_ld jsonb,
        primary key (id)
    )
2025-10-24T18:29:37.854+02:00  INFO 34429 --- [fdk-resource-service] [           main] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
2025-10-24T18:29:37.952+02:00  WARN 34429 --- [fdk-resource-service] [           main] JpaBaseConfiguration$JpaWebConfiguration : spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
2025-10-24T18:29:38.408+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.s.d.j.r.query.QueryEnhancerFactory     : Hibernate is in classpath; If applicable, HQL parser will be used.
2025-10-24T18:29:39.077+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.s.b.a.e.web.EndpointLinksResolver      : Exposing 3 endpoints beneath base path '/actuator'
2025-10-24T18:29:39.088+02:00  INFO 34429 --- [fdk-resource-service] [           main] n.f.r.integration.KafkaIntegrationTest   : Started KafkaIntegrationTest in 3.296 seconds (process running for 12.503)
2025-10-24T18:29:39.253+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] KafkaListenerAnnotationBeanPostProcessor : No retry topic configuration found for topics [information-model-events]
2025-10-24T18:29:39.304+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [PLAINTEXT://localhost:42839]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-test-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

2025-10-24T18:29:39.323+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-10-24T18:29:39.336+02:00  INFO 34429 --- [fdk-resource-service] [           main] i.c.k.s.KafkaAvroDeserializerConfig      : KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.schema.id.deserializer = class io.confluent.kafka.serializers.schema.id.DualSchemaIdDeserializer
	key.schema.id.serializer = class io.confluent.kafka.serializers.schema.id.PrefixSchemaIdSerializer
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.retries = 3
	max.schemas.per.subject = 1000
	normalize.schemas = false
	propagate.schema.tags = false
	proxy.host = 
	proxy.port = -1
	retries.max.wait.ms = 20000
	retries.wait.ms = 1000
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:43977]
	schema.registry.url.randomize = false
	specific.avro.key.type = null
	specific.avro.reader = false
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.schema.id.deserializer = class io.confluent.kafka.serializers.schema.id.DualSchemaIdDeserializer
	value.schema.id.serializer = class io.confluent.kafka.serializers.schema.id.PrefixSchemaIdSerializer
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2025-10-24T18:29:39.427+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.clients.consumer.ConsumerConfig    : These configurations '[schema.registry.url, specific.avro.reader]' were supplied but are not used yet.
2025-10-24T18:29:39.428+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-10-24T18:29:39.428+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-10-24T18:29:39.428+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1761323379427
2025-10-24T18:29:39.431+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-test-group-1, groupId=test-group] Subscribed to topic(s): information-model-events
2025-10-24T18:29:39.436+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] KafkaListenerAnnotationBeanPostProcessor : No retry topic configuration found for topics [concept-events]
2025-10-24T18:29:39.436+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:29:39.437+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [PLAINTEXT://localhost:42839]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-test-group-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

2025-10-24T18:29:39.437+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-10-24T18:29:39.437+02:00  INFO 34429 --- [fdk-resource-service] [           main] i.c.k.s.KafkaAvroDeserializerConfig      : KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.schema.id.deserializer = class io.confluent.kafka.serializers.schema.id.DualSchemaIdDeserializer
	key.schema.id.serializer = class io.confluent.kafka.serializers.schema.id.PrefixSchemaIdSerializer
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.retries = 3
	max.schemas.per.subject = 1000
	normalize.schemas = false
	propagate.schema.tags = false
	proxy.host = 
	proxy.port = -1
	retries.max.wait.ms = 20000
	retries.wait.ms = 1000
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:43977]
	schema.registry.url.randomize = false
	specific.avro.key.type = null
	specific.avro.reader = false
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.schema.id.deserializer = class io.confluent.kafka.serializers.schema.id.DualSchemaIdDeserializer
	value.schema.id.serializer = class io.confluent.kafka.serializers.schema.id.PrefixSchemaIdSerializer
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2025-10-24T18:29:39.441+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.clients.consumer.ConsumerConfig    : These configurations '[schema.registry.url, specific.avro.reader]' were supplied but are not used yet.
2025-10-24T18:29:39.441+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-10-24T18:29:39.441+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-10-24T18:29:39.441+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1761323379441
2025-10-24T18:29:39.443+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-test-group-2, groupId=test-group] Subscribed to topic(s): concept-events
2025-10-24T18:29:39.444+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:29:39.444+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] KafkaListenerAnnotationBeanPostProcessor : No retry topic configuration found for topics [rdf-parse-events]
2025-10-24T18:29:39.445+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [PLAINTEXT://localhost:42839]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-test-group-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

2025-10-24T18:29:39.445+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-10-24T18:29:39.445+02:00  INFO 34429 --- [fdk-resource-service] [           main] i.c.k.s.KafkaAvroDeserializerConfig      : KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.schema.id.deserializer = class io.confluent.kafka.serializers.schema.id.DualSchemaIdDeserializer
	key.schema.id.serializer = class io.confluent.kafka.serializers.schema.id.PrefixSchemaIdSerializer
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.retries = 3
	max.schemas.per.subject = 1000
	normalize.schemas = false
	propagate.schema.tags = false
	proxy.host = 
	proxy.port = -1
	retries.max.wait.ms = 20000
	retries.wait.ms = 1000
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:43977]
	schema.registry.url.randomize = false
	specific.avro.key.type = null
	specific.avro.reader = false
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.schema.id.deserializer = class io.confluent.kafka.serializers.schema.id.DualSchemaIdDeserializer
	value.schema.id.serializer = class io.confluent.kafka.serializers.schema.id.PrefixSchemaIdSerializer
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2025-10-24T18:29:39.449+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.clients.consumer.ConsumerConfig    : These configurations '[schema.registry.url, specific.avro.reader]' were supplied but are not used yet.
2025-10-24T18:29:39.449+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-10-24T18:29:39.449+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-10-24T18:29:39.449+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1761323379449
2025-10-24T18:29:39.451+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-test-group-3, groupId=test-group] Subscribed to topic(s): rdf-parse-events
2025-10-24T18:29:39.452+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:29:39.452+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] KafkaListenerAnnotationBeanPostProcessor : No retry topic configuration found for topics [dataset-events]
2025-10-24T18:29:39.453+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [PLAINTEXT://localhost:42839]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-test-group-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

2025-10-24T18:29:39.453+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-10-24T18:29:39.453+02:00  INFO 34429 --- [fdk-resource-service] [           main] i.c.k.s.KafkaAvroDeserializerConfig      : KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.schema.id.deserializer = class io.confluent.kafka.serializers.schema.id.DualSchemaIdDeserializer
	key.schema.id.serializer = class io.confluent.kafka.serializers.schema.id.PrefixSchemaIdSerializer
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.retries = 3
	max.schemas.per.subject = 1000
	normalize.schemas = false
	propagate.schema.tags = false
	proxy.host = 
	proxy.port = -1
	retries.max.wait.ms = 20000
	retries.wait.ms = 1000
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:43977]
	schema.registry.url.randomize = false
	specific.avro.key.type = null
	specific.avro.reader = false
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.schema.id.deserializer = class io.confluent.kafka.serializers.schema.id.DualSchemaIdDeserializer
	value.schema.id.serializer = class io.confluent.kafka.serializers.schema.id.PrefixSchemaIdSerializer
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2025-10-24T18:29:39.456+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.clients.consumer.ConsumerConfig    : These configurations '[schema.registry.url, specific.avro.reader]' were supplied but are not used yet.
2025-10-24T18:29:39.456+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-10-24T18:29:39.456+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-10-24T18:29:39.456+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1761323379456
2025-10-24T18:29:39.458+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-test-group-4, groupId=test-group] Subscribed to topic(s): dataset-events
2025-10-24T18:29:39.459+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:29:39.459+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] KafkaListenerAnnotationBeanPostProcessor : No retry topic configuration found for topics [data-service-events]
2025-10-24T18:29:39.460+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [PLAINTEXT://localhost:42839]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-test-group-5
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

2025-10-24T18:29:39.461+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-10-24T18:29:39.461+02:00  INFO 34429 --- [fdk-resource-service] [           main] i.c.k.s.KafkaAvroDeserializerConfig      : KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.schema.id.deserializer = class io.confluent.kafka.serializers.schema.id.DualSchemaIdDeserializer
	key.schema.id.serializer = class io.confluent.kafka.serializers.schema.id.PrefixSchemaIdSerializer
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.retries = 3
	max.schemas.per.subject = 1000
	normalize.schemas = false
	propagate.schema.tags = false
	proxy.host = 
	proxy.port = -1
	retries.max.wait.ms = 20000
	retries.wait.ms = 1000
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:43977]
	schema.registry.url.randomize = false
	specific.avro.key.type = null
	specific.avro.reader = false
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.schema.id.deserializer = class io.confluent.kafka.serializers.schema.id.DualSchemaIdDeserializer
	value.schema.id.serializer = class io.confluent.kafka.serializers.schema.id.PrefixSchemaIdSerializer
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2025-10-24T18:29:39.464+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.clients.consumer.ConsumerConfig    : These configurations '[schema.registry.url, specific.avro.reader]' were supplied but are not used yet.
2025-10-24T18:29:39.464+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-10-24T18:29:39.464+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-10-24T18:29:39.464+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1761323379464
2025-10-24T18:29:39.465+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-test-group-5, groupId=test-group] Subscribed to topic(s): data-service-events
2025-10-24T18:29:39.466+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:29:39.466+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] KafkaListenerAnnotationBeanPostProcessor : No retry topic configuration found for topics [service-events]
2025-10-24T18:29:39.467+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [PLAINTEXT://localhost:42839]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-test-group-6
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

2025-10-24T18:29:39.467+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-10-24T18:29:39.467+02:00  INFO 34429 --- [fdk-resource-service] [           main] i.c.k.s.KafkaAvroDeserializerConfig      : KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.schema.id.deserializer = class io.confluent.kafka.serializers.schema.id.DualSchemaIdDeserializer
	key.schema.id.serializer = class io.confluent.kafka.serializers.schema.id.PrefixSchemaIdSerializer
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.retries = 3
	max.schemas.per.subject = 1000
	normalize.schemas = false
	propagate.schema.tags = false
	proxy.host = 
	proxy.port = -1
	retries.max.wait.ms = 20000
	retries.wait.ms = 1000
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:43977]
	schema.registry.url.randomize = false
	specific.avro.key.type = null
	specific.avro.reader = false
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.schema.id.deserializer = class io.confluent.kafka.serializers.schema.id.DualSchemaIdDeserializer
	value.schema.id.serializer = class io.confluent.kafka.serializers.schema.id.PrefixSchemaIdSerializer
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2025-10-24T18:29:39.470+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.clients.consumer.ConsumerConfig    : These configurations '[schema.registry.url, specific.avro.reader]' were supplied but are not used yet.
2025-10-24T18:29:39.470+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-10-24T18:29:39.470+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-10-24T18:29:39.470+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1761323379470
2025-10-24T18:29:39.472+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-test-group-6, groupId=test-group] Subscribed to topic(s): service-events
2025-10-24T18:29:39.472+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:29:39.472+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] KafkaListenerAnnotationBeanPostProcessor : No retry topic configuration found for topics [event-events]
2025-10-24T18:29:39.473+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [PLAINTEXT://localhost:42839]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-test-group-7
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

2025-10-24T18:29:39.473+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-10-24T18:29:39.473+02:00  INFO 34429 --- [fdk-resource-service] [           main] i.c.k.s.KafkaAvroDeserializerConfig      : KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.schema.id.deserializer = class io.confluent.kafka.serializers.schema.id.DualSchemaIdDeserializer
	key.schema.id.serializer = class io.confluent.kafka.serializers.schema.id.PrefixSchemaIdSerializer
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.retries = 3
	max.schemas.per.subject = 1000
	normalize.schemas = false
	propagate.schema.tags = false
	proxy.host = 
	proxy.port = -1
	retries.max.wait.ms = 20000
	retries.wait.ms = 1000
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:43977]
	schema.registry.url.randomize = false
	specific.avro.key.type = null
	specific.avro.reader = false
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.schema.id.deserializer = class io.confluent.kafka.serializers.schema.id.DualSchemaIdDeserializer
	value.schema.id.serializer = class io.confluent.kafka.serializers.schema.id.PrefixSchemaIdSerializer
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2025-10-24T18:29:39.476+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.clients.consumer.ConsumerConfig    : These configurations '[schema.registry.url, specific.avro.reader]' were supplied but are not used yet.
2025-10-24T18:29:39.476+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-10-24T18:29:39.476+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-10-24T18:29:39.476+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1761323379476
2025-10-24T18:29:39.478+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-test-group-7, groupId=test-group] Subscribed to topic(s): event-events
2025-10-24T18:29:39.478+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#6-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:29:39.479+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] KafkaListenerAnnotationBeanPostProcessor : 7 @KafkaListener methods processed on bean 'kafkaConsumer': {public void no.fdk.resourceservice.kafka.KafkaConsumer.handleInformationModelEvent(org.apache.kafka.clients.consumer.ConsumerRecord,org.springframework.kafka.support.Acknowledgment,java.lang.String,int,long)=[@org.springframework.kafka.annotation.KafkaListener(topicPattern="", beanRef="__listener", containerFactory="", contentTypeConverter="", topics={"${app.kafka.topics.information-model}"}, groupId="", batch="", clientIdPrefix="", topicPartitions={}, splitIterables=true, concurrency="", autoStartup="", filter="", containerGroup="", idIsGroup=true, errorHandler="", containerPostProcessor="", id="", properties={}, info="")], public void no.fdk.resourceservice.kafka.KafkaConsumer.handleConceptEvent(org.apache.kafka.clients.consumer.ConsumerRecord,org.springframework.kafka.support.Acknowledgment,java.lang.String,int,long)=[@org.springframework.kafka.annotation.KafkaListener(topicPattern="", beanRef="__listener", containerFactory="", contentTypeConverter="", topics={"${app.kafka.topics.concept}"}, groupId="", batch="", clientIdPrefix="", topicPartitions={}, splitIterables=true, concurrency="", autoStartup="", filter="", containerGroup="", idIsGroup=true, errorHandler="", containerPostProcessor="", id="", properties={}, info="")], public void no.fdk.resourceservice.kafka.KafkaConsumer.handleRdfParseEvent(org.apache.kafka.clients.consumer.ConsumerRecord,org.springframework.kafka.support.Acknowledgment,java.lang.String,int,long)=[@org.springframework.kafka.annotation.KafkaListener(topicPattern="", beanRef="__listener", containerFactory="", contentTypeConverter="", topics={"${app.kafka.topics.rdf-parse}"}, groupId="", batch="", clientIdPrefix="", topicPartitions={}, splitIterables=true, concurrency="", autoStartup="", filter="", containerGroup="", idIsGroup=true, errorHandler="", containerPostProcessor="", id="", properties={}, info="")], public void no.fdk.resourceservice.kafka.KafkaConsumer.handleDatasetEvent(org.apache.kafka.clients.consumer.ConsumerRecord,org.springframework.kafka.support.Acknowledgment,java.lang.String,int,long)=[@org.springframework.kafka.annotation.KafkaListener(topicPattern="", beanRef="__listener", containerFactory="", contentTypeConverter="", topics={"${app.kafka.topics.dataset}"}, groupId="", batch="", clientIdPrefix="", topicPartitions={}, splitIterables=true, concurrency="", autoStartup="", filter="", containerGroup="", idIsGroup=true, errorHandler="", containerPostProcessor="", id="", properties={}, info="")], public void no.fdk.resourceservice.kafka.KafkaConsumer.handleDataServiceEvent(org.apache.kafka.clients.consumer.ConsumerRecord,org.springframework.kafka.support.Acknowledgment,java.lang.String,int,long)=[@org.springframework.kafka.annotation.KafkaListener(topicPattern="", beanRef="__listener", containerFactory="", contentTypeConverter="", topics={"${app.kafka.topics.data-service}"}, groupId="", batch="", clientIdPrefix="", topicPartitions={}, splitIterables=true, concurrency="", autoStartup="", filter="", containerGroup="", idIsGroup=true, errorHandler="", containerPostProcessor="", id="", properties={}, info="")], public void no.fdk.resourceservice.kafka.KafkaConsumer.handleServiceEvent(org.apache.kafka.clients.consumer.ConsumerRecord,org.springframework.kafka.support.Acknowledgment,java.lang.String,int,long)=[@org.springframework.kafka.annotation.KafkaListener(topicPattern="", beanRef="__listener", containerFactory="", contentTypeConverter="", topics={"${app.kafka.topics.service}"}, groupId="", batch="", clientIdPrefix="", topicPartitions={}, splitIterables=true, concurrency="", autoStartup="", filter="", containerGroup="", idIsGroup=true, errorHandler="", containerPostProcessor="", id="", properties={}, info="")], public void no.fdk.resourceservice.kafka.KafkaConsumer.handleEventEvent(org.apache.kafka.clients.consumer.ConsumerRecord,org.springframework.kafka.support.Acknowledgment,java.lang.String,int,long)=[@org.springframework.kafka.annotation.KafkaListener(topicPattern="", beanRef="__listener", containerFactory="", contentTypeConverter="", topics={"${app.kafka.topics.event}"}, groupId="", batch="", clientIdPrefix="", topicPartitions={}, splitIterables=true, concurrency="", autoStartup="", filter="", containerGroup="", idIsGroup=true, errorHandler="", containerPostProcessor="", id="", properties={}, info="")]}
2025-10-24T18:29:39.613+02:00  WARN 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-test-group-5, groupId=test-group] The metadata response from the cluster reported a recoverable issue with correlation id 3 : {data-service-events=LEADER_NOT_AVAILABLE}
2025-10-24T18:29:39.614+02:00  WARN 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-test-group-6, groupId=test-group] The metadata response from the cluster reported a recoverable issue with correlation id 3 : {service-events=LEADER_NOT_AVAILABLE}
2025-10-24T18:29:39.613+02:00  WARN 34429 --- [fdk-resource-service] [ntainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-test-group-1, groupId=test-group] The metadata response from the cluster reported a recoverable issue with correlation id 3 : {information-model-events=LEADER_NOT_AVAILABLE}
2025-10-24T18:29:39.614+02:00  WARN 34429 --- [fdk-resource-service] [ntainer#6-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-test-group-7, groupId=test-group] The metadata response from the cluster reported a recoverable issue with correlation id 3 : {event-events=LEADER_NOT_AVAILABLE}
2025-10-24T18:29:39.614+02:00  WARN 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-test-group-4, groupId=test-group] The metadata response from the cluster reported a recoverable issue with correlation id 3 : {dataset-events=LEADER_NOT_AVAILABLE}
2025-10-24T18:29:39.621+02:00  WARN 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-test-group-2, groupId=test-group] The metadata response from the cluster reported a recoverable issue with correlation id 3 : {concept-events=LEADER_NOT_AVAILABLE}
2025-10-24T18:29:39.621+02:00  WARN 34429 --- [fdk-resource-service] [ntainer#2-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-test-group-3, groupId=test-group] The metadata response from the cluster reported a recoverable issue with correlation id 3 : {rdf-parse-events=LEADER_NOT_AVAILABLE}
2025-10-24T18:29:39.622+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-test-group-2, groupId=test-group] Cluster ID: BiwIzKnYQGKuWBEG8w9bVw
2025-10-24T18:29:39.622+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-test-group-6, groupId=test-group] Cluster ID: BiwIzKnYQGKuWBEG8w9bVw
2025-10-24T18:29:39.622+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#2-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-test-group-3, groupId=test-group] Cluster ID: BiwIzKnYQGKuWBEG8w9bVw
2025-10-24T18:29:39.622+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-test-group-5, groupId=test-group] Cluster ID: BiwIzKnYQGKuWBEG8w9bVw
2025-10-24T18:29:39.622+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#6-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-test-group-7, groupId=test-group] Cluster ID: BiwIzKnYQGKuWBEG8w9bVw
2025-10-24T18:29:39.622+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-test-group-4, groupId=test-group] Cluster ID: BiwIzKnYQGKuWBEG8w9bVw
2025-10-24T18:29:39.622+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-test-group-1, groupId=test-group] Cluster ID: BiwIzKnYQGKuWBEG8w9bVw
2025-10-24T18:29:39.623+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-2, groupId=test-group] Discovered group coordinator localhost:42839 (id: 2147483646 rack: null)
2025-10-24T18:29:39.623+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-7, groupId=test-group] Discovered group coordinator localhost:42839 (id: 2147483646 rack: null)
2025-10-24T18:29:39.623+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-3, groupId=test-group] Discovered group coordinator localhost:42839 (id: 2147483646 rack: null)
2025-10-24T18:29:39.623+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-4, groupId=test-group] Discovered group coordinator localhost:42839 (id: 2147483646 rack: null)
2025-10-24T18:29:39.623+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-1, groupId=test-group] Discovered group coordinator localhost:42839 (id: 2147483646 rack: null)
2025-10-24T18:29:39.623+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-5, groupId=test-group] Discovered group coordinator localhost:42839 (id: 2147483646 rack: null)
2025-10-24T18:29:39.623+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-6, groupId=test-group] Discovered group coordinator localhost:42839 (id: 2147483646 rack: null)
2025-10-24T18:29:39.624+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-4, groupId=test-group] (Re-)joining group
2025-10-24T18:29:39.626+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-5, groupId=test-group] (Re-)joining group
2025-10-24T18:29:39.626+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-6, groupId=test-group] (Re-)joining group
2025-10-24T18:29:39.626+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-7, groupId=test-group] (Re-)joining group
2025-10-24T18:29:39.626+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-3, groupId=test-group] (Re-)joining group
2025-10-24T18:29:39.626+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-2, groupId=test-group] (Re-)joining group
2025-10-24T18:29:39.626+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-1, groupId=test-group] (Re-)joining group
2025-10-24T18:29:39.639+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-1, groupId=test-group] Request joining group due to: need to re-join with the given member-id: consumer-test-group-1-cf6eeb9d-7953-4efa-950e-880ea3834cc8
2025-10-24T18:29:39.639+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-6, groupId=test-group] Request joining group due to: need to re-join with the given member-id: consumer-test-group-6-8ba584f0-d935-4829-a665-005ec7983b4a
2025-10-24T18:29:39.639+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-5, groupId=test-group] Request joining group due to: need to re-join with the given member-id: consumer-test-group-5-11d19ea5-3247-4ab1-a002-2f9649be5b5a
2025-10-24T18:29:39.640+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-1, groupId=test-group] (Re-)joining group
2025-10-24T18:29:39.640+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-5, groupId=test-group] (Re-)joining group
2025-10-24T18:29:39.640+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-6, groupId=test-group] (Re-)joining group
2025-10-24T18:29:39.640+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-7, groupId=test-group] Request joining group due to: need to re-join with the given member-id: consumer-test-group-7-aa3e9458-5f99-44c3-8b2d-b7f8d08aae1b
2025-10-24T18:29:39.640+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-2, groupId=test-group] Request joining group due to: need to re-join with the given member-id: consumer-test-group-2-10108748-0aec-4c84-a991-9efdae717310
2025-10-24T18:29:39.640+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-4, groupId=test-group] Request joining group due to: need to re-join with the given member-id: consumer-test-group-4-bb92af65-ebd1-47bd-9d64-252ba9696404
2025-10-24T18:29:39.640+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-7, groupId=test-group] (Re-)joining group
2025-10-24T18:29:39.640+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-2, groupId=test-group] (Re-)joining group
2025-10-24T18:29:39.640+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-4, groupId=test-group] (Re-)joining group
2025-10-24T18:29:39.642+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-3, groupId=test-group] Request joining group due to: need to re-join with the given member-id: consumer-test-group-3-9e3e6526-7e3f-4317-b991-5d2468f8eb17
2025-10-24T18:29:39.643+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-3, groupId=test-group] (Re-)joining group
2025-10-24T18:29:39.651+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-7, groupId=test-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-test-group-7-aa3e9458-5f99-44c3-8b2d-b7f8d08aae1b', protocol='range'}
2025-10-24T18:29:39.651+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-6, groupId=test-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-test-group-6-8ba584f0-d935-4829-a665-005ec7983b4a', protocol='range'}
2025-10-24T18:29:39.652+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-1, groupId=test-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-test-group-1-cf6eeb9d-7953-4efa-950e-880ea3834cc8', protocol='range'}
2025-10-24T18:29:39.654+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-5, groupId=test-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-test-group-5-11d19ea5-3247-4ab1-a002-2f9649be5b5a', protocol='range'}
2025-10-24T18:29:39.654+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-3, groupId=test-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-test-group-3-9e3e6526-7e3f-4317-b991-5d2468f8eb17', protocol='range'}
2025-10-24T18:29:39.655+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-4, groupId=test-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-test-group-4-bb92af65-ebd1-47bd-9d64-252ba9696404', protocol='range'}
2025-10-24T18:29:39.656+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-2, groupId=test-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-test-group-2-10108748-0aec-4c84-a991-9efdae717310', protocol='range'}
2025-10-24T18:29:39.670+02:00  WARN 34429 --- [fdk-resource-service] [ntainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-test-group-1, groupId=test-group] The metadata response from the cluster reported a recoverable issue with correlation id 11 : {concept-events=LEADER_NOT_AVAILABLE, rdf-parse-events=LEADER_NOT_AVAILABLE, event-events=LEADER_NOT_AVAILABLE, service-events=LEADER_NOT_AVAILABLE, dataset-events=LEADER_NOT_AVAILABLE, information-model-events=LEADER_NOT_AVAILABLE, data-service-events=LEADER_NOT_AVAILABLE}
2025-10-24T18:29:39.672+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-1, groupId=test-group] Finished assignment for group at generation 1: {consumer-test-group-7-aa3e9458-5f99-44c3-8b2d-b7f8d08aae1b=Assignment(partitions=[]), consumer-test-group-6-8ba584f0-d935-4829-a665-005ec7983b4a=Assignment(partitions=[]), consumer-test-group-1-cf6eeb9d-7953-4efa-950e-880ea3834cc8=Assignment(partitions=[]), consumer-test-group-5-11d19ea5-3247-4ab1-a002-2f9649be5b5a=Assignment(partitions=[]), consumer-test-group-3-9e3e6526-7e3f-4317-b991-5d2468f8eb17=Assignment(partitions=[]), consumer-test-group-4-bb92af65-ebd1-47bd-9d64-252ba9696404=Assignment(partitions=[]), consumer-test-group-2-10108748-0aec-4c84-a991-9efdae717310=Assignment(partitions=[])}
2025-10-24T18:29:39.675+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-7, groupId=test-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-test-group-7-aa3e9458-5f99-44c3-8b2d-b7f8d08aae1b', protocol='range'}
2025-10-24T18:29:39.676+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-7, groupId=test-group] Notifying assignor about the new Assignment(partitions=[])
2025-10-24T18:29:39.676+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#6-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-test-group-7, groupId=test-group] Adding newly assigned partitions: 
2025-10-24T18:29:39.677+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#6-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : test-group: partitions assigned: []
2025-10-24T18:29:39.677+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-6, groupId=test-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-test-group-6-8ba584f0-d935-4829-a665-005ec7983b4a', protocol='range'}
2025-10-24T18:29:39.678+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-6, groupId=test-group] Notifying assignor about the new Assignment(partitions=[])
2025-10-24T18:29:39.678+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-test-group-6, groupId=test-group] Adding newly assigned partitions: 
2025-10-24T18:29:39.678+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : test-group: partitions assigned: []
2025-10-24T18:29:39.679+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-4, groupId=test-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-test-group-4-bb92af65-ebd1-47bd-9d64-252ba9696404', protocol='range'}
2025-10-24T18:29:39.679+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-3, groupId=test-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-test-group-3-9e3e6526-7e3f-4317-b991-5d2468f8eb17', protocol='range'}
2025-10-24T18:29:39.679+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-5, groupId=test-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-test-group-5-11d19ea5-3247-4ab1-a002-2f9649be5b5a', protocol='range'}
2025-10-24T18:29:39.679+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-4, groupId=test-group] Notifying assignor about the new Assignment(partitions=[])
2025-10-24T18:29:39.679+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-test-group-4, groupId=test-group] Adding newly assigned partitions: 
2025-10-24T18:29:39.679+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : test-group: partitions assigned: []
2025-10-24T18:29:39.679+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-3, groupId=test-group] Notifying assignor about the new Assignment(partitions=[])
2025-10-24T18:29:39.679+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-2, groupId=test-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-test-group-2-10108748-0aec-4c84-a991-9efdae717310', protocol='range'}
2025-10-24T18:29:39.679+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-5, groupId=test-group] Notifying assignor about the new Assignment(partitions=[])
2025-10-24T18:29:39.679+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-2, groupId=test-group] Notifying assignor about the new Assignment(partitions=[])
2025-10-24T18:29:39.679+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#2-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-test-group-3, groupId=test-group] Adding newly assigned partitions: 
2025-10-24T18:29:39.679+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-test-group-5, groupId=test-group] Adding newly assigned partitions: 
2025-10-24T18:29:39.679+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-test-group-2, groupId=test-group] Adding newly assigned partitions: 
2025-10-24T18:29:39.679+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : test-group: partitions assigned: []
2025-10-24T18:29:39.679+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : test-group: partitions assigned: []
2025-10-24T18:29:39.679+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : test-group: partitions assigned: []
2025-10-24T18:29:39.680+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-1, groupId=test-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-test-group-1-cf6eeb9d-7953-4efa-950e-880ea3834cc8', protocol='range'}
2025-10-24T18:29:39.681+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-1, groupId=test-group] Notifying assignor about the new Assignment(partitions=[])
2025-10-24T18:29:39.681+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#0-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-test-group-1, groupId=test-group] Adding newly assigned partitions: 
2025-10-24T18:29:39.681+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : test-group: partitions assigned: []
2025-10-24T18:29:39.784+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-1, groupId=test-group] Request joining group due to: cached metadata has changed from (version3: {concept-events=[], event-events=[], rdf-parse-events=[], service-events=[], dataset-events=[], information-model-events=[], data-service-events=[]}) at the beginning of the rebalance to (version4: {concept-events=[NO_RACKS], event-events=[NO_RACKS], rdf-parse-events=[NO_RACKS], service-events=[NO_RACKS], dataset-events=[NO_RACKS], information-model-events=[NO_RACKS], data-service-events=[NO_RACKS]})
2025-10-24T18:29:39.785+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#0-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-test-group-1, groupId=test-group] Revoke previously assigned partitions 
2025-10-24T18:29:39.785+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : test-group: partitions revoked: []
2025-10-24T18:29:39.785+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:29:39.785+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-1, groupId=test-group] (Re-)joining group
2025-10-24T18:29:39.809+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [PLAINTEXT://localhost:42839]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2025-10-24T18:29:39.810+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-10-24T18:29:39.813+02:00  INFO 34429 --- [fdk-resource-service] [           main] i.c.k.s.KafkaAvroSerializerConfig        : KafkaAvroSerializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.remove.java.properties = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.schema.id.deserializer = class io.confluent.kafka.serializers.schema.id.DualSchemaIdDeserializer
	key.schema.id.serializer = class io.confluent.kafka.serializers.schema.id.PrefixSchemaIdSerializer
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.retries = 3
	max.schemas.per.subject = 1000
	normalize.schemas = false
	propagate.schema.tags = false
	proxy.host = 
	proxy.port = -1
	retries.max.wait.ms = 20000
	retries.wait.ms = 1000
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:43977]
	schema.registry.url.randomize = false
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.schema.id.deserializer = class io.confluent.kafka.serializers.schema.id.DualSchemaIdDeserializer
	value.schema.id.serializer = class io.confluent.kafka.serializers.schema.id.PrefixSchemaIdSerializer
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2025-10-24T18:29:39.816+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Instantiated an idempotent producer.
2025-10-24T18:29:39.822+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.clients.producer.ProducerConfig    : These configurations '[schema.registry.url]' were supplied but are not used yet.
2025-10-24T18:29:39.822+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-10-24T18:29:39.822+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-10-24T18:29:39.822+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1761323379822
 Verifying Kafka topics exist...
 Topic: dataset-events
 Topic: data-service-events
 Topic: service-events
 Topics should be auto-created by KAFKA_AUTO_CREATE_TOPICS_ENABLE=true
2025-10-24T18:29:39.827+02:00  INFO 34429 --- [fdk-resource-service] [ad | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Cluster ID: BiwIzKnYQGKuWBEG8w9bVw
2025-10-24T18:29:39.839+02:00  INFO 34429 --- [fdk-resource-service] [ad | producer-1] o.a.k.c.p.internals.TransactionManager   : [Producer clientId=producer-1] ProducerId set to 0 with epoch 0
 Produced message to topic: dataset-events
 Produced message to topic: data-service-events
 Produced message to topic: service-events
 Waiting for Kafka consumers to process messages...
 Consumer group: test-group
 Bootstrap servers: PLAINTEXT://localhost:42839
 Schema registry: http://localhost:43977
 Looking for consumer activity...
2025-10-24T18:29:42.660+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-6, groupId=test-group] Request joining group due to: group is already rebalancing
2025-10-24T18:29:42.660+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-2, groupId=test-group] Request joining group due to: group is already rebalancing
2025-10-24T18:29:42.660+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-test-group-6, groupId=test-group] Revoke previously assigned partitions 
2025-10-24T18:29:42.661+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-4, groupId=test-group] Request joining group due to: group is already rebalancing
2025-10-24T18:29:42.661+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-7, groupId=test-group] Request joining group due to: group is already rebalancing
2025-10-24T18:29:42.661+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-test-group-4, groupId=test-group] Revoke previously assigned partitions 
2025-10-24T18:29:42.661+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-test-group-2, groupId=test-group] Revoke previously assigned partitions 
2025-10-24T18:29:42.661+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : test-group: partitions revoked: []
2025-10-24T18:29:42.661+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : test-group: partitions revoked: []
2025-10-24T18:29:42.661+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#6-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-test-group-7, groupId=test-group] Revoke previously assigned partitions 
2025-10-24T18:29:42.661+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : test-group: partitions revoked: []
2025-10-24T18:29:42.661+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:29:42.661+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:29:42.661+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#6-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : test-group: partitions revoked: []
2025-10-24T18:29:42.661+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:29:42.661+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#6-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:29:42.661+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-6, groupId=test-group] (Re-)joining group
2025-10-24T18:29:42.662+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-2, groupId=test-group] (Re-)joining group
2025-10-24T18:29:42.661+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-4, groupId=test-group] (Re-)joining group
2025-10-24T18:29:42.661+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-7, groupId=test-group] (Re-)joining group
2025-10-24T18:29:42.664+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-5, groupId=test-group] Request joining group due to: group is already rebalancing
2025-10-24T18:29:42.664+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-3, groupId=test-group] Request joining group due to: group is already rebalancing
2025-10-24T18:29:42.664+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#2-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-test-group-3, groupId=test-group] Revoke previously assigned partitions 
2025-10-24T18:29:42.664+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-test-group-5, groupId=test-group] Revoke previously assigned partitions 
2025-10-24T18:29:42.664+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : test-group: partitions revoked: []
2025-10-24T18:29:42.664+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : test-group: partitions revoked: []
2025-10-24T18:29:42.664+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:29:42.664+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:29:42.664+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-5, groupId=test-group] (Re-)joining group
2025-10-24T18:29:42.664+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-3, groupId=test-group] (Re-)joining group
2025-10-24T18:29:42.670+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-7, groupId=test-group] Successfully joined group with generation Generation{generationId=2, memberId='consumer-test-group-7-aa3e9458-5f99-44c3-8b2d-b7f8d08aae1b', protocol='range'}
2025-10-24T18:29:42.670+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-6, groupId=test-group] Successfully joined group with generation Generation{generationId=2, memberId='consumer-test-group-6-8ba584f0-d935-4829-a665-005ec7983b4a', protocol='range'}
2025-10-24T18:29:42.671+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-1, groupId=test-group] Successfully joined group with generation Generation{generationId=2, memberId='consumer-test-group-1-cf6eeb9d-7953-4efa-950e-880ea3834cc8', protocol='range'}
2025-10-24T18:29:42.672+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-5, groupId=test-group] Successfully joined group with generation Generation{generationId=2, memberId='consumer-test-group-5-11d19ea5-3247-4ab1-a002-2f9649be5b5a', protocol='range'}
2025-10-24T18:29:42.675+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-4, groupId=test-group] Successfully joined group with generation Generation{generationId=2, memberId='consumer-test-group-4-bb92af65-ebd1-47bd-9d64-252ba9696404', protocol='range'}
2025-10-24T18:29:42.675+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-2, groupId=test-group] Successfully joined group with generation Generation{generationId=2, memberId='consumer-test-group-2-10108748-0aec-4c84-a991-9efdae717310', protocol='range'}
2025-10-24T18:29:42.677+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-3, groupId=test-group] Successfully joined group with generation Generation{generationId=2, memberId='consumer-test-group-3-9e3e6526-7e3f-4317-b991-5d2468f8eb17', protocol='range'}
2025-10-24T18:29:42.680+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-1, groupId=test-group] Finished assignment for group at generation 2: {consumer-test-group-7-aa3e9458-5f99-44c3-8b2d-b7f8d08aae1b=Assignment(partitions=[event-events-0]), consumer-test-group-6-8ba584f0-d935-4829-a665-005ec7983b4a=Assignment(partitions=[service-events-0]), consumer-test-group-1-cf6eeb9d-7953-4efa-950e-880ea3834cc8=Assignment(partitions=[information-model-events-0]), consumer-test-group-5-11d19ea5-3247-4ab1-a002-2f9649be5b5a=Assignment(partitions=[data-service-events-0]), consumer-test-group-3-9e3e6526-7e3f-4317-b991-5d2468f8eb17=Assignment(partitions=[rdf-parse-events-0]), consumer-test-group-4-bb92af65-ebd1-47bd-9d64-252ba9696404=Assignment(partitions=[dataset-events-0]), consumer-test-group-2-10108748-0aec-4c84-a991-9efdae717310=Assignment(partitions=[concept-events-0])}
2025-10-24T18:29:42.685+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-6, groupId=test-group] Successfully synced group in generation Generation{generationId=2, memberId='consumer-test-group-6-8ba584f0-d935-4829-a665-005ec7983b4a', protocol='range'}
2025-10-24T18:29:42.685+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-7, groupId=test-group] Successfully synced group in generation Generation{generationId=2, memberId='consumer-test-group-7-aa3e9458-5f99-44c3-8b2d-b7f8d08aae1b', protocol='range'}
2025-10-24T18:29:42.685+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-7, groupId=test-group] Notifying assignor about the new Assignment(partitions=[event-events-0])
2025-10-24T18:29:42.685+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-6, groupId=test-group] Notifying assignor about the new Assignment(partitions=[service-events-0])
2025-10-24T18:29:42.686+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-5, groupId=test-group] Successfully synced group in generation Generation{generationId=2, memberId='consumer-test-group-5-11d19ea5-3247-4ab1-a002-2f9649be5b5a', protocol='range'}
2025-10-24T18:29:42.686+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-5, groupId=test-group] Notifying assignor about the new Assignment(partitions=[data-service-events-0])
2025-10-24T18:29:42.687+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-3, groupId=test-group] Successfully synced group in generation Generation{generationId=2, memberId='consumer-test-group-3-9e3e6526-7e3f-4317-b991-5d2468f8eb17', protocol='range'}
2025-10-24T18:29:42.687+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-3, groupId=test-group] Notifying assignor about the new Assignment(partitions=[rdf-parse-events-0])
2025-10-24T18:29:42.688+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-test-group-5, groupId=test-group] Adding newly assigned partitions: data-service-events-0
2025-10-24T18:29:42.688+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#2-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-test-group-3, groupId=test-group] Adding newly assigned partitions: rdf-parse-events-0
2025-10-24T18:29:42.688+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-test-group-6, groupId=test-group] Adding newly assigned partitions: service-events-0
2025-10-24T18:29:42.688+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#6-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-test-group-7, groupId=test-group] Adding newly assigned partitions: event-events-0
2025-10-24T18:29:42.688+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-4, groupId=test-group] Successfully synced group in generation Generation{generationId=2, memberId='consumer-test-group-4-bb92af65-ebd1-47bd-9d64-252ba9696404', protocol='range'}
2025-10-24T18:29:42.688+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-4, groupId=test-group] Notifying assignor about the new Assignment(partitions=[dataset-events-0])
2025-10-24T18:29:42.688+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-test-group-4, groupId=test-group] Adding newly assigned partitions: dataset-events-0
2025-10-24T18:29:42.689+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-2, groupId=test-group] Successfully synced group in generation Generation{generationId=2, memberId='consumer-test-group-2-10108748-0aec-4c84-a991-9efdae717310', protocol='range'}
2025-10-24T18:29:42.689+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-2, groupId=test-group] Notifying assignor about the new Assignment(partitions=[concept-events-0])
2025-10-24T18:29:42.689+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-1, groupId=test-group] Successfully synced group in generation Generation{generationId=2, memberId='consumer-test-group-1-cf6eeb9d-7953-4efa-950e-880ea3834cc8', protocol='range'}
2025-10-24T18:29:42.689+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-test-group-2, groupId=test-group] Adding newly assigned partitions: concept-events-0
2025-10-24T18:29:42.690+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-1, groupId=test-group] Notifying assignor about the new Assignment(partitions=[information-model-events-0])
2025-10-24T18:29:42.690+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#0-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-test-group-1, groupId=test-group] Adding newly assigned partitions: information-model-events-0
2025-10-24T18:29:42.702+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-4, groupId=test-group] Found no committed offset for partition dataset-events-0
2025-10-24T18:29:42.702+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-3, groupId=test-group] Found no committed offset for partition rdf-parse-events-0
2025-10-24T18:29:42.702+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#6-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-7, groupId=test-group] Found no committed offset for partition event-events-0
2025-10-24T18:29:42.702+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-5, groupId=test-group] Found no committed offset for partition data-service-events-0
2025-10-24T18:29:42.702+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-1, groupId=test-group] Found no committed offset for partition information-model-events-0
2025-10-24T18:29:42.702+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-2, groupId=test-group] Found no committed offset for partition concept-events-0
2025-10-24T18:29:42.702+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-test-group-6, groupId=test-group] Found no committed offset for partition service-events-0
2025-10-24T18:29:42.710+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-test-group-5, groupId=test-group] Resetting offset for partition data-service-events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:42839 (id: 1 rack: null)], epoch=0}}.
2025-10-24T18:29:42.710+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-test-group-6, groupId=test-group] Resetting offset for partition service-events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:42839 (id: 1 rack: null)], epoch=0}}.
2025-10-24T18:29:42.710+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-test-group-2, groupId=test-group] Resetting offset for partition concept-events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:42839 (id: 1 rack: null)], epoch=0}}.
2025-10-24T18:29:42.710+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-test-group-4, groupId=test-group] Resetting offset for partition dataset-events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:42839 (id: 1 rack: null)], epoch=0}}.
2025-10-24T18:29:42.710+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-test-group-1, groupId=test-group] Resetting offset for partition information-model-events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:42839 (id: 1 rack: null)], epoch=0}}.
2025-10-24T18:29:42.711+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : test-group: partitions assigned: [information-model-events-0]
2025-10-24T18:29:42.711+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : test-group: partitions assigned: [concept-events-0]
2025-10-24T18:29:42.710+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#6-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-test-group-7, groupId=test-group] Resetting offset for partition event-events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:42839 (id: 1 rack: null)], epoch=0}}.
2025-10-24T18:29:42.711+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : test-group: partitions assigned: [data-service-events-0]
2025-10-24T18:29:42.710+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#2-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-test-group-3, groupId=test-group] Resetting offset for partition rdf-parse-events-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:42839 (id: 1 rack: null)], epoch=0}}.
2025-10-24T18:29:42.711+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : test-group: partitions assigned: [dataset-events-0]
2025-10-24T18:29:42.711+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : test-group: partitions assigned: [service-events-0]
2025-10-24T18:29:42.712+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#6-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : test-group: partitions assigned: [event-events-0]
2025-10-24T18:29:42.712+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : test-group: partitions assigned: [rdf-parse-events-0]
2025-10-24T18:29:42.776+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 1 records
2025-10-24T18:29:42.776+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 1 records
2025-10-24T18:29:42.776+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 1 records
2025-10-24T18:29:42.784+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] .a.RecordMessagingMessageListenerAdapter : Processing [GenericMessage [payload={"type": "DATASET_HARVESTED", "fdkId": "test-dataset-1", "graph": "{uri=https://example.com/dataset, title=Test Dataset}", "timestamp": 1761323379822}, headers={kafka_offset=0, kafka_consumer=org.springframework.kafka.core.DefaultKafkaConsumerFactory$ExtendedKafkaConsumer@28abf53f, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, kafka_receivedMessageKey=test-dataset-1, kafka_receivedTopic=dataset-events, kafka_receivedTimestamp=1761323379860, kafka_acknowledgment=Acknowledgment for dataset-events-0@0, kafka_groupId=test-group}]]
2025-10-24T18:29:42.784+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] .a.RecordMessagingMessageListenerAdapter : Processing [GenericMessage [payload={"type": "DATA_SERVICE_HARVESTED", "fdkId": "test-data_service-1", "graph": "{uri=https://example.com/data-service, title=Test Data Service}", "timestamp": 1761323380013}, headers={kafka_offset=0, kafka_consumer=org.springframework.kafka.core.DefaultKafkaConsumerFactory$ExtendedKafkaConsumer@577fa96b, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, kafka_receivedMessageKey=test-data_service-1, kafka_receivedTopic=data-service-events, kafka_receivedTimestamp=1761323380019, kafka_acknowledgment=Acknowledgment for data-service-events-0@0, kafka_groupId=test-group}]]
2025-10-24T18:29:42.784+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] .a.RecordMessagingMessageListenerAdapter : Processing [GenericMessage [payload={"type": "SERVICE_HARVESTED", "fdkId": "test-service-1", "graph": "{uri=https://example.com/service, title=Test Service}", "timestamp": 1761323380032}, headers={kafka_offset=0, kafka_consumer=org.springframework.kafka.core.DefaultKafkaConsumerFactory$ExtendedKafkaConsumer@4b5e9aee, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, kafka_receivedMessageKey=test-service-1, kafka_receivedTopic=service-events, kafka_receivedTimestamp=1761323380036, kafka_acknowledgment=Acknowledgment for service-events-0@0, kafka_groupId=test-group}]]
2025-10-24T18:29:42.786+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] n.f.resourceservice.kafka.KafkaConsumer  : Received service event from topic: service-events, partition: 0, offset: 0
2025-10-24T18:29:42.786+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] n.f.resourceservice.kafka.KafkaConsumer  : Received dataset event from topic: dataset-events, partition: 0, offset: 0
2025-10-24T18:29:42.786+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] n.f.resourceservice.kafka.KafkaConsumer  : Converting GenericRecord to ServiceEvent
2025-10-24T18:29:42.786+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] n.f.resourceservice.kafka.KafkaConsumer  : Received data service event from topic: data-service-events, partition: 0, offset: 0
2025-10-24T18:29:42.786+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] n.f.resourceservice.kafka.KafkaConsumer  : Converting GenericRecord to DatasetEvent
2025-10-24T18:29:42.786+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] n.f.resourceservice.kafka.KafkaConsumer  : Converting GenericRecord to DataServiceEvent
2025-10-24T18:29:42.796+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] n.f.r.service.CircuitBreakerService      : Processing service event with circuit breaker: {"type": "SERVICE_HARVESTED", "fdkId": "test-service-1", "graph": "{uri=https://example.com/service, title=Test Service}", "timestamp": 1761323380032}
2025-10-24T18:29:42.796+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] n.f.r.service.CircuitBreakerService      : Processing dataset event with circuit breaker: {"type": "DATASET_HARVESTED", "fdkId": "test-dataset-1", "graph": "{uri=https://example.com/dataset, title=Test Dataset}", "timestamp": 1761323379822}
2025-10-24T18:29:42.796+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] n.f.r.service.CircuitBreakerService      : Processing data service event with circuit breaker: {"type": "DATA_SERVICE_HARVESTED", "fdkId": "test-data_service-1", "graph": "{uri=https://example.com/data-service, title=Test Data Service}", "timestamp": 1761323380013}
2025-10-24T18:29:42.797+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] n.f.r.service.CircuitBreakerService      :  PROCESS RESOURCE: Processing resource event - fdkId=test-service-1, resourceType=SERVICE, eventType=SERVICE_HARVESTED
2025-10-24T18:29:42.797+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] n.f.r.service.CircuitBreakerService      :  PROCESS RESOURCE: Processing resource event - fdkId=test-dataset-1, resourceType=DATASET, eventType=DATASET_HARVESTED
2025-10-24T18:29:42.797+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] n.f.r.service.CircuitBreakerService      :  PROCESS RESOURCE: Action extracted: HARVESTED
2025-10-24T18:29:42.797+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] n.f.r.service.CircuitBreakerService      :  PROCESS RESOURCE: Action extracted: HARVESTED
2025-10-24T18:29:42.797+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] n.f.r.service.CircuitBreakerService      :  PROCESS RESOURCE: Processing HARVESTED event
2025-10-24T18:29:42.797+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] n.f.r.service.CircuitBreakerService      :  PROCESS RESOURCE: Processing resource event - fdkId=test-data_service-1, resourceType=DATA_SERVICE, eventType=DATA_SERVICE_HARVESTED
2025-10-24T18:29:42.797+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] n.f.r.service.CircuitBreakerService      :  PROCESS RESOURCE: Processing HARVESTED event
2025-10-24T18:29:42.797+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] n.f.r.service.CircuitBreakerService      :  PROCESS RESOURCE: Action extracted: HARVESTED
2025-10-24T18:29:42.797+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] n.f.r.service.RdfProcessingService       : Converting Turtle to JSON-LD
2025-10-24T18:29:42.797+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] n.f.r.service.CircuitBreakerService      :  PROCESS RESOURCE: Processing HARVESTED event
2025-10-24T18:29:42.797+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] n.f.r.service.RdfProcessingService       : Converting Turtle to JSON-LD
2025-10-24T18:29:42.797+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] n.f.r.service.RdfProcessingService       : Converting Turtle to JSON-LD
2025-10-24T18:29:43.018+02:00 ERROR 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] org.apache.jena.riot                     : [line: 1, col: 1 ] Not implemented (formulae, graph literals)
2025-10-24T18:29:43.018+02:00 ERROR 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] org.apache.jena.riot                     : [line: 1, col: 1 ] Not implemented (formulae, graph literals)
2025-10-24T18:29:43.018+02:00 ERROR 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] org.apache.jena.riot                     : [line: 1, col: 1 ] Not implemented (formulae, graph literals)
2025-10-24T18:29:43.018+02:00 ERROR 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] n.f.r.service.RdfProcessingService       : Failed to convert Turtle to JSON-LD

org.apache.jena.riot.RiotException: [line: 1, col: 1 ] Not implemented (formulae, graph literals)
	at org.apache.jena.riot.system.ErrorHandlerFactory$ErrorHandlerStd.fatal(ErrorHandlerFactory.java:155) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangEngine.raiseException(LangEngine.java:164) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangEngine.exception(LangEngine.java:153) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangEngine.exception(LangEngine.java:147) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangTurtleBase.triplesFormula(LangTurtleBase.java:758) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangTurtleBase.triplesNodeCompound(LangTurtleBase.java:736) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangTurtleBase.triples(LangTurtleBase.java:253) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangTurtle.oneTopLevelElement(LangTurtle.java:46) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangTurtleBase.runParser(LangTurtleBase.java:89) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangBase.parse(LangBase.java:43) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.RiotParsers$AbstractReaderRIOTLang.read(RiotParsers.java:133) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.RiotParsers$AbstractReaderRIOTLang.read(RiotParsers.java:91) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.RDFParser.read(RDFParser.java:453) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.RDFParser.parseNotUri(RDFParser.java:443) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.RDFParser.parse(RDFParser.java:380) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.RDFParserBuilder.parse(RDFParserBuilder.java:553) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.RDFDataMgr.parseFromInputStream(RDFDataMgr.java:545) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.RDFDataMgr.read(RDFDataMgr.java:252) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.RDFDataMgr.read(RDFDataMgr.java:219) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.RDFDataMgr.read(RDFDataMgr.java:205) ~[jena-arq-5.6.0.jar:5.6.0]
	at no.fdk.resourceservice.service.RdfProcessingService.convertTurtleToJsonLd(RdfProcessingService.kt:43) ~[classes/:na]
	at no.fdk.resourceservice.service.CircuitBreakerService.processResourceEvent(CircuitBreakerService.kt:154) ~[classes/:na]
	at no.fdk.resourceservice.service.CircuitBreakerService.handleDataServiceEvent(CircuitBreakerService.kt:117) ~[classes/:na]
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:580) ~[na:na]
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:360) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:196) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:89) ~[spring-aop-6.2.11.jar:6.2.11]
	at io.github.resilience4j.circuitbreaker.CircuitBreaker.lambda$decorateCheckedSupplier$0(CircuitBreaker.java:71) ~[resilience4j-circuitbreaker-2.2.0.jar:2.2.0]
	at io.github.resilience4j.circuitbreaker.CircuitBreaker.executeCheckedSupplier(CircuitBreaker.java:739) ~[resilience4j-circuitbreaker-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.circuitbreaker.configure.CircuitBreakerAspect.defaultHandling(CircuitBreakerAspect.java:179) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.circuitbreaker.configure.CircuitBreakerAspect.proceed(CircuitBreakerAspect.java:126) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.circuitbreaker.configure.CircuitBreakerAspect.lambda$circuitBreakerAroundAdvice$0(CircuitBreakerAspect.java:108) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.fallback.DefaultFallbackDecorator.lambda$decorate$0(DefaultFallbackDecorator.java:36) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.fallback.FallbackExecutor.execute(FallbackExecutor.java:39) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.circuitbreaker.configure.CircuitBreakerAspect.circuitBreakerAroundAdvice(CircuitBreakerAspect.java:109) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:580) ~[na:na]
	at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:649) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:631) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:71) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:173) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:89) ~[spring-aop-6.2.11.jar:6.2.11]
	at io.github.resilience4j.retry.Retry.lambda$decorateCheckedSupplier$1(Retry.java:135) ~[resilience4j-retry-2.2.0.jar:2.2.0]
	at io.github.resilience4j.retry.Retry.executeCheckedSupplier(Retry.java:350) ~[resilience4j-retry-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.retry.configure.RetryAspect.handleDefaultJoinPoint(RetryAspect.java:175) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.retry.configure.RetryAspect.proceed(RetryAspect.java:132) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.retry.configure.RetryAspect.lambda$retryAroundAdvice$0(RetryAspect.java:116) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.fallback.FallbackExecutor.execute(FallbackExecutor.java:37) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.retry.configure.RetryAspect.retryAroundAdvice(RetryAspect.java:117) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:580) ~[na:na]
	at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:649) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:631) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:71) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:173) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728) ~[spring-aop-6.2.11.jar:6.2.11]
	at no.fdk.resourceservice.service.CircuitBreakerService$$SpringCGLIB$$0.handleDataServiceEvent(<generated>) ~[classes/:na]
	at no.fdk.resourceservice.kafka.KafkaConsumer.handleDataServiceEvent(KafkaConsumer.kt:332) ~[classes/:na]
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:580) ~[na:na]
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169) ~[spring-messaging-6.2.11.jar:6.2.11]
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119) ~[spring-messaging-6.2.11.jar:6.2.11]
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:78) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:475) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:421) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2887) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2865) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2777) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2614) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2503) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2152) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1528) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1466) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1335) ~[spring-kafka-3.3.10.jar:3.3.10]
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1804) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:1570) ~[na:na]

2025-10-24T18:29:43.018+02:00 ERROR 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] n.f.r.service.RdfProcessingService       : Failed to convert Turtle to JSON-LD

org.apache.jena.riot.RiotException: [line: 1, col: 1 ] Not implemented (formulae, graph literals)
	at org.apache.jena.riot.system.ErrorHandlerFactory$ErrorHandlerStd.fatal(ErrorHandlerFactory.java:155) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangEngine.raiseException(LangEngine.java:164) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangEngine.exception(LangEngine.java:153) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangEngine.exception(LangEngine.java:147) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangTurtleBase.triplesFormula(LangTurtleBase.java:758) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangTurtleBase.triplesNodeCompound(LangTurtleBase.java:736) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangTurtleBase.triples(LangTurtleBase.java:253) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangTurtle.oneTopLevelElement(LangTurtle.java:46) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangTurtleBase.runParser(LangTurtleBase.java:89) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangBase.parse(LangBase.java:43) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.RiotParsers$AbstractReaderRIOTLang.read(RiotParsers.java:133) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.RiotParsers$AbstractReaderRIOTLang.read(RiotParsers.java:91) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.RDFParser.read(RDFParser.java:453) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.RDFParser.parseNotUri(RDFParser.java:443) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.RDFParser.parse(RDFParser.java:380) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.RDFParserBuilder.parse(RDFParserBuilder.java:553) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.RDFDataMgr.parseFromInputStream(RDFDataMgr.java:545) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.RDFDataMgr.read(RDFDataMgr.java:252) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.RDFDataMgr.read(RDFDataMgr.java:219) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.RDFDataMgr.read(RDFDataMgr.java:205) ~[jena-arq-5.6.0.jar:5.6.0]
	at no.fdk.resourceservice.service.RdfProcessingService.convertTurtleToJsonLd(RdfProcessingService.kt:43) ~[classes/:na]
	at no.fdk.resourceservice.service.CircuitBreakerService.processResourceEvent(CircuitBreakerService.kt:154) ~[classes/:na]
	at no.fdk.resourceservice.service.CircuitBreakerService.handleServiceEvent(CircuitBreakerService.kt:131) ~[classes/:na]
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:580) ~[na:na]
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:360) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:196) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:89) ~[spring-aop-6.2.11.jar:6.2.11]
	at io.github.resilience4j.circuitbreaker.CircuitBreaker.lambda$decorateCheckedSupplier$0(CircuitBreaker.java:71) ~[resilience4j-circuitbreaker-2.2.0.jar:2.2.0]
	at io.github.resilience4j.circuitbreaker.CircuitBreaker.executeCheckedSupplier(CircuitBreaker.java:739) ~[resilience4j-circuitbreaker-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.circuitbreaker.configure.CircuitBreakerAspect.defaultHandling(CircuitBreakerAspect.java:179) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.circuitbreaker.configure.CircuitBreakerAspect.proceed(CircuitBreakerAspect.java:126) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.circuitbreaker.configure.CircuitBreakerAspect.lambda$circuitBreakerAroundAdvice$0(CircuitBreakerAspect.java:108) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.fallback.DefaultFallbackDecorator.lambda$decorate$0(DefaultFallbackDecorator.java:36) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.fallback.FallbackExecutor.execute(FallbackExecutor.java:39) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.circuitbreaker.configure.CircuitBreakerAspect.circuitBreakerAroundAdvice(CircuitBreakerAspect.java:109) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:580) ~[na:na]
	at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:649) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:631) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:71) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:173) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:89) ~[spring-aop-6.2.11.jar:6.2.11]
	at io.github.resilience4j.retry.Retry.lambda$decorateCheckedSupplier$1(Retry.java:135) ~[resilience4j-retry-2.2.0.jar:2.2.0]
	at io.github.resilience4j.retry.Retry.executeCheckedSupplier(Retry.java:350) ~[resilience4j-retry-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.retry.configure.RetryAspect.handleDefaultJoinPoint(RetryAspect.java:175) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.retry.configure.RetryAspect.proceed(RetryAspect.java:132) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.retry.configure.RetryAspect.lambda$retryAroundAdvice$0(RetryAspect.java:116) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.fallback.FallbackExecutor.execute(FallbackExecutor.java:37) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.retry.configure.RetryAspect.retryAroundAdvice(RetryAspect.java:117) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:580) ~[na:na]
	at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:649) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:631) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:71) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:173) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728) ~[spring-aop-6.2.11.jar:6.2.11]
	at no.fdk.resourceservice.service.CircuitBreakerService$$SpringCGLIB$$0.handleServiceEvent(<generated>) ~[classes/:na]
	at no.fdk.resourceservice.kafka.KafkaConsumer.handleServiceEvent(KafkaConsumer.kt:386) ~[classes/:na]
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:580) ~[na:na]
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169) ~[spring-messaging-6.2.11.jar:6.2.11]
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119) ~[spring-messaging-6.2.11.jar:6.2.11]
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:78) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:475) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:421) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2887) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2865) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2777) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2614) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2503) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2152) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1528) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1466) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1335) ~[spring-kafka-3.3.10.jar:3.3.10]
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1804) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:1570) ~[na:na]

2025-10-24T18:29:43.018+02:00 ERROR 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] n.f.r.service.RdfProcessingService       : Failed to convert Turtle to JSON-LD

org.apache.jena.riot.RiotException: [line: 1, col: 1 ] Not implemented (formulae, graph literals)
	at org.apache.jena.riot.system.ErrorHandlerFactory$ErrorHandlerStd.fatal(ErrorHandlerFactory.java:155) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangEngine.raiseException(LangEngine.java:164) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangEngine.exception(LangEngine.java:153) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangEngine.exception(LangEngine.java:147) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangTurtleBase.triplesFormula(LangTurtleBase.java:758) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangTurtleBase.triplesNodeCompound(LangTurtleBase.java:736) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangTurtleBase.triples(LangTurtleBase.java:253) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangTurtle.oneTopLevelElement(LangTurtle.java:46) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangTurtleBase.runParser(LangTurtleBase.java:89) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangBase.parse(LangBase.java:43) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.RiotParsers$AbstractReaderRIOTLang.read(RiotParsers.java:133) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.RiotParsers$AbstractReaderRIOTLang.read(RiotParsers.java:91) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.RDFParser.read(RDFParser.java:453) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.RDFParser.parseNotUri(RDFParser.java:443) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.RDFParser.parse(RDFParser.java:380) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.RDFParserBuilder.parse(RDFParserBuilder.java:553) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.RDFDataMgr.parseFromInputStream(RDFDataMgr.java:545) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.RDFDataMgr.read(RDFDataMgr.java:252) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.RDFDataMgr.read(RDFDataMgr.java:219) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.RDFDataMgr.read(RDFDataMgr.java:205) ~[jena-arq-5.6.0.jar:5.6.0]
	at no.fdk.resourceservice.service.RdfProcessingService.convertTurtleToJsonLd(RdfProcessingService.kt:43) ~[classes/:na]
	at no.fdk.resourceservice.service.CircuitBreakerService.processResourceEvent(CircuitBreakerService.kt:154) ~[classes/:na]
	at no.fdk.resourceservice.service.CircuitBreakerService.handleDatasetEvent(CircuitBreakerService.kt:110) ~[classes/:na]
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:580) ~[na:na]
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:360) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:196) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:89) ~[spring-aop-6.2.11.jar:6.2.11]
	at io.github.resilience4j.circuitbreaker.CircuitBreaker.lambda$decorateCheckedSupplier$0(CircuitBreaker.java:71) ~[resilience4j-circuitbreaker-2.2.0.jar:2.2.0]
	at io.github.resilience4j.circuitbreaker.CircuitBreaker.executeCheckedSupplier(CircuitBreaker.java:739) ~[resilience4j-circuitbreaker-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.circuitbreaker.configure.CircuitBreakerAspect.defaultHandling(CircuitBreakerAspect.java:179) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.circuitbreaker.configure.CircuitBreakerAspect.proceed(CircuitBreakerAspect.java:126) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.circuitbreaker.configure.CircuitBreakerAspect.lambda$circuitBreakerAroundAdvice$0(CircuitBreakerAspect.java:108) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.fallback.DefaultFallbackDecorator.lambda$decorate$0(DefaultFallbackDecorator.java:36) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.fallback.FallbackExecutor.execute(FallbackExecutor.java:39) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.circuitbreaker.configure.CircuitBreakerAspect.circuitBreakerAroundAdvice(CircuitBreakerAspect.java:109) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:580) ~[na:na]
	at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:649) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:631) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:71) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:173) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:89) ~[spring-aop-6.2.11.jar:6.2.11]
	at io.github.resilience4j.retry.Retry.lambda$decorateCheckedSupplier$1(Retry.java:135) ~[resilience4j-retry-2.2.0.jar:2.2.0]
	at io.github.resilience4j.retry.Retry.executeCheckedSupplier(Retry.java:350) ~[resilience4j-retry-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.retry.configure.RetryAspect.handleDefaultJoinPoint(RetryAspect.java:175) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.retry.configure.RetryAspect.proceed(RetryAspect.java:132) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.retry.configure.RetryAspect.lambda$retryAroundAdvice$0(RetryAspect.java:116) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.fallback.FallbackExecutor.execute(FallbackExecutor.java:37) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.retry.configure.RetryAspect.retryAroundAdvice(RetryAspect.java:117) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:580) ~[na:na]
	at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:649) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:631) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:71) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:173) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728) ~[spring-aop-6.2.11.jar:6.2.11]
	at no.fdk.resourceservice.service.CircuitBreakerService$$SpringCGLIB$$0.handleDatasetEvent(<generated>) ~[classes/:na]
	at no.fdk.resourceservice.kafka.KafkaConsumer.handleDatasetEvent(KafkaConsumer.kt:305) ~[classes/:na]
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:580) ~[na:na]
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169) ~[spring-messaging-6.2.11.jar:6.2.11]
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119) ~[spring-messaging-6.2.11.jar:6.2.11]
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:78) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:475) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:421) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2887) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2865) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2777) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2614) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2503) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2152) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1528) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1466) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1335) ~[spring-kafka-3.3.10.jar:3.3.10]
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1804) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:1570) ~[na:na]

2025-10-24T18:29:43.021+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] n.f.r.service.CircuitBreakerService      :  PROCESS RESOURCE: Converted to JSON-LD, calling resourceService.storeResource
2025-10-24T18:29:43.021+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] n.f.r.service.CircuitBreakerService      :  PROCESS RESOURCE: Converted to JSON-LD, calling resourceService.storeResource
2025-10-24T18:29:43.021+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] n.f.r.service.CircuitBreakerService      :  PROCESS RESOURCE: Converted to JSON-LD, calling resourceService.storeResource
2025-10-24T18:29:43.042+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] n.f.r.service.ResourceService            : Storing resource JSON-LD with id: test-data_service-1, type: DATA_SERVICE, timestamp: 1761323380013
2025-10-24T18:29:43.042+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] n.f.r.service.ResourceService            : Storing resource JSON-LD with id: test-service-1, type: SERVICE, timestamp: 1761323380032
2025-10-24T18:29:43.042+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] n.f.r.service.ResourceService            : Storing resource JSON-LD with id: test-dataset-1, type: DATASET, timestamp: 1761323379822
2025-10-24T18:29:43.055+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=?
2025-10-24T18:29:43.055+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=?
2025-10-24T18:29:43.055+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=?
2025-10-24T18:29:43.076+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=?
2025-10-24T18:29:43.076+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=?
2025-10-24T18:29:43.076+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=?
2025-10-24T18:29:43.101+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] org.hibernate.SQL                        : 
    insert 
    into
        resources
        (created_at, deleted, resource_json, resource_json_ld, resource_type, timestamp, updated_at, id) 
    values
        (?, ?, ?, ?, ?, ?, ?, ?)
Hibernate: 
    insert 
    into
        resources
        (created_at, deleted, resource_json, resource_json_ld, resource_type, timestamp, updated_at, id) 
    values
        (?, ?, ?, ?, ?, ?, ?, ?)
2025-10-24T18:29:43.101+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] org.hibernate.SQL                        : 
    insert 
    into
        resources
        (created_at, deleted, resource_json, resource_json_ld, resource_type, timestamp, updated_at, id) 
    values
        (?, ?, ?, ?, ?, ?, ?, ?)
Hibernate: 
    insert 
    into
        resources
        (created_at, deleted, resource_json, resource_json_ld, resource_type, timestamp, updated_at, id) 
    values
        (?, ?, ?, ?, ?, ?, ?, ?)
2025-10-24T18:29:43.101+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] org.hibernate.SQL                        : 
    insert 
    into
        resources
        (created_at, deleted, resource_json, resource_json_ld, resource_type, timestamp, updated_at, id) 
    values
        (?, ?, ?, ?, ?, ?, ?, ?)
Hibernate: 
    insert 
    into
        resources
        (created_at, deleted, resource_json, resource_json_ld, resource_type, timestamp, updated_at, id) 
    values
        (?, ?, ?, ?, ?, ?, ?, ?)
2025-10-24T18:29:43.110+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] n.f.r.service.CircuitBreakerService      :  PROCESS RESOURCE: Successfully stored HARVESTED resource
2025-10-24T18:29:43.110+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] n.f.r.service.CircuitBreakerService      :  PROCESS RESOURCE: Successfully stored HARVESTED resource
2025-10-24T18:29:43.110+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] n.f.r.service.CircuitBreakerService      :  PROCESS RESOURCE: Successfully stored HARVESTED resource
2025-10-24T18:29:43.112+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] n.f.resourceservice.kafka.KafkaConsumer  : Successfully processed service event, acknowledged
2025-10-24T18:29:43.112+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] n.f.resourceservice.kafka.KafkaConsumer  : Successfully processed data service event, acknowledged
2025-10-24T18:29:43.112+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] n.f.resourceservice.kafka.KafkaConsumer  : Successfully processed dataset event, acknowledged
2025-10-24T18:29:43.112+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {data-service-events-0=OffsetAndMetadata{offset=1, leaderEpoch=null, metadata=''}}
2025-10-24T18:29:43.112+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {service-events-0=OffsetAndMetadata{offset=1, leaderEpoch=null, metadata=''}}
2025-10-24T18:29:43.112+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {dataset-events-0=OffsetAndMetadata{offset=1, leaderEpoch=null, metadata=''}}
2025-10-24T18:29:43.113+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Committing: {service-events-0=OffsetAndMetadata{offset=1, leaderEpoch=null, metadata=''}}
2025-10-24T18:29:43.113+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Committing: {data-service-events-0=OffsetAndMetadata{offset=1, leaderEpoch=null, metadata=''}}
2025-10-24T18:29:43.113+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Committing: {dataset-events-0=OffsetAndMetadata{offset=1, leaderEpoch=null, metadata=''}}
2025-10-24T18:29:44.439+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:29:44.440+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:29:44.445+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:29:44.446+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:29:44.453+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:29:44.454+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:29:44.479+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#6-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:29:44.479+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#6-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:29:48.129+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:29:48.130+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:29:48.130+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:29:48.130+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:29:48.130+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:29:48.130+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:29:49.442+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:29:49.443+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:29:49.447+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:29:49.448+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:29:49.455+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:29:49.455+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:29:49.480+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#6-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:29:49.481+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#6-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
 Checking for resource: test-dataset-1
2025-10-24T18:29:50.060+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] n.f.r.service.ResourceService            : Getting resource JSON with id: test-dataset-1 and type: DATASET
2025-10-24T18:29:50.111+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
 Resource test-dataset-1 was NOT found in database
 Available resources in database:
 Checking for resource: test-data_service-1
2025-10-24T18:29:50.125+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] n.f.r.service.ResourceService            : Getting resource JSON with id: test-data_service-1 and type: DATA_SERVICE
2025-10-24T18:29:50.126+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
 Resource test-data_service-1 was NOT found in database
 Available resources in database:
 Checking for resource: test-service-1
2025-10-24T18:29:50.130+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] n.f.r.service.ResourceService            : Getting resource JSON with id: test-service-1 and type: SERVICE
2025-10-24T18:29:50.131+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
 Resource test-service-1 was NOT found in database
 Available resources in database:
2025-10-24T18:29:50.137+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2025-10-24T18:29:50.141+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-10-24T18:29:50.141+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-24T18:29:50.142+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-10-24T18:29:50.142+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-10-24T18:29:50.142+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.kafka.common.utils.AppInfoParser     : App info kafka.producer for producer-1 unregistered
]]></system-out>
    <system-err><![CDATA[Mockito is currently self-attaching to enable the inline-mock-maker. This will no longer work in future releases of the JDK. Please add Mockito as an agent to your build as described in Mockito's documentation: https://javadoc.io/doc/org.mockito/mockito-core/latest/org.mockito/org/mockito/Mockito.html#0.3
WARNING: A Java agent has been loaded dynamically (/Users/jeffreiffers/.m2/repository/net/bytebuddy/byte-buddy-agent/1.17.7/byte-buddy-agent-1.17.7.jar)
WARNING: If a serviceability tool is in use, please run with -XX:+EnableDynamicAgentLoading to hide this warning
WARNING: If a serviceability tool is not in use, please run with -Djdk.instrument.traceUsage for more information
WARNING: Dynamic loading of agents will be disallowed by default in a future release
]]></system-err>
  </testcase>
  <testcase name="should handle single concept resource via Kafka" classname="no.fdk.resourceservice.integration.KafkaIntegrationTest" time="30.496">
    <system-out><![CDATA[2025-10-24T18:29:50.159+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [PLAINTEXT://localhost:42839]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-2
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2025-10-24T18:29:50.159+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-10-24T18:29:50.160+02:00  INFO 34429 --- [fdk-resource-service] [           main] i.c.k.s.KafkaAvroSerializerConfig        : KafkaAvroSerializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.remove.java.properties = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.schema.id.deserializer = class io.confluent.kafka.serializers.schema.id.DualSchemaIdDeserializer
	key.schema.id.serializer = class io.confluent.kafka.serializers.schema.id.PrefixSchemaIdSerializer
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.retries = 3
	max.schemas.per.subject = 1000
	normalize.schemas = false
	propagate.schema.tags = false
	proxy.host = 
	proxy.port = -1
	retries.max.wait.ms = 20000
	retries.wait.ms = 1000
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:43977]
	schema.registry.url.randomize = false
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.schema.id.deserializer = class io.confluent.kafka.serializers.schema.id.DualSchemaIdDeserializer
	value.schema.id.serializer = class io.confluent.kafka.serializers.schema.id.PrefixSchemaIdSerializer
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2025-10-24T18:29:50.161+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-2] Instantiated an idempotent producer.
2025-10-24T18:29:50.164+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.clients.producer.ProducerConfig    : These configurations '[schema.registry.url]' were supplied but are not used yet.
2025-10-24T18:29:50.164+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-10-24T18:29:50.164+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-10-24T18:29:50.164+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1761323390164
2025-10-24T18:29:50.175+02:00  INFO 34429 --- [fdk-resource-service] [ad | producer-2] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-2] Cluster ID: BiwIzKnYQGKuWBEG8w9bVw
2025-10-24T18:29:50.177+02:00  INFO 34429 --- [fdk-resource-service] [ad | producer-2] o.a.k.c.p.internals.TransactionManager   : [Producer clientId=producer-2] ProducerId set to 1 with epoch 0
 Produced concept event to topic: concept-events
 Waiting for consumer to process message...
 Current thread: main
 Active threads: 37
 Kafka threads: [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1, org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1, micrometer-kafka-metrics, kafka-coordinator-heartbeat-thread | test-group, micrometer-kafka-metrics, kafka-producer-network-thread | producer-2, micrometer-kafka-metrics, micrometer-kafka-metrics, org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1, kafka-coordinator-heartbeat-thread | test-group, micrometer-kafka-metrics, org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1, kafka-coordinator-heartbeat-thread | test-group, org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1, kafka-coordinator-heartbeat-thread | test-group, kafka-coordinator-heartbeat-thread | test-group, kafka-coordinator-heartbeat-thread | test-group, org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1, kafka-coordinator-heartbeat-thread | test-group, org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1, micrometer-kafka-metrics, micrometer-kafka-metrics]
 Checking if Kafka listeners are registered...
2025-10-24T18:29:50.211+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 1 records
2025-10-24T18:29:50.211+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] .a.RecordMessagingMessageListenerAdapter : Processing [GenericMessage [payload={"type": "CONCEPT_HARVESTED", "fdkId": "test-concept-simple", "graph": "{uri=https://example.com/simple-concept, title=Simple Concept}", "timestamp": 1761323390168}, headers={kafka_offset=0, kafka_consumer=org.springframework.kafka.core.DefaultKafkaConsumerFactory$ExtendedKafkaConsumer@293a59aa, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, kafka_receivedMessageKey=test-concept-simple, kafka_receivedTopic=concept-events, kafka_receivedTimestamp=1761323390175, kafka_acknowledgment=Acknowledgment for concept-events-0@0, kafka_groupId=test-group}]]
2025-10-24T18:29:50.212+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] n.f.resourceservice.kafka.KafkaConsumer  :  CONCEPT LISTENER: Received concept event from topic: concept-events, partition: 0, offset: 0
2025-10-24T18:29:50.212+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] n.f.resourceservice.kafka.KafkaConsumer  : Converting GenericRecord to ConceptEvent
2025-10-24T18:29:50.212+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] n.f.resourceservice.kafka.KafkaConsumer  :  CONCEPT LISTENER: Calling circuitBreakerService.handleConceptEvent
2025-10-24T18:29:50.213+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] n.f.r.service.CircuitBreakerService      :  CIRCUIT BREAKER: Processing concept event with circuit breaker: {"type": "CONCEPT_HARVESTED", "fdkId": "test-concept-simple", "graph": "{uri=https://example.com/simple-concept, title=Simple Concept}", "timestamp": 1761323390168}
2025-10-24T18:29:50.213+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] n.f.r.service.CircuitBreakerService      :  CIRCUIT BREAKER: fdkId=test-concept-simple, type=CONCEPT_HARVESTED, timestamp=1761323390168
2025-10-24T18:29:50.213+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] n.f.r.service.CircuitBreakerService      :  PROCESS RESOURCE: Processing resource event - fdkId=test-concept-simple, resourceType=CONCEPT, eventType=CONCEPT_HARVESTED
2025-10-24T18:29:50.213+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] n.f.r.service.CircuitBreakerService      :  PROCESS RESOURCE: Action extracted: HARVESTED
2025-10-24T18:29:50.213+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] n.f.r.service.CircuitBreakerService      :  PROCESS RESOURCE: Processing HARVESTED event
2025-10-24T18:29:50.213+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] n.f.r.service.RdfProcessingService       : Converting Turtle to JSON-LD
2025-10-24T18:29:50.214+02:00 ERROR 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] org.apache.jena.riot                     : [line: 1, col: 1 ] Not implemented (formulae, graph literals)
2025-10-24T18:29:50.214+02:00 ERROR 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] n.f.r.service.RdfProcessingService       : Failed to convert Turtle to JSON-LD

org.apache.jena.riot.RiotException: [line: 1, col: 1 ] Not implemented (formulae, graph literals)
	at org.apache.jena.riot.system.ErrorHandlerFactory$ErrorHandlerStd.fatal(ErrorHandlerFactory.java:155) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangEngine.raiseException(LangEngine.java:164) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangEngine.exception(LangEngine.java:153) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangEngine.exception(LangEngine.java:147) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangTurtleBase.triplesFormula(LangTurtleBase.java:758) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangTurtleBase.triplesNodeCompound(LangTurtleBase.java:736) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangTurtleBase.triples(LangTurtleBase.java:253) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangTurtle.oneTopLevelElement(LangTurtle.java:46) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangTurtleBase.runParser(LangTurtleBase.java:89) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangBase.parse(LangBase.java:43) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.RiotParsers$AbstractReaderRIOTLang.read(RiotParsers.java:133) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.RiotParsers$AbstractReaderRIOTLang.read(RiotParsers.java:91) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.RDFParser.read(RDFParser.java:453) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.RDFParser.parseNotUri(RDFParser.java:443) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.RDFParser.parse(RDFParser.java:380) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.RDFParserBuilder.parse(RDFParserBuilder.java:553) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.RDFDataMgr.parseFromInputStream(RDFDataMgr.java:545) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.RDFDataMgr.read(RDFDataMgr.java:252) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.RDFDataMgr.read(RDFDataMgr.java:219) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.RDFDataMgr.read(RDFDataMgr.java:205) ~[jena-arq-5.6.0.jar:5.6.0]
	at no.fdk.resourceservice.service.RdfProcessingService.convertTurtleToJsonLd(RdfProcessingService.kt:43) ~[classes/:na]
	at no.fdk.resourceservice.service.CircuitBreakerService.processResourceEvent(CircuitBreakerService.kt:154) ~[classes/:na]
	at no.fdk.resourceservice.service.CircuitBreakerService.handleConceptEvent(CircuitBreakerService.kt:102) ~[classes/:na]
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:580) ~[na:na]
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:360) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:196) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:89) ~[spring-aop-6.2.11.jar:6.2.11]
	at io.github.resilience4j.circuitbreaker.CircuitBreaker.lambda$decorateCheckedSupplier$0(CircuitBreaker.java:71) ~[resilience4j-circuitbreaker-2.2.0.jar:2.2.0]
	at io.github.resilience4j.circuitbreaker.CircuitBreaker.executeCheckedSupplier(CircuitBreaker.java:739) ~[resilience4j-circuitbreaker-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.circuitbreaker.configure.CircuitBreakerAspect.defaultHandling(CircuitBreakerAspect.java:179) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.circuitbreaker.configure.CircuitBreakerAspect.proceed(CircuitBreakerAspect.java:126) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.circuitbreaker.configure.CircuitBreakerAspect.lambda$circuitBreakerAroundAdvice$0(CircuitBreakerAspect.java:108) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.fallback.DefaultFallbackDecorator.lambda$decorate$0(DefaultFallbackDecorator.java:36) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.fallback.FallbackExecutor.execute(FallbackExecutor.java:39) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.circuitbreaker.configure.CircuitBreakerAspect.circuitBreakerAroundAdvice(CircuitBreakerAspect.java:109) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:580) ~[na:na]
	at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:649) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:631) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:71) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:173) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:89) ~[spring-aop-6.2.11.jar:6.2.11]
	at io.github.resilience4j.retry.Retry.lambda$decorateCheckedSupplier$1(Retry.java:135) ~[resilience4j-retry-2.2.0.jar:2.2.0]
	at io.github.resilience4j.retry.Retry.executeCheckedSupplier(Retry.java:350) ~[resilience4j-retry-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.retry.configure.RetryAspect.handleDefaultJoinPoint(RetryAspect.java:175) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.retry.configure.RetryAspect.proceed(RetryAspect.java:132) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.retry.configure.RetryAspect.lambda$retryAroundAdvice$0(RetryAspect.java:116) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.fallback.FallbackExecutor.execute(FallbackExecutor.java:37) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.retry.configure.RetryAspect.retryAroundAdvice(RetryAspect.java:117) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:580) ~[na:na]
	at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:649) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:631) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:71) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:173) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728) ~[spring-aop-6.2.11.jar:6.2.11]
	at no.fdk.resourceservice.service.CircuitBreakerService$$SpringCGLIB$$0.handleConceptEvent(<generated>) ~[classes/:na]
	at no.fdk.resourceservice.kafka.KafkaConsumer.handleConceptEvent(KafkaConsumer.kt:277) ~[classes/:na]
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:580) ~[na:na]
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169) ~[spring-messaging-6.2.11.jar:6.2.11]
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119) ~[spring-messaging-6.2.11.jar:6.2.11]
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:78) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:475) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:421) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2887) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2865) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2777) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2614) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2503) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2152) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1528) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1466) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1335) ~[spring-kafka-3.3.10.jar:3.3.10]
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1804) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:1570) ~[na:na]

2025-10-24T18:29:50.214+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] n.f.r.service.CircuitBreakerService      :  PROCESS RESOURCE: Converted to JSON-LD, calling resourceService.storeResource
2025-10-24T18:29:50.215+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] n.f.r.service.ResourceService            : Storing resource JSON-LD with id: test-concept-simple, type: CONCEPT, timestamp: 1761323390168
2025-10-24T18:29:50.216+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=?
2025-10-24T18:29:50.218+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=?
2025-10-24T18:29:50.220+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] org.hibernate.SQL                        : 
    insert 
    into
        resources
        (created_at, deleted, resource_json, resource_json_ld, resource_type, timestamp, updated_at, id) 
    values
        (?, ?, ?, ?, ?, ?, ?, ?)
Hibernate: 
    insert 
    into
        resources
        (created_at, deleted, resource_json, resource_json_ld, resource_type, timestamp, updated_at, id) 
    values
        (?, ?, ?, ?, ?, ?, ?, ?)
2025-10-24T18:29:50.222+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] n.f.r.service.CircuitBreakerService      :  PROCESS RESOURCE: Successfully stored HARVESTED resource
2025-10-24T18:29:50.222+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] n.f.r.service.CircuitBreakerService      :  CIRCUIT BREAKER: Successfully processed concept event
2025-10-24T18:29:50.222+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] n.f.resourceservice.kafka.KafkaConsumer  :  CONCEPT LISTENER: Successfully processed, acknowledging message
2025-10-24T18:29:50.222+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] n.f.resourceservice.kafka.KafkaConsumer  :  CONCEPT LISTENER: Message acknowledged successfully
2025-10-24T18:29:50.222+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {concept-events-0=OffsetAndMetadata{offset=1, leaderEpoch=null, metadata=''}}
2025-10-24T18:29:50.222+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Committing: {concept-events-0=OffsetAndMetadata{offset=1, leaderEpoch=null, metadata=''}}
 Waiting... attempt 1/30
2025-10-24T18:29:51.213+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] n.f.r.service.ResourceService            : Getting resource JSON with id: test-concept-simple and type: CONCEPT
2025-10-24T18:29:51.217+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
 Waiting... attempt 2/30
2025-10-24T18:29:52.230+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] n.f.r.service.ResourceService            : Getting resource JSON with id: test-concept-simple and type: CONCEPT
2025-10-24T18:29:52.235+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
2025-10-24T18:29:53.132+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:29:53.134+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:29:53.133+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:29:53.133+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:29:53.134+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:29:53.134+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
 Waiting... attempt 3/30
2025-10-24T18:29:53.247+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] n.f.r.service.ResourceService            : Getting resource JSON with id: test-concept-simple and type: CONCEPT
2025-10-24T18:29:53.248+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
 Waiting... attempt 4/30
2025-10-24T18:29:54.262+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] n.f.r.service.ResourceService            : Getting resource JSON with id: test-concept-simple and type: CONCEPT
2025-10-24T18:29:54.264+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
2025-10-24T18:29:54.444+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:29:54.444+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:29:54.457+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:29:54.457+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:29:54.483+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#6-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:29:54.484+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#6-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:29:55.228+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:29:55.228+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
 Waiting... attempt 5/30
2025-10-24T18:29:55.278+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] n.f.r.service.ResourceService            : Getting resource JSON with id: test-concept-simple and type: CONCEPT
2025-10-24T18:29:55.280+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
 Waiting... attempt 6/30
2025-10-24T18:29:56.290+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] n.f.r.service.ResourceService            : Getting resource JSON with id: test-concept-simple and type: CONCEPT
2025-10-24T18:29:56.292+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
 Waiting... attempt 7/30
2025-10-24T18:29:57.304+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] n.f.r.service.ResourceService            : Getting resource JSON with id: test-concept-simple and type: CONCEPT
2025-10-24T18:29:57.306+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
2025-10-24T18:29:58.135+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:29:58.135+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:29:58.135+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:29:58.136+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:29:58.136+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:29:58.136+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
 Waiting... attempt 8/30
2025-10-24T18:29:58.315+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] n.f.r.service.ResourceService            : Getting resource JSON with id: test-concept-simple and type: CONCEPT
2025-10-24T18:29:58.317+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
 Waiting... attempt 9/30
2025-10-24T18:29:59.329+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] n.f.r.service.ResourceService            : Getting resource JSON with id: test-concept-simple and type: CONCEPT
2025-10-24T18:29:59.331+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
2025-10-24T18:29:59.446+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:29:59.446+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:29:59.458+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:29:59.458+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:29:59.485+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#6-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:29:59.485+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#6-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:30:00.229+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:30:00.230+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
 Waiting... attempt 10/30
2025-10-24T18:30:00.340+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] n.f.r.service.ResourceService            : Getting resource JSON with id: test-concept-simple and type: CONCEPT
2025-10-24T18:30:00.342+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
 Waiting... attempt 11/30
2025-10-24T18:30:01.352+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] n.f.r.service.ResourceService            : Getting resource JSON with id: test-concept-simple and type: CONCEPT
2025-10-24T18:30:01.354+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
 Waiting... attempt 12/30
2025-10-24T18:30:02.365+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] n.f.r.service.ResourceService            : Getting resource JSON with id: test-concept-simple and type: CONCEPT
2025-10-24T18:30:02.367+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
2025-10-24T18:30:03.137+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:30:03.137+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:30:03.137+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:30:03.137+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:30:03.137+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:30:03.137+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
 Waiting... attempt 13/30
2025-10-24T18:30:03.377+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] n.f.r.service.ResourceService            : Getting resource JSON with id: test-concept-simple and type: CONCEPT
2025-10-24T18:30:03.379+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
 Waiting... attempt 14/30
2025-10-24T18:30:04.386+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] n.f.r.service.ResourceService            : Getting resource JSON with id: test-concept-simple and type: CONCEPT
2025-10-24T18:30:04.390+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
2025-10-24T18:30:04.446+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:30:04.447+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:30:04.459+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:30:04.459+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:30:04.486+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#6-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:30:04.486+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#6-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:30:05.231+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:30:05.232+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
 Waiting... attempt 15/30
2025-10-24T18:30:05.404+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] n.f.r.service.ResourceService            : Getting resource JSON with id: test-concept-simple and type: CONCEPT
2025-10-24T18:30:05.405+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
 Waiting... attempt 16/30
2025-10-24T18:30:06.417+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] n.f.r.service.ResourceService            : Getting resource JSON with id: test-concept-simple and type: CONCEPT
2025-10-24T18:30:06.421+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
 Waiting... attempt 17/30
2025-10-24T18:30:07.432+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] n.f.r.service.ResourceService            : Getting resource JSON with id: test-concept-simple and type: CONCEPT
2025-10-24T18:30:07.434+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
2025-10-24T18:30:08.139+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:30:08.139+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:30:08.139+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:30:08.139+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:30:08.139+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:30:08.139+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
 Waiting... attempt 18/30
2025-10-24T18:30:08.444+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] n.f.r.service.ResourceService            : Getting resource JSON with id: test-concept-simple and type: CONCEPT
2025-10-24T18:30:08.446+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
2025-10-24T18:30:09.449+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:30:09.449+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:30:09.462+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:30:09.462+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
 Waiting... attempt 19/30
2025-10-24T18:30:09.468+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] n.f.r.service.ResourceService            : Getting resource JSON with id: test-concept-simple and type: CONCEPT
2025-10-24T18:30:09.471+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
2025-10-24T18:30:09.489+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#6-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:30:09.489+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#6-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:30:10.233+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:30:10.233+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
 Waiting... attempt 20/30
2025-10-24T18:30:10.481+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] n.f.r.service.ResourceService            : Getting resource JSON with id: test-concept-simple and type: CONCEPT
2025-10-24T18:30:10.483+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
 Waiting... attempt 21/30
2025-10-24T18:30:11.494+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] n.f.r.service.ResourceService            : Getting resource JSON with id: test-concept-simple and type: CONCEPT
2025-10-24T18:30:11.498+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
 Waiting... attempt 22/30
2025-10-24T18:30:12.510+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] n.f.r.service.ResourceService            : Getting resource JSON with id: test-concept-simple and type: CONCEPT
2025-10-24T18:30:12.512+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
2025-10-24T18:30:13.140+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:30:13.140+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:30:13.140+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:30:13.140+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:30:13.140+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:30:13.140+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
 Waiting... attempt 23/30
2025-10-24T18:30:13.525+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] n.f.r.service.ResourceService            : Getting resource JSON with id: test-concept-simple and type: CONCEPT
2025-10-24T18:30:13.529+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
2025-10-24T18:30:14.450+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:30:14.450+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:30:14.463+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:30:14.464+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:30:14.490+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#6-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:30:14.491+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#6-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
 Waiting... attempt 24/30
2025-10-24T18:30:14.541+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] n.f.r.service.ResourceService            : Getting resource JSON with id: test-concept-simple and type: CONCEPT
2025-10-24T18:30:14.543+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
2025-10-24T18:30:15.235+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:30:15.235+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
 Waiting... attempt 25/30
2025-10-24T18:30:15.555+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] n.f.r.service.ResourceService            : Getting resource JSON with id: test-concept-simple and type: CONCEPT
2025-10-24T18:30:15.557+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
 Waiting... attempt 26/30
2025-10-24T18:30:16.568+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] n.f.r.service.ResourceService            : Getting resource JSON with id: test-concept-simple and type: CONCEPT
2025-10-24T18:30:16.570+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
 Waiting... attempt 27/30
2025-10-24T18:30:17.583+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] n.f.r.service.ResourceService            : Getting resource JSON with id: test-concept-simple and type: CONCEPT
2025-10-24T18:30:17.585+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
2025-10-24T18:30:18.141+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:30:18.141+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:30:18.141+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:30:18.141+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:30:18.141+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:30:18.141+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
 Waiting... attempt 28/30
2025-10-24T18:30:18.600+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] n.f.r.service.ResourceService            : Getting resource JSON with id: test-concept-simple and type: CONCEPT
2025-10-24T18:30:18.602+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
2025-10-24T18:30:19.451+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:30:19.451+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:30:19.466+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:30:19.466+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:30:19.493+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#6-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:30:19.493+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#6-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
 Waiting... attempt 29/30
2025-10-24T18:30:19.615+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] n.f.r.service.ResourceService            : Getting resource JSON with id: test-concept-simple and type: CONCEPT
2025-10-24T18:30:19.616+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
2025-10-24T18:30:20.237+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:30:20.237+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
 Waiting... attempt 30/30
2025-10-24T18:30:20.628+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] n.f.r.service.ResourceService            : Getting resource JSON with id: test-concept-simple and type: CONCEPT
2025-10-24T18:30:20.631+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
2025-10-24T18:30:20.636+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] n.f.r.service.ResourceService            : Getting resource JSON with id: test-concept-simple and type: CONCEPT
2025-10-24T18:30:20.638+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
 Resource test-concept-simple was NOT found in database
 This suggests the Kafka consumer is not processing messages
2025-10-24T18:30:20.642+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-2] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2025-10-24T18:30:20.646+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-10-24T18:30:20.646+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-24T18:30:20.646+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-10-24T18:30:20.646+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-10-24T18:30:20.646+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.kafka.common.utils.AppInfoParser     : App info kafka.producer for producer-2 unregistered
]]></system-out>
  </testcase>
  <testcase name="should produce and consume Kafka messages end-to-end" classname="no.fdk.resourceservice.integration.KafkaIntegrationTest" time="2.072">
    <failure message="Resource should be stored in database ==&gt; expected: not &lt;null&gt;" type="org.opentest4j.AssertionFailedError"><![CDATA[org.opentest4j.AssertionFailedError: Resource should be stored in database ==> expected: not <null>
	at org.junit.jupiter.api.AssertionFailureBuilder.build(AssertionFailureBuilder.java:152)
	at org.junit.jupiter.api.AssertionFailureBuilder.buildAndThrow(AssertionFailureBuilder.java:132)
	at org.junit.jupiter.api.AssertNotNull.failNull(AssertNotNull.java:49)
	at org.junit.jupiter.api.AssertNotNull.assertNotNull(AssertNotNull.java:35)
	at org.junit.jupiter.api.Assertions.assertNotNull(Assertions.java:312)
	at no.fdk.resourceservice.integration.KafkaIntegrationTest.should produce and consume Kafka messages end-to-end(KafkaIntegrationTest.kt:102)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1597)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1597)
]]></failure>
    <system-out><![CDATA[2025-10-24T18:30:20.656+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [PLAINTEXT://localhost:42839]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-3
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2025-10-24T18:30:20.656+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-10-24T18:30:20.657+02:00  INFO 34429 --- [fdk-resource-service] [           main] i.c.k.s.KafkaAvroSerializerConfig        : KafkaAvroSerializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.remove.java.properties = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.schema.id.deserializer = class io.confluent.kafka.serializers.schema.id.DualSchemaIdDeserializer
	key.schema.id.serializer = class io.confluent.kafka.serializers.schema.id.PrefixSchemaIdSerializer
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.retries = 3
	max.schemas.per.subject = 1000
	normalize.schemas = false
	propagate.schema.tags = false
	proxy.host = 
	proxy.port = -1
	retries.max.wait.ms = 20000
	retries.wait.ms = 1000
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:43977]
	schema.registry.url.randomize = false
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.schema.id.deserializer = class io.confluent.kafka.serializers.schema.id.DualSchemaIdDeserializer
	value.schema.id.serializer = class io.confluent.kafka.serializers.schema.id.PrefixSchemaIdSerializer
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2025-10-24T18:30:20.659+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-3] Instantiated an idempotent producer.
2025-10-24T18:30:20.661+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.clients.producer.ProducerConfig    : These configurations '[schema.registry.url]' were supplied but are not used yet.
2025-10-24T18:30:20.662+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-10-24T18:30:20.662+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-10-24T18:30:20.662+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1761323420662
2025-10-24T18:30:20.671+02:00  INFO 34429 --- [fdk-resource-service] [ad | producer-3] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-3] Cluster ID: BiwIzKnYQGKuWBEG8w9bVw
2025-10-24T18:30:20.671+02:00  INFO 34429 --- [fdk-resource-service] [ad | producer-3] o.a.k.c.p.internals.TransactionManager   : [Producer clientId=producer-3] ProducerId set to 2 with epoch 0
 Produced message to topic: concept-events
2025-10-24T18:30:20.699+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 1 records
2025-10-24T18:30:20.700+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] .a.RecordMessagingMessageListenerAdapter : Processing [GenericMessage [payload={"type": "CONCEPT_HARVESTED", "fdkId": "test-concept-1", "graph": "{uri=https://example.com/test-concept, title=Test Concept, description=A test concept for Kafka integration}", "timestamp": 1761323420655}, headers={kafka_offset=1, kafka_consumer=org.springframework.kafka.core.DefaultKafkaConsumerFactory$ExtendedKafkaConsumer@293a59aa, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, kafka_receivedMessageKey=test-concept-1, kafka_receivedTopic=concept-events, kafka_receivedTimestamp=1761323420671, kafka_acknowledgment=Acknowledgment for concept-events-0@1, kafka_groupId=test-group}]]
2025-10-24T18:30:20.701+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] n.f.resourceservice.kafka.KafkaConsumer  :  CONCEPT LISTENER: Received concept event from topic: concept-events, partition: 0, offset: 1
2025-10-24T18:30:20.701+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] n.f.resourceservice.kafka.KafkaConsumer  : Converting GenericRecord to ConceptEvent
2025-10-24T18:30:20.701+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] n.f.resourceservice.kafka.KafkaConsumer  :  CONCEPT LISTENER: Calling circuitBreakerService.handleConceptEvent
2025-10-24T18:30:20.701+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] n.f.r.service.CircuitBreakerService      :  CIRCUIT BREAKER: Processing concept event with circuit breaker: {"type": "CONCEPT_HARVESTED", "fdkId": "test-concept-1", "graph": "{uri=https://example.com/test-concept, title=Test Concept, description=A test concept for Kafka integration}", "timestamp": 1761323420655}
2025-10-24T18:30:20.701+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] n.f.r.service.CircuitBreakerService      :  CIRCUIT BREAKER: fdkId=test-concept-1, type=CONCEPT_HARVESTED, timestamp=1761323420655
2025-10-24T18:30:20.701+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] n.f.r.service.CircuitBreakerService      :  PROCESS RESOURCE: Processing resource event - fdkId=test-concept-1, resourceType=CONCEPT, eventType=CONCEPT_HARVESTED
2025-10-24T18:30:20.701+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] n.f.r.service.CircuitBreakerService      :  PROCESS RESOURCE: Action extracted: HARVESTED
2025-10-24T18:30:20.701+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] n.f.r.service.CircuitBreakerService      :  PROCESS RESOURCE: Processing HARVESTED event
2025-10-24T18:30:20.701+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] n.f.r.service.RdfProcessingService       : Converting Turtle to JSON-LD
2025-10-24T18:30:20.702+02:00 ERROR 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] org.apache.jena.riot                     : [line: 1, col: 1 ] Not implemented (formulae, graph literals)
2025-10-24T18:30:20.702+02:00 ERROR 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] n.f.r.service.RdfProcessingService       : Failed to convert Turtle to JSON-LD

org.apache.jena.riot.RiotException: [line: 1, col: 1 ] Not implemented (formulae, graph literals)
	at org.apache.jena.riot.system.ErrorHandlerFactory$ErrorHandlerStd.fatal(ErrorHandlerFactory.java:155) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangEngine.raiseException(LangEngine.java:164) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangEngine.exception(LangEngine.java:153) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangEngine.exception(LangEngine.java:147) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangTurtleBase.triplesFormula(LangTurtleBase.java:758) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangTurtleBase.triplesNodeCompound(LangTurtleBase.java:736) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangTurtleBase.triples(LangTurtleBase.java:253) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangTurtle.oneTopLevelElement(LangTurtle.java:46) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangTurtleBase.runParser(LangTurtleBase.java:89) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangBase.parse(LangBase.java:43) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.RiotParsers$AbstractReaderRIOTLang.read(RiotParsers.java:133) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.RiotParsers$AbstractReaderRIOTLang.read(RiotParsers.java:91) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.RDFParser.read(RDFParser.java:453) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.RDFParser.parseNotUri(RDFParser.java:443) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.RDFParser.parse(RDFParser.java:380) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.RDFParserBuilder.parse(RDFParserBuilder.java:553) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.RDFDataMgr.parseFromInputStream(RDFDataMgr.java:545) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.RDFDataMgr.read(RDFDataMgr.java:252) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.RDFDataMgr.read(RDFDataMgr.java:219) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.RDFDataMgr.read(RDFDataMgr.java:205) ~[jena-arq-5.6.0.jar:5.6.0]
	at no.fdk.resourceservice.service.RdfProcessingService.convertTurtleToJsonLd(RdfProcessingService.kt:43) ~[classes/:na]
	at no.fdk.resourceservice.service.CircuitBreakerService.processResourceEvent(CircuitBreakerService.kt:154) ~[classes/:na]
	at no.fdk.resourceservice.service.CircuitBreakerService.handleConceptEvent(CircuitBreakerService.kt:102) ~[classes/:na]
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:580) ~[na:na]
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:360) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:196) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:89) ~[spring-aop-6.2.11.jar:6.2.11]
	at io.github.resilience4j.circuitbreaker.CircuitBreaker.lambda$decorateCheckedSupplier$0(CircuitBreaker.java:71) ~[resilience4j-circuitbreaker-2.2.0.jar:2.2.0]
	at io.github.resilience4j.circuitbreaker.CircuitBreaker.executeCheckedSupplier(CircuitBreaker.java:739) ~[resilience4j-circuitbreaker-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.circuitbreaker.configure.CircuitBreakerAspect.defaultHandling(CircuitBreakerAspect.java:179) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.circuitbreaker.configure.CircuitBreakerAspect.proceed(CircuitBreakerAspect.java:126) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.circuitbreaker.configure.CircuitBreakerAspect.lambda$circuitBreakerAroundAdvice$0(CircuitBreakerAspect.java:108) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.fallback.DefaultFallbackDecorator.lambda$decorate$0(DefaultFallbackDecorator.java:36) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.fallback.FallbackExecutor.execute(FallbackExecutor.java:39) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.circuitbreaker.configure.CircuitBreakerAspect.circuitBreakerAroundAdvice(CircuitBreakerAspect.java:109) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:580) ~[na:na]
	at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:649) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:631) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:71) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:173) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:89) ~[spring-aop-6.2.11.jar:6.2.11]
	at io.github.resilience4j.retry.Retry.lambda$decorateCheckedSupplier$1(Retry.java:135) ~[resilience4j-retry-2.2.0.jar:2.2.0]
	at io.github.resilience4j.retry.Retry.executeCheckedSupplier(Retry.java:350) ~[resilience4j-retry-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.retry.configure.RetryAspect.handleDefaultJoinPoint(RetryAspect.java:175) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.retry.configure.RetryAspect.proceed(RetryAspect.java:132) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.retry.configure.RetryAspect.lambda$retryAroundAdvice$0(RetryAspect.java:116) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.fallback.FallbackExecutor.execute(FallbackExecutor.java:37) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.retry.configure.RetryAspect.retryAroundAdvice(RetryAspect.java:117) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:580) ~[na:na]
	at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:649) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:631) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:71) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:173) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728) ~[spring-aop-6.2.11.jar:6.2.11]
	at no.fdk.resourceservice.service.CircuitBreakerService$$SpringCGLIB$$0.handleConceptEvent(<generated>) ~[classes/:na]
	at no.fdk.resourceservice.kafka.KafkaConsumer.handleConceptEvent(KafkaConsumer.kt:277) ~[classes/:na]
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:580) ~[na:na]
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169) ~[spring-messaging-6.2.11.jar:6.2.11]
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119) ~[spring-messaging-6.2.11.jar:6.2.11]
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:78) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:475) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:421) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2887) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2865) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2777) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2614) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2503) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2152) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1528) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1466) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1335) ~[spring-kafka-3.3.10.jar:3.3.10]
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1804) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:1570) ~[na:na]

2025-10-24T18:30:20.703+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] n.f.r.service.CircuitBreakerService      :  PROCESS RESOURCE: Converted to JSON-LD, calling resourceService.storeResource
2025-10-24T18:30:20.703+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] n.f.r.service.ResourceService            : Storing resource JSON-LD with id: test-concept-1, type: CONCEPT, timestamp: 1761323420655
2025-10-24T18:30:20.704+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=?
2025-10-24T18:30:20.708+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=?
2025-10-24T18:30:20.711+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] org.hibernate.SQL                        : 
    insert 
    into
        resources
        (created_at, deleted, resource_json, resource_json_ld, resource_type, timestamp, updated_at, id) 
    values
        (?, ?, ?, ?, ?, ?, ?, ?)
Hibernate: 
    insert 
    into
        resources
        (created_at, deleted, resource_json, resource_json_ld, resource_type, timestamp, updated_at, id) 
    values
        (?, ?, ?, ?, ?, ?, ?, ?)
2025-10-24T18:30:20.713+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] n.f.r.service.CircuitBreakerService      :  PROCESS RESOURCE: Successfully stored HARVESTED resource
2025-10-24T18:30:20.713+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] n.f.r.service.CircuitBreakerService      :  CIRCUIT BREAKER: Successfully processed concept event
2025-10-24T18:30:20.714+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] n.f.resourceservice.kafka.KafkaConsumer  :  CONCEPT LISTENER: Successfully processed, acknowledging message
2025-10-24T18:30:20.714+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] n.f.resourceservice.kafka.KafkaConsumer  :  CONCEPT LISTENER: Message acknowledged successfully
2025-10-24T18:30:20.714+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {concept-events-0=OffsetAndMetadata{offset=2, leaderEpoch=null, metadata=''}}
2025-10-24T18:30:20.714+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Committing: {concept-events-0=OffsetAndMetadata{offset=2, leaderEpoch=null, metadata=''}}
2025-10-24T18:30:22.703+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] n.f.r.service.ResourceService            : Getting resource JSON with id: test-concept-1 and type: CONCEPT
2025-10-24T18:30:22.705+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
2025-10-24T18:30:22.714+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-3] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2025-10-24T18:30:22.718+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-10-24T18:30:22.718+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-24T18:30:22.718+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-10-24T18:30:22.718+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-10-24T18:30:22.719+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.kafka.common.utils.AppInfoParser     : App info kafka.producer for producer-3 unregistered
]]></system-out>
  </testcase>
  <testcase name="should test business logic directly without Kafka" classname="no.fdk.resourceservice.integration.KafkaIntegrationTest" time="1.14">
    <system-out><![CDATA[ Testing HARVESTED event...
2025-10-24T18:30:22.733+02:00  INFO 34429 --- [fdk-resource-service] [           main] n.f.r.service.CircuitBreakerService      :  CIRCUIT BREAKER: Processing concept event with circuit breaker: {"type": "CONCEPT_HARVESTED", "fdkId": "test-concept-direct", "graph": "@prefix dc: <http://purl.org/dc/elements/1.1/> .\n@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\n\n<https://example.com/direct-concept>\n    dc:title \"Direct Concept\" ;\n    rdf:type <http://example.org/Concept> .", "timestamp": 1761323422732}
2025-10-24T18:30:22.733+02:00  INFO 34429 --- [fdk-resource-service] [           main] n.f.r.service.CircuitBreakerService      :  CIRCUIT BREAKER: fdkId=test-concept-direct, type=CONCEPT_HARVESTED, timestamp=1761323422732
2025-10-24T18:30:22.733+02:00  INFO 34429 --- [fdk-resource-service] [           main] n.f.r.service.CircuitBreakerService      :  PROCESS RESOURCE: Processing resource event - fdkId=test-concept-direct, resourceType=CONCEPT, eventType=CONCEPT_HARVESTED
2025-10-24T18:30:22.733+02:00  INFO 34429 --- [fdk-resource-service] [           main] n.f.r.service.CircuitBreakerService      :  PROCESS RESOURCE: Action extracted: HARVESTED
2025-10-24T18:30:22.733+02:00  INFO 34429 --- [fdk-resource-service] [           main] n.f.r.service.CircuitBreakerService      :  PROCESS RESOURCE: Processing HARVESTED event
2025-10-24T18:30:22.733+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] n.f.r.service.RdfProcessingService       : Converting Turtle to JSON-LD
2025-10-24T18:30:22.837+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] n.f.r.service.RdfProcessingService       : Successfully converted Turtle to JSON-LD with expanded namespaces
2025-10-24T18:30:22.837+02:00  INFO 34429 --- [fdk-resource-service] [           main] n.f.r.service.CircuitBreakerService      :  PROCESS RESOURCE: Converted to JSON-LD, calling resourceService.storeResource
2025-10-24T18:30:22.838+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] n.f.r.service.ResourceService            : Storing resource JSON-LD with id: test-concept-direct, type: CONCEPT, timestamp: 1761323422732
2025-10-24T18:30:22.838+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=?
2025-10-24T18:30:22.841+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=?
2025-10-24T18:30:22.845+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] org.hibernate.SQL                        : 
    insert 
    into
        resources
        (created_at, deleted, resource_json, resource_json_ld, resource_type, timestamp, updated_at, id) 
    values
        (?, ?, ?, ?, ?, ?, ?, ?)
Hibernate: 
    insert 
    into
        resources
        (created_at, deleted, resource_json, resource_json_ld, resource_type, timestamp, updated_at, id) 
    values
        (?, ?, ?, ?, ?, ?, ?, ?)
2025-10-24T18:30:22.848+02:00  INFO 34429 --- [fdk-resource-service] [           main] n.f.r.service.CircuitBreakerService      :  PROCESS RESOURCE: Successfully stored HARVESTED resource
2025-10-24T18:30:22.848+02:00  INFO 34429 --- [fdk-resource-service] [           main] n.f.r.service.CircuitBreakerService      :  CIRCUIT BREAKER: Successfully processed concept event
 Testing REASONED event...
2025-10-24T18:30:22.848+02:00  INFO 34429 --- [fdk-resource-service] [           main] n.f.r.service.CircuitBreakerService      :  CIRCUIT BREAKER: Processing concept event with circuit breaker: {"type": "CONCEPT_REASONED", "fdkId": "test-concept-direct", "graph": "@prefix dc: <http://purl.org/dc/elements/1.1/> .\n@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\n\n<https://example.com/direct-concept>\n    dc:title \"Direct Concept\" ;\n    rdf:type <http://example.org/Concept> .", "timestamp": 1761323423848}
2025-10-24T18:30:22.848+02:00  INFO 34429 --- [fdk-resource-service] [           main] n.f.r.service.CircuitBreakerService      :  CIRCUIT BREAKER: fdkId=test-concept-direct, type=CONCEPT_REASONED, timestamp=1761323423848
2025-10-24T18:30:22.849+02:00  INFO 34429 --- [fdk-resource-service] [           main] n.f.r.service.CircuitBreakerService      :  PROCESS RESOURCE: Processing resource event - fdkId=test-concept-direct, resourceType=CONCEPT, eventType=CONCEPT_REASONED
2025-10-24T18:30:22.849+02:00  INFO 34429 --- [fdk-resource-service] [           main] n.f.r.service.CircuitBreakerService      :  PROCESS RESOURCE: Action extracted: REASONED
2025-10-24T18:30:22.849+02:00  WARN 34429 --- [fdk-resource-service] [           main] n.f.r.service.CircuitBreakerService      : Unknown action in event type: CONCEPT_REASONED
2025-10-24T18:30:22.849+02:00  INFO 34429 --- [fdk-resource-service] [           main] n.f.r.service.CircuitBreakerService      :  CIRCUIT BREAKER: Successfully processed concept event
2025-10-24T18:30:23.142+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:30:23.142+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:30:23.142+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:30:23.142+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#4-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:30:23.142+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:30:23.142+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#5-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:30:23.857+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] n.f.r.service.ResourceService            : Getting resource JSON with id: test-concept-direct and type: CONCEPT
2025-10-24T18:30:23.859+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
 Resource test-concept-direct was NOT found in database
 This suggests the business logic is not working
]]></system-out>
  </testcase>
  <testcase name="should handle resource updates via Kafka" classname="no.fdk.resourceservice.integration.KafkaIntegrationTest" time="2.058">
    <failure message="expected: not &lt;null&gt;" type="org.opentest4j.AssertionFailedError"><![CDATA[org.opentest4j.AssertionFailedError: expected: not <null>
	at org.junit.jupiter.api.AssertionFailureBuilder.build(AssertionFailureBuilder.java:152)
	at org.junit.jupiter.api.AssertionFailureBuilder.buildAndThrow(AssertionFailureBuilder.java:132)
	at org.junit.jupiter.api.AssertNotNull.failNull(AssertNotNull.java:49)
	at org.junit.jupiter.api.AssertNotNull.assertNotNull(AssertNotNull.java:35)
	at org.junit.jupiter.api.AssertNotNull.assertNotNull(AssertNotNull.java:30)
	at org.junit.jupiter.api.Assertions.assertNotNull(Assertions.java:304)
	at no.fdk.resourceservice.integration.KafkaIntegrationTest.should handle resource updates via Kafka(KafkaIntegrationTest.kt:400)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1597)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1597)
]]></failure>
    <system-out><![CDATA[2025-10-24T18:30:23.874+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [PLAINTEXT://localhost:42839]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-4
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2025-10-24T18:30:23.874+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-10-24T18:30:23.875+02:00  INFO 34429 --- [fdk-resource-service] [           main] i.c.k.s.KafkaAvroSerializerConfig        : KafkaAvroSerializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.remove.java.properties = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.schema.id.deserializer = class io.confluent.kafka.serializers.schema.id.DualSchemaIdDeserializer
	key.schema.id.serializer = class io.confluent.kafka.serializers.schema.id.PrefixSchemaIdSerializer
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.retries = 3
	max.schemas.per.subject = 1000
	normalize.schemas = false
	propagate.schema.tags = false
	proxy.host = 
	proxy.port = -1
	retries.max.wait.ms = 20000
	retries.wait.ms = 1000
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:43977]
	schema.registry.url.randomize = false
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.schema.id.deserializer = class io.confluent.kafka.serializers.schema.id.DualSchemaIdDeserializer
	value.schema.id.serializer = class io.confluent.kafka.serializers.schema.id.PrefixSchemaIdSerializer
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

2025-10-24T18:30:23.877+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-4] Instantiated an idempotent producer.
2025-10-24T18:30:23.880+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.clients.producer.ProducerConfig    : These configurations '[schema.registry.url]' were supplied but are not used yet.
2025-10-24T18:30:23.880+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-10-24T18:30:23.880+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-10-24T18:30:23.880+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1761323423880
2025-10-24T18:30:23.891+02:00  INFO 34429 --- [fdk-resource-service] [ad | producer-4] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-4] Cluster ID: BiwIzKnYQGKuWBEG8w9bVw
2025-10-24T18:30:23.891+02:00  INFO 34429 --- [fdk-resource-service] [ad | producer-4] o.a.k.c.p.internals.TransactionManager   : [Producer clientId=producer-4] ProducerId set to 3 with epoch 0
 Sent CREATE event
2025-10-24T18:30:23.911+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 1 records
2025-10-24T18:30:23.912+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] .a.RecordMessagingMessageListenerAdapter : Processing [GenericMessage [payload={"type": "CONCEPT_HARVESTED", "fdkId": "test-concept-update", "graph": "{uri=https://example.com/concept, title=Initial Title}", "timestamp": 1761323423880}, headers={kafka_offset=2, kafka_consumer=org.springframework.kafka.core.DefaultKafkaConsumerFactory$ExtendedKafkaConsumer@293a59aa, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, kafka_receivedMessageKey=test-concept-update, kafka_receivedTopic=concept-events, kafka_receivedTimestamp=1761323423891, kafka_acknowledgment=Acknowledgment for concept-events-0@2, kafka_groupId=test-group}]]
2025-10-24T18:30:23.912+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] n.f.resourceservice.kafka.KafkaConsumer  :  CONCEPT LISTENER: Received concept event from topic: concept-events, partition: 0, offset: 2
2025-10-24T18:30:23.912+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] n.f.resourceservice.kafka.KafkaConsumer  : Converting GenericRecord to ConceptEvent
2025-10-24T18:30:23.912+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] n.f.resourceservice.kafka.KafkaConsumer  :  CONCEPT LISTENER: Calling circuitBreakerService.handleConceptEvent
2025-10-24T18:30:23.913+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] n.f.r.service.CircuitBreakerService      :  CIRCUIT BREAKER: Processing concept event with circuit breaker: {"type": "CONCEPT_HARVESTED", "fdkId": "test-concept-update", "graph": "{uri=https://example.com/concept, title=Initial Title}", "timestamp": 1761323423880}
2025-10-24T18:30:23.913+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] n.f.r.service.CircuitBreakerService      :  CIRCUIT BREAKER: fdkId=test-concept-update, type=CONCEPT_HARVESTED, timestamp=1761323423880
2025-10-24T18:30:23.913+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] n.f.r.service.CircuitBreakerService      :  PROCESS RESOURCE: Processing resource event - fdkId=test-concept-update, resourceType=CONCEPT, eventType=CONCEPT_HARVESTED
2025-10-24T18:30:23.913+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] n.f.r.service.CircuitBreakerService      :  PROCESS RESOURCE: Action extracted: HARVESTED
2025-10-24T18:30:23.913+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] n.f.r.service.CircuitBreakerService      :  PROCESS RESOURCE: Processing HARVESTED event
2025-10-24T18:30:23.913+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] n.f.r.service.RdfProcessingService       : Converting Turtle to JSON-LD
2025-10-24T18:30:23.913+02:00 ERROR 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] org.apache.jena.riot                     : [line: 1, col: 1 ] Not implemented (formulae, graph literals)
2025-10-24T18:30:23.913+02:00 ERROR 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] n.f.r.service.RdfProcessingService       : Failed to convert Turtle to JSON-LD

org.apache.jena.riot.RiotException: [line: 1, col: 1 ] Not implemented (formulae, graph literals)
	at org.apache.jena.riot.system.ErrorHandlerFactory$ErrorHandlerStd.fatal(ErrorHandlerFactory.java:155) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangEngine.raiseException(LangEngine.java:164) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangEngine.exception(LangEngine.java:153) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangEngine.exception(LangEngine.java:147) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangTurtleBase.triplesFormula(LangTurtleBase.java:758) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangTurtleBase.triplesNodeCompound(LangTurtleBase.java:736) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangTurtleBase.triples(LangTurtleBase.java:253) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangTurtle.oneTopLevelElement(LangTurtle.java:46) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangTurtleBase.runParser(LangTurtleBase.java:89) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.LangBase.parse(LangBase.java:43) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.RiotParsers$AbstractReaderRIOTLang.read(RiotParsers.java:133) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.lang.RiotParsers$AbstractReaderRIOTLang.read(RiotParsers.java:91) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.RDFParser.read(RDFParser.java:453) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.RDFParser.parseNotUri(RDFParser.java:443) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.RDFParser.parse(RDFParser.java:380) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.RDFParserBuilder.parse(RDFParserBuilder.java:553) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.RDFDataMgr.parseFromInputStream(RDFDataMgr.java:545) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.RDFDataMgr.read(RDFDataMgr.java:252) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.RDFDataMgr.read(RDFDataMgr.java:219) ~[jena-arq-5.6.0.jar:5.6.0]
	at org.apache.jena.riot.RDFDataMgr.read(RDFDataMgr.java:205) ~[jena-arq-5.6.0.jar:5.6.0]
	at no.fdk.resourceservice.service.RdfProcessingService.convertTurtleToJsonLd(RdfProcessingService.kt:43) ~[classes/:na]
	at no.fdk.resourceservice.service.CircuitBreakerService.processResourceEvent(CircuitBreakerService.kt:154) ~[classes/:na]
	at no.fdk.resourceservice.service.CircuitBreakerService.handleConceptEvent(CircuitBreakerService.kt:102) ~[classes/:na]
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:580) ~[na:na]
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:360) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:196) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:89) ~[spring-aop-6.2.11.jar:6.2.11]
	at io.github.resilience4j.circuitbreaker.CircuitBreaker.lambda$decorateCheckedSupplier$0(CircuitBreaker.java:71) ~[resilience4j-circuitbreaker-2.2.0.jar:2.2.0]
	at io.github.resilience4j.circuitbreaker.CircuitBreaker.executeCheckedSupplier(CircuitBreaker.java:739) ~[resilience4j-circuitbreaker-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.circuitbreaker.configure.CircuitBreakerAspect.defaultHandling(CircuitBreakerAspect.java:179) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.circuitbreaker.configure.CircuitBreakerAspect.proceed(CircuitBreakerAspect.java:126) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.circuitbreaker.configure.CircuitBreakerAspect.lambda$circuitBreakerAroundAdvice$0(CircuitBreakerAspect.java:108) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.fallback.DefaultFallbackDecorator.lambda$decorate$0(DefaultFallbackDecorator.java:36) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.fallback.FallbackExecutor.execute(FallbackExecutor.java:39) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.circuitbreaker.configure.CircuitBreakerAspect.circuitBreakerAroundAdvice(CircuitBreakerAspect.java:109) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:580) ~[na:na]
	at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:649) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:631) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:71) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:173) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:89) ~[spring-aop-6.2.11.jar:6.2.11]
	at io.github.resilience4j.retry.Retry.lambda$decorateCheckedSupplier$1(Retry.java:135) ~[resilience4j-retry-2.2.0.jar:2.2.0]
	at io.github.resilience4j.retry.Retry.executeCheckedSupplier(Retry.java:350) ~[resilience4j-retry-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.retry.configure.RetryAspect.handleDefaultJoinPoint(RetryAspect.java:175) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.retry.configure.RetryAspect.proceed(RetryAspect.java:132) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.retry.configure.RetryAspect.lambda$retryAroundAdvice$0(RetryAspect.java:116) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.fallback.FallbackExecutor.execute(FallbackExecutor.java:37) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at io.github.resilience4j.spring6.retry.configure.RetryAspect.retryAroundAdvice(RetryAspect.java:117) ~[resilience4j-spring6-2.2.0.jar:2.2.0]
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:580) ~[na:na]
	at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:649) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:631) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:71) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:173) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184) ~[spring-aop-6.2.11.jar:6.2.11]
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:728) ~[spring-aop-6.2.11.jar:6.2.11]
	at no.fdk.resourceservice.service.CircuitBreakerService$$SpringCGLIB$$0.handleConceptEvent(<generated>) ~[classes/:na]
	at no.fdk.resourceservice.kafka.KafkaConsumer.handleConceptEvent(KafkaConsumer.kt:277) ~[classes/:na]
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103) ~[na:na]
	at java.base/java.lang.reflect.Method.invoke(Method.java:580) ~[na:na]
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169) ~[spring-messaging-6.2.11.jar:6.2.11]
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119) ~[spring-messaging-6.2.11.jar:6.2.11]
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:78) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:475) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:421) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2887) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2865) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2777) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2614) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2503) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2152) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1528) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1466) ~[spring-kafka-3.3.10.jar:3.3.10]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1335) ~[spring-kafka-3.3.10.jar:3.3.10]
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1804) ~[na:na]
	at java.base/java.lang.Thread.run(Thread.java:1570) ~[na:na]

2025-10-24T18:30:23.914+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] n.f.r.service.CircuitBreakerService      :  PROCESS RESOURCE: Converted to JSON-LD, calling resourceService.storeResource
2025-10-24T18:30:23.914+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] n.f.r.service.ResourceService            : Storing resource JSON-LD with id: test-concept-update, type: CONCEPT, timestamp: 1761323423880
2025-10-24T18:30:23.915+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=?
2025-10-24T18:30:23.919+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=?
2025-10-24T18:30:23.922+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] org.hibernate.SQL                        : 
    insert 
    into
        resources
        (created_at, deleted, resource_json, resource_json_ld, resource_type, timestamp, updated_at, id) 
    values
        (?, ?, ?, ?, ?, ?, ?, ?)
Hibernate: 
    insert 
    into
        resources
        (created_at, deleted, resource_json, resource_json_ld, resource_type, timestamp, updated_at, id) 
    values
        (?, ?, ?, ?, ?, ?, ?, ?)
2025-10-24T18:30:23.928+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] n.f.r.service.CircuitBreakerService      :  PROCESS RESOURCE: Successfully stored HARVESTED resource
2025-10-24T18:30:23.928+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] n.f.r.service.CircuitBreakerService      :  CIRCUIT BREAKER: Successfully processed concept event
2025-10-24T18:30:23.928+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] n.f.resourceservice.kafka.KafkaConsumer  :  CONCEPT LISTENER: Successfully processed, acknowledging message
2025-10-24T18:30:23.928+02:00  INFO 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] n.f.resourceservice.kafka.KafkaConsumer  :  CONCEPT LISTENER: Message acknowledged successfully
2025-10-24T18:30:23.928+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {concept-events-0=OffsetAndMetadata{offset=3, leaderEpoch=null, metadata=''}}
2025-10-24T18:30:23.928+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Committing: {concept-events-0=OffsetAndMetadata{offset=3, leaderEpoch=null, metadata=''}}
2025-10-24T18:30:24.453+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:30:24.453+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:30:24.468+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:30:24.468+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:30:24.495+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#6-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Received: 0 records
2025-10-24T18:30:24.495+02:00 DEBUG 34429 --- [fdk-resource-service] [ntainer#6-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : Commit list: {}
2025-10-24T18:30:25.913+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] n.f.r.service.ResourceService            : Getting resource JSON with id: test-concept-update and type: CONCEPT
2025-10-24T18:30:25.915+02:00 DEBUG 34429 --- [fdk-resource-service] [           main] org.hibernate.SQL                        : 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
Hibernate: 
    select
        re1_0.id,
        re1_0.created_at,
        re1_0.deleted,
        re1_0.resource_json,
        re1_0.resource_json_ld,
        re1_0.resource_type,
        re1_0.timestamp,
        re1_0.updated_at 
    from
        resources re1_0 
    where
        re1_0.id=? 
        and not(re1_0.deleted)
2025-10-24T18:30:25.921+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-4] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2025-10-24T18:30:25.924+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-10-24T18:30:25.924+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-24T18:30:25.924+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-10-24T18:30:25.924+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-10-24T18:30:25.924+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.kafka.common.utils.AppInfoParser     : App info kafka.producer for producer-4 unregistered
]]></system-out>
  </testcase>
  <testcase name="should verify Kafka infrastructure is working" classname="no.fdk.resourceservice.integration.KafkaIntegrationTest" time="0.167">
    <system-out><![CDATA[ Testing Kafka infrastructure...
 Kafka bootstrap servers: PLAINTEXT://localhost:42839
 Schema registry URL: http://localhost:43977
2025-10-24T18:30:25.934+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [PLAINTEXT://localhost:42839]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-5
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2025-10-24T18:30:25.935+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
2025-10-24T18:30:25.936+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-5] Instantiated an idempotent producer.
2025-10-24T18:30:25.938+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.9.1
2025-10-24T18:30:25.938+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: f745dfdcee2b9851
2025-10-24T18:30:25.938+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1761323425938
2025-10-24T18:30:25.959+02:00  WARN 34429 --- [fdk-resource-service] [ad | producer-5] org.apache.kafka.clients.NetworkClient   : [Producer clientId=producer-5] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {test-topic=LEADER_NOT_AVAILABLE}
2025-10-24T18:30:25.959+02:00  INFO 34429 --- [fdk-resource-service] [ad | producer-5] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-5] Cluster ID: BiwIzKnYQGKuWBEG8w9bVw
2025-10-24T18:30:25.960+02:00  INFO 34429 --- [fdk-resource-service] [ad | producer-5] o.a.k.c.p.internals.TransactionManager   : [Producer clientId=producer-5] ProducerId set to 4 with epoch 0
 Kafka producer test successful
2025-10-24T18:30:26.088+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-5] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2025-10-24T18:30:26.090+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
2025-10-24T18:30:26.090+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-10-24T18:30:26.090+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-10-24T18:30:26.090+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
2025-10-24T18:30:26.090+02:00  INFO 34429 --- [fdk-resource-service] [           main] o.a.kafka.common.utils.AppInfoParser     : App info kafka.producer for producer-5 unregistered
]]></system-out>
  </testcase>
</testsuite>